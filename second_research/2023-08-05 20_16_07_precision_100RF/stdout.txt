~~~~~~~~~~ RANDOMIZED SEARCH CV ~~~~~~~~~~
Fitting 5 folds for each of 100 candidates, totalling 500 fits
Parameter choice num 0 / 99 - starting...
0 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 0 1 0]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=  35.7s
1 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 0]
scoring metric: precision, score: 0.7142857142857143 
>>>
predicted correctly / predicted_in_total = 15 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.714 total time=   9.3s
2 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   4.4s
3 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.42857142857142855 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.429 total time=   8.0s
4 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
New improvement!
New best score is 0.5558441558441558
In parameter choice num 0 / 99 avg score was: 0.5558441558441558.
updating 2023-08-05 20_16_07_precision_100RF\search_statistics.txt...
statistics file updated successfully with new improvement in score message!
Best parameter choice score by now is 0.5558441558441558
In parameter choice num 0 / 99 avg score was: 0.5558441558441558.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.636 total time=   5.3s
Parameter choice num 1 / 99 - starting...
5 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.444 total time=   5.2s
6 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.600 total time=   5.9s
7 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 0 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: precision, score: 0.4 
>>>
predicted correctly / predicted_in_total = 6 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.400 total time=   4.4s
8 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   3.7s
9 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 1 0 1]
scoring metric: precision, score: 0.5833333333333334 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
Best parameter choice score by now is 0.5558441558441558
In parameter choice num 1 / 99 avg score was: 0.5055555555555555.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.583 total time=   3.4s
Parameter choice num 2 / 99 - starting...
10 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.444 total time=   0.4s
11 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.625 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.625 total time=   0.4s
12 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1]
scoring metric: precision, score: 0.47058823529411764 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.471 total time=   0.5s
13 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.444 total time=   0.4s
14 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.5558441558441558
In parameter choice num 2 / 99 avg score was: 0.5241681521093285.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.636 total time=   0.4s
Parameter choice num 3 / 99 - starting...
15 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.500 total time=   3.5s
16 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.600 total time=   3.4s
17 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: precision, score: 0.4375 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.438 total time=   4.1s
18 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.375 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.375 total time=   5.6s
19 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 1 0]
scoring metric: precision, score: 0.6923076923076923 
>>>
predicted correctly / predicted_in_total = 13 / 22
<<<
Best parameter choice score by now is 0.5558441558441558
In parameter choice num 3 / 99 avg score was: 0.5209615384615385.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.692 total time=   3.9s
Parameter choice num 4 / 99 - starting...
20 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.444 total time=   1.9s
21 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.667 total time=   2.4s
22 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.5263157894736842 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.526 total time=   2.0s
23 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   1.7s
24 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.5558441558441558
In parameter choice num 4 / 99 avg score was: 0.5547581073896863.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.636 total time=   1.9s
Parameter choice num 5 / 99 - starting...
25 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: precision, score: 0.5833333333333334 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.583 total time=   0.7s
26 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 0 0 0 0 1 1 1 1 1 1 0 1 0]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.667 total time=   0.6s
27 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1]
scoring metric: precision, score: 0.47058823529411764 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.471 total time=   0.4s
28 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.42857142857142855 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.429 total time=   0.4s
29 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
New improvement!
New best score is 0.5571046600458365
In parameter choice num 5 / 99 avg score was: 0.5571046600458365.
updating 2023-08-05 20_16_07_precision_100RF\search_statistics.txt...
statistics file updated successfully with new improvement in score message!
Best parameter choice score by now is 0.5571046600458365
In parameter choice num 5 / 99 avg score was: 0.5571046600458365.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.636 total time=   0.5s
Parameter choice num 6 / 99 - starting...
30 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 0 1 0]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   3.9s
31 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6428571428571429 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.643 total time=   3.8s
32 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   3.9s
33 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.5555555555555556 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.556 total time=   3.7s
34 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
New improvement!
New best score is 0.566955266955267
In parameter choice num 6 / 99 avg score was: 0.566955266955267.
updating 2023-08-05 20_16_07_precision_100RF\search_statistics.txt...
statistics file updated successfully with new improvement in score message!
Best parameter choice score by now is 0.566955266955267
In parameter choice num 6 / 99 avg score was: 0.566955266955267.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.636 total time=   3.8s
Parameter choice num 7 / 99 - starting...
35 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.667 total time=   1.0s
36 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.600 total time=   1.0s
37 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: precision, score: 0.3076923076923077 
>>>
predicted correctly / predicted_in_total = 4 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.308 total time=   1.0s
38 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1]
scoring metric: precision, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 6 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.364 total time=   1.0s
39 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0]
scoring metric: precision, score: 0.75 
>>>
predicted correctly / predicted_in_total = 14 / 22
<<<
Best parameter choice score by now is 0.566955266955267
In parameter choice num 7 / 99 avg score was: 0.5375990675990676.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.750 total time=   1.0s
Parameter choice num 8 / 99 - starting...
40 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 1 0 1 1]
scoring metric: precision, score: 0.5833333333333334 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.583 total time=   0.4s
41 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0]
scoring metric: precision, score: 0.6923076923076923 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.692 total time=   0.4s
42 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1]
scoring metric: precision, score: 0.47058823529411764 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.471 total time=   0.8s
43 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.6 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.600 total time=   0.5s
44 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 1 0 1]
scoring metric: precision, score: 0.5833333333333334 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
New improvement!
New best score is 0.5859125188536953
In parameter choice num 8 / 99 avg score was: 0.5859125188536953.
updating 2023-08-05 20_16_07_precision_100RF\search_statistics.txt...
statistics file updated successfully with new improvement in score message!
Best parameter choice score by now is 0.5859125188536953
In parameter choice num 8 / 99 avg score was: 0.5859125188536953.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.583 total time=   0.4s
Parameter choice num 9 / 99 - starting...
45 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.636 total time=   1.1s
46 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.600 total time=   1.0s
47 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: precision, score: 0.35714285714285715 
>>>
predicted correctly / predicted_in_total = 5 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.357 total time=   1.0s
48 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1]
scoring metric: precision, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 6 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.364 total time=   1.0s
49 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0]
scoring metric: precision, score: 0.75 
>>>
predicted correctly / predicted_in_total = 14 / 22
<<<
Best parameter choice score by now is 0.5859125188536953
In parameter choice num 9 / 99 avg score was: 0.5414285714285715.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.750 total time=   1.0s
Parameter choice num 10 / 99 - starting...
50 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.636 total time=   1.0s
51 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.600 total time=   1.0s
52 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: precision, score: 0.35714285714285715 
>>>
predicted correctly / predicted_in_total = 5 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.357 total time=   1.1s
53 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1]
scoring metric: precision, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 6 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.364 total time=   1.0s
54 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0]
scoring metric: precision, score: 0.75 
>>>
predicted correctly / predicted_in_total = 14 / 22
<<<
Best parameter choice score by now is 0.5859125188536953
In parameter choice num 10 / 99 avg score was: 0.5414285714285715.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.750 total time=   1.1s
Parameter choice num 11 / 99 - starting...
55 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 0 0 0 0 1 1 0 1 1 1 0 1 0]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.636 total time=   0.4s
56 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0]
scoring metric: precision, score: 0.6923076923076923 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.692 total time=   0.4s
57 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.500 total time=   0.4s
58 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.444 total time=   0.5s
59 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
New improvement!
New best score is 0.5879564879564879
In parameter choice num 11 / 99 avg score was: 0.5879564879564879.
updating 2023-08-05 20_16_07_precision_100RF\search_statistics.txt...
statistics file updated successfully with new improvement in score message!
Best parameter choice score by now is 0.5879564879564879
In parameter choice num 11 / 99 avg score was: 0.5879564879564879.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.667 total time=   0.4s
Parameter choice num 12 / 99 - starting...
60 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.636 total time=   0.9s
61 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.600 total time=   1.0s
62 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: precision, score: 0.35714285714285715 
>>>
predicted correctly / predicted_in_total = 5 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.357 total time=   0.9s
63 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1]
scoring metric: precision, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 6 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.364 total time=   1.0s
64 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0]
scoring metric: precision, score: 0.75 
>>>
predicted correctly / predicted_in_total = 14 / 22
<<<
Best parameter choice score by now is 0.5879564879564879
In parameter choice num 12 / 99 avg score was: 0.5414285714285715.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.750 total time=   1.1s
Parameter choice num 13 / 99 - starting...
65 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 0 1 1]
scoring metric: precision, score: 0.5454545454545454 
>>>
predicted correctly / predicted_in_total = 10 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.545 total time=   1.5s
66 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.667 total time=   1.5s
67 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   1.1s
68 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.5555555555555556 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.556 total time=   1.0s
69 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.5879564879564879
In parameter choice num 13 / 99 avg score was: 0.5808080808080807.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.636 total time=   1.0s
Parameter choice num 14 / 99 - starting...
70 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.636 total time=   1.0s
71 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.5625 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.562 total time=   1.0s
72 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: precision, score: 0.3076923076923077 
>>>
predicted correctly / predicted_in_total = 4 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.308 total time=   1.0s
73 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 0 1 1 1]
scoring metric: precision, score: 0.4166666666666667 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.417 total time=   1.0s
74 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0]
scoring metric: precision, score: 0.75 
>>>
predicted correctly / predicted_in_total = 14 / 22
<<<
Best parameter choice score by now is 0.5879564879564879
In parameter choice num 14 / 99 avg score was: 0.5346445221445222.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.750 total time=   1.0s
Parameter choice num 15 / 99 - starting...
75 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.667 total time=   3.3s
76 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.600 total time=   3.4s
77 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: precision, score: 0.3076923076923077 
>>>
predicted correctly / predicted_in_total = 4 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.308 total time=   3.5s
78 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 0 1 1 1]
scoring metric: precision, score: 0.4166666666666667 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.417 total time=   3.5s
79 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 0 1 1 0 0 0 0 1 1 0]
scoring metric: precision, score: 0.8181818181818182 
>>>
predicted correctly / predicted_in_total = 15 / 22
<<<
Best parameter choice score by now is 0.5879564879564879
In parameter choice num 15 / 99 avg score was: 0.5618414918414919.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.818 total time=   3.7s
Parameter choice num 16 / 99 - starting...
80 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.667 total time=   1.0s
81 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.600 total time=   1.3s
82 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: precision, score: 0.4375 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.438 total time=   1.0s
83 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.375 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.375 total time=   1.0s
84 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.5879564879564879
In parameter choice num 16 / 99 avg score was: 0.5431060606060606.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.636 total time=   1.1s
Parameter choice num 17 / 99 - starting...
85 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 1 0]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.636 total time=   4.2s
86 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.667 total time=   4.0s
87 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.47058823529411764 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.471 total time=   3.8s
88 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.444 total time=   4.1s
89 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.5879564879564879
In parameter choice num 17 / 99 avg score was: 0.5708853238265003.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.636 total time=   3.8s
Parameter choice num 18 / 99 - starting...
90 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.667 total time=   0.4s
91 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.600 total time=   0.4s
92 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: precision, score: 0.4375 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.438 total time=   0.5s
93 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 1 1 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.444 total time=   0.4s
94 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 1 0]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.5879564879564879
In parameter choice num 18 / 99 avg score was: 0.5630555555555555.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.667 total time=   0.4s
Parameter choice num 19 / 99 - starting...
95 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 0 0 0 1 0 0 0 0 1 1 0 1 0 1 0 1 0]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.667 total time=   1.2s
96 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6428571428571429 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.643 total time=   1.5s
97 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.500 total time=   1.1s
98 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.444 total time=   0.5s
99 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.5879564879564879
In parameter choice num 19 / 99 avg score was: 0.584126984126984.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.667 total time=   0.4s
Parameter choice num 20 / 99 - starting...
100 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.500 total time=   1.2s
101 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.5714285714285714 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.571 total time=   1.0s
102 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 0 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: precision, score: 0.4 
>>>
predicted correctly / predicted_in_total = 6 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.400 total time=   1.0s
103 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.42857142857142855 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.429 total time=   1.0s
104 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.5879564879564879
In parameter choice num 20 / 99 avg score was: 0.5133333333333334.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.667 total time=   1.1s
Parameter choice num 21 / 99 - starting...
105 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 1 1 1 0 0 0 1 0 0 0 1 1 1 1 0 0 0 1 1]
scoring metric: precision, score: 0.6153846153846154 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.615 total time=   1.1s
106 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 0 1 0]
scoring metric: precision, score: 0.6428571428571429 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.643 total time=   1.2s
107 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: precision, score: 0.4375 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.438 total time=   1.1s
108 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.444 total time=   1.2s
109 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 1 0]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.5879564879564879
In parameter choice num 21 / 99 avg score was: 0.5613705738705739.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.667 total time=   1.3s
Parameter choice num 22 / 99 - starting...
110 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: precision, score: 0.4 
>>>
predicted correctly / predicted_in_total = 7 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.400 total time=   1.2s
111 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6428571428571429 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.643 total time=   1.3s
112 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   1.2s
113 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.42857142857142855 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.429 total time=   1.2s
114 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.5879564879564879
In parameter choice num 22 / 99 avg score was: 0.5215584415584416.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.636 total time=   1.3s
Parameter choice num 23 / 99 - starting...
115 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.500 total time=   1.1s
116 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.625 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.625 total time=   1.0s
117 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: precision, score: 0.4375 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.438 total time=   1.1s
118 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.375 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.375 total time=   1.1s
119 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0]
scoring metric: precision, score: 0.6 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
Best parameter choice score by now is 0.5879564879564879
In parameter choice num 23 / 99 avg score was: 0.5075000000000001.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.600 total time=   1.0s
Parameter choice num 24 / 99 - starting...
120 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 1 1]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.667 total time=   3.8s
121 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.667 total time=   3.9s
122 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.47058823529411764 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.471 total time=   5.1s
123 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.444 total time=   8.2s
124 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.5879564879564879
In parameter choice num 24 / 99 avg score was: 0.5830065359477123.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.667 total time=  15.5s
Parameter choice num 25 / 99 - starting...
125 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 1 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.500 total time=   1.3s
126 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6153846153846154 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.615 total time=   2.3s
127 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: precision, score: 0.4375 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.438 total time=   3.0s
128 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.42857142857142855 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.429 total time=   4.3s
129 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0]
scoring metric: precision, score: 0.6 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
Best parameter choice score by now is 0.5879564879564879
In parameter choice num 25 / 99 avg score was: 0.5162912087912088.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.600 total time=   0.5s
Parameter choice num 26 / 99 - starting...
130 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 1 1 1 0 0 0 1 0 0 1 1 1 1 1 0 0 0 1 1]
scoring metric: precision, score: 0.6153846153846154 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.615 total time=   3.9s
131 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 0 1 0]
scoring metric: precision, score: 0.6428571428571429 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.643 total time=   5.2s
132 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: precision, score: 0.4375 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.438 total time=   7.0s
133 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.375 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.375 total time=   4.4s
134 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 1 0]
scoring metric: precision, score: 0.6923076923076923 
>>>
predicted correctly / predicted_in_total = 13 / 22
<<<
Best parameter choice score by now is 0.5879564879564879
In parameter choice num 26 / 99 avg score was: 0.5526098901098901.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.692 total time=   3.9s
Parameter choice num 27 / 99 - starting...
135 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 1 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   0.5s
136 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6428571428571429 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.643 total time=   0.5s
137 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: precision, score: 0.47058823529411764 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.471 total time=   0.4s
138 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.5714285714285714 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.571 total time=   0.4s
139 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 1 0 1]
scoring metric: precision, score: 0.5833333333333334 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
Best parameter choice score by now is 0.5879564879564879
In parameter choice num 27 / 99 avg score was: 0.5536414565826331.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.583 total time=   0.4s
Parameter choice num 28 / 99 - starting...
140 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: precision, score: 0.5454545454545454 
>>>
predicted correctly / predicted_in_total = 10 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.545 total time=   1.1s
141 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.625 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.625 total time=   1.2s
142 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: precision, score: 0.4375 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.438 total time=   1.0s
143 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.500 total time=   1.1s
144 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.5879564879564879
In parameter choice num 28 / 99 avg score was: 0.5488636363636363.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.636 total time=   1.0s
Parameter choice num 29 / 99 - starting...
145 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.444 total time=   1.2s
146 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.600 total time=   1.0s
147 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.4375 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.438 total time=   1.0s
148 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.5714285714285714 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.571 total time=   1.0s
149 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 1 0 1]
scoring metric: precision, score: 0.5833333333333334 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
Best parameter choice score by now is 0.5879564879564879
In parameter choice num 29 / 99 avg score was: 0.5273412698412698.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.583 total time=   1.0s
Parameter choice num 30 / 99 - starting...
150 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.667 total time=   3.8s
151 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 1 0 0 0 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.5333333333333333 
>>>
predicted correctly / predicted_in_total = 10 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.533 total time=   4.2s
152 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: precision, score: 0.3076923076923077 
>>>
predicted correctly / predicted_in_total = 4 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.308 total time=   3.9s
153 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 1 1 1]
scoring metric: precision, score: 0.3 
>>>
predicted correctly / predicted_in_total = 5 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.300 total time=   3.6s
154 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0]
scoring metric: precision, score: 0.75 
>>>
predicted correctly / predicted_in_total = 14 / 22
<<<
Best parameter choice score by now is 0.5879564879564879
In parameter choice num 30 / 99 avg score was: 0.5115384615384615.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.750 total time=   3.5s
Parameter choice num 31 / 99 - starting...
155 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.444 total time=   4.1s
156 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 1 0 0 0 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.5333333333333333 
>>>
predicted correctly / predicted_in_total = 10 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.533 total time=   4.2s
157 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 0 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: precision, score: 0.4 
>>>
predicted correctly / predicted_in_total = 6 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.400 total time=   3.2s
158 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.42857142857142855 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.429 total time=   3.6s
159 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.5879564879564879
In parameter choice num 31 / 99 avg score was: 0.4946031746031746.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.667 total time=   3.5s
Parameter choice num 32 / 99 - starting...
160 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 1 1 1 0 0 1 0 0 0 1 1 1 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.7142857142857143 
>>>
predicted correctly / predicted_in_total = 15 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.714 total time=   0.4s
161 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0]
scoring metric: precision, score: 0.5714285714285714 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.571 total time=   0.4s
162 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: precision, score: 0.35714285714285715 
>>>
predicted correctly / predicted_in_total = 5 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.357 total time=   0.4s
163 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1]
scoring metric: precision, score: 0.4166666666666667 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.417 total time=   0.4s
164 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 0 1 1 0]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.5879564879564879
In parameter choice num 32 / 99 avg score was: 0.5452380952380952.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.667 total time=   0.4s
Parameter choice num 33 / 99 - starting...
165 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 1 1]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.636 total time=   0.4s
166 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.667 total time=   0.4s
167 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.500 total time=   0.4s
168 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.444 total time=   0.4s
169 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.5879564879564879
In parameter choice num 33 / 99 avg score was: 0.5828282828282828.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.667 total time=   0.4s
Parameter choice num 34 / 99 - starting...
170 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.444 total time=   3.4s
171 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.600 total time=   3.3s
172 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: precision, score: 0.4375 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.438 total time=   4.2s
173 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.375 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.375 total time=   4.2s
174 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.5879564879564879
In parameter choice num 34 / 99 avg score was: 0.5047222222222222.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.667 total time=   3.5s
Parameter choice num 35 / 99 - starting...
175 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 1 1 0 0 0 1 1 0 1 0 1 0 1 0]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.667 total time=   0.5s
176 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 0 1 1 1 1 1 0 1 0]
scoring metric: precision, score: 0.6923076923076923 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.692 total time=   1.0s
177 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.500 total time=   0.4s
178 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.444 total time=   0.5s
179 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
New improvement!
New best score is 0.5940170940170939
In parameter choice num 35 / 99 avg score was: 0.5940170940170939.
updating 2023-08-05 20_16_07_precision_100RF\search_statistics.txt...
statistics file updated successfully with new improvement in score message!
Best parameter choice score by now is 0.5940170940170939
In parameter choice num 35 / 99 avg score was: 0.5940170940170939.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.667 total time=   0.4s
Parameter choice num 36 / 99 - starting...
180 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.667 total time=   5.8s
181 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.5625 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.562 total time=   5.0s
182 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: precision, score: 0.3076923076923077 
>>>
predicted correctly / predicted_in_total = 4 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.308 total time=   5.4s
183 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1]
scoring metric: precision, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 6 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.364 total time=   4.0s
184 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0]
scoring metric: precision, score: 0.75 
>>>
predicted correctly / predicted_in_total = 14 / 22
<<<
Best parameter choice score by now is 0.5940170940170939
In parameter choice num 36 / 99 avg score was: 0.5300990675990676.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.750 total time=  10.7s
Parameter choice num 37 / 99 - starting...
185 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 1 0]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.636 total time=   9.1s
186 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.667 total time=   5.0s
187 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.47058823529411764 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.471 total time=   5.1s
188 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.444 total time=   4.3s
189 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.5940170940170939
In parameter choice num 37 / 99 avg score was: 0.5708853238265003.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.636 total time=   4.3s
Parameter choice num 38 / 99 - starting...
190 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 1 0 1 1 1 0 1 1]
scoring metric: precision, score: 0.6923076923076923 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.692 total time=   0.4s
191 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0]
scoring metric: precision, score: 0.6923076923076923 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.692 total time=   0.4s
192 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.500 total time=   0.4s
193 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.444 total time=   0.4s
194 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.7272727272727273 
>>>
predicted correctly / predicted_in_total = 13 / 22
<<<
New improvement!
New best score is 0.6112665112665112
In parameter choice num 38 / 99 avg score was: 0.6112665112665112.
updating 2023-08-05 20_16_07_precision_100RF\search_statistics.txt...
statistics file updated successfully with new improvement in score message!
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 38 / 99 avg score was: 0.6112665112665112.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.727 total time=   0.4s
Parameter choice num 39 / 99 - starting...
195 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.444 total time=   3.5s
196 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.667 total time=   3.4s
197 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.5263157894736842 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.526 total time=   3.3s
198 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   3.4s
199 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 1 0 1]
scoring metric: precision, score: 0.5833333333333334 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 39 / 99 avg score was: 0.5441520467836257.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.583 total time=   3.3s
Parameter choice num 40 / 99 - starting...
200 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.444 total time=   1.0s
201 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.667 total time=   1.0s
202 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.5263157894736842 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.526 total time=   1.0s
203 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   1.3s
204 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 40 / 99 avg score was: 0.5547581073896863.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.636 total time=   1.3s
Parameter choice num 41 / 99 - starting...
205 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.636 total time=   1.2s
206 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.600 total time=   1.2s
207 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: precision, score: 0.3076923076923077 
>>>
predicted correctly / predicted_in_total = 4 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.308 total time=   1.0s
208 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 0 1 1 1]
scoring metric: precision, score: 0.4166666666666667 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.417 total time=   1.2s
209 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0]
scoring metric: precision, score: 0.75 
>>>
predicted correctly / predicted_in_total = 14 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 41 / 99 avg score was: 0.5421445221445221.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.750 total time=   1.3s
Parameter choice num 42 / 99 - starting...
210 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.444 total time=   4.3s
211 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.600 total time=   3.8s
212 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 0 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: precision, score: 0.4 
>>>
predicted correctly / predicted_in_total = 6 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.400 total time=   4.9s
213 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.42857142857142855 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.429 total time=   4.5s
214 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0]
scoring metric: precision, score: 0.6 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 42 / 99 avg score was: 0.49460317460317454.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.600 total time=   3.9s
Parameter choice num 43 / 99 - starting...
215 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 1 1 1 0 0 1 0 0 0 1 1 1 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.7142857142857143 
>>>
predicted correctly / predicted_in_total = 15 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.714 total time=   0.6s
216 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0]
scoring metric: precision, score: 0.5714285714285714 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.571 total time=   0.4s
217 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: precision, score: 0.35714285714285715 
>>>
predicted correctly / predicted_in_total = 5 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.357 total time=   0.7s
218 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1]
scoring metric: precision, score: 0.4166666666666667 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.417 total time=   0.5s
219 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 0 1 1 0]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 43 / 99 avg score was: 0.5452380952380952.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.667 total time=   1.3s
Parameter choice num 44 / 99 - starting...
220 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 1 0]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.636 total time=   5.0s
221 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.667 total time=   4.2s
222 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.47058823529411764 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.471 total time=   4.1s
223 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.444 total time=   5.4s
224 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 44 / 99 avg score was: 0.5708853238265003.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.636 total time=   6.4s
Parameter choice num 45 / 99 - starting...
225 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.667 total time=   3.8s
226 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 1 0 0 0 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.5333333333333333 
>>>
predicted correctly / predicted_in_total = 10 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.533 total time=   4.3s
227 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: precision, score: 0.3076923076923077 
>>>
predicted correctly / predicted_in_total = 4 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.308 total time=   4.1s
228 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.3333333333333333 
>>>
predicted correctly / predicted_in_total = 6 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.333 total time=   3.6s
229 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 1 0]
scoring metric: precision, score: 0.6923076923076923 
>>>
predicted correctly / predicted_in_total = 13 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 45 / 99 avg score was: 0.5066666666666666.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.692 total time=   3.6s
Parameter choice num 46 / 99 - starting...
230 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.667 total time=   3.2s
231 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.5625 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.562 total time=   3.2s
232 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: precision, score: 0.3076923076923077 
>>>
predicted correctly / predicted_in_total = 4 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.308 total time=   3.5s
233 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1]
scoring metric: precision, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 6 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.364 total time=   5.4s
234 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0]
scoring metric: precision, score: 0.75 
>>>
predicted correctly / predicted_in_total = 14 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 46 / 99 avg score was: 0.5300990675990676.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.750 total time=   3.3s
Parameter choice num 47 / 99 - starting...
235 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: precision, score: 0.4 
>>>
predicted correctly / predicted_in_total = 7 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.400 total time=   1.3s
236 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6428571428571429 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.643 total time=   1.2s
237 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   1.1s
238 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.42857142857142855 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.429 total time=   1.3s
239 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 47 / 99 avg score was: 0.5215584415584416.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.636 total time=   1.5s
Parameter choice num 48 / 99 - starting...
240 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 1 1]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.667 total time=   5.1s
241 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.667 total time=   4.0s
242 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.47058823529411764 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.471 total time=   3.6s
243 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.444 total time=   3.6s
244 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 48 / 99 avg score was: 0.5769459298871064.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.636 total time=   3.5s
Parameter choice num 49 / 99 - starting...
245 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 1 0 1 1 1 1 1 0 0 0 1 0]
scoring metric: precision, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   0.4s
246 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0]
scoring metric: precision, score: 0.6923076923076923 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.692 total time=   0.4s
247 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.47058823529411764 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.471 total time=   0.4s
248 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 0 1 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.636 total time=   0.4s
249 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 1 0 1]
scoring metric: precision, score: 0.5833333333333334 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 49 / 99 avg score was: 0.5674276703688468.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.583 total time=   0.4s
Parameter choice num 50 / 99 - starting...
250 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.636 total time=   0.9s
251 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.5625 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.562 total time=   0.9s
252 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: precision, score: 0.3076923076923077 
>>>
predicted correctly / predicted_in_total = 4 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.308 total time=   1.0s
253 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 0 1 1 1]
scoring metric: precision, score: 0.4166666666666667 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.417 total time=   1.0s
254 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0]
scoring metric: precision, score: 0.75 
>>>
predicted correctly / predicted_in_total = 14 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 50 / 99 avg score was: 0.5346445221445222.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.750 total time=   1.0s
Parameter choice num 51 / 99 - starting...
255 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.667 total time=   3.2s
256 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.5714285714285714 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.571 total time=   3.4s
257 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 0 0 0 1 1]
scoring metric: precision, score: 0.25 
>>>
predicted correctly / predicted_in_total = 3 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.250 total time=   3.3s
258 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 0 1 1 0 1 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.4 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.400 total time=   4.4s
259 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 0 1 1 0 0 0 0 1 1 0]
scoring metric: precision, score: 0.8181818181818182 
>>>
predicted correctly / predicted_in_total = 15 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 51 / 99 avg score was: 0.5412554112554113.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.818 total time=   6.1s
Parameter choice num 52 / 99 - starting...
260 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 0 1 0]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   5.2s
261 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6428571428571429 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.643 total time=   4.3s
262 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   3.6s
263 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   3.7s
264 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 1 0 1]
scoring metric: precision, score: 0.5833333333333334 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 52 / 99 avg score was: 0.5452380952380953.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.583 total time=   3.9s
Parameter choice num 53 / 99 - starting...
265 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.444 total time=   3.7s
266 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.667 total time=   4.1s
267 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   4.9s
268 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.42857142857142855 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.429 total time=   6.5s
269 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 1 0 1]
scoring metric: precision, score: 0.5833333333333334 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 53 / 99 avg score was: 0.5246031746031746.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.583 total time=   3.9s
Parameter choice num 54 / 99 - starting...
270 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 1 1 0 0 1 1 0]
scoring metric: precision, score: 0.6153846153846154 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.615 total time=   0.4s
271 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.5625 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.562 total time=   0.6s
272 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: precision, score: 0.4 
>>>
predicted correctly / predicted_in_total = 6 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.400 total time=   0.7s
273 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 1 0 1 1 1]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.444 total time=   0.9s
274 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 1 0]
scoring metric: precision, score: 0.6923076923076923 
>>>
predicted correctly / predicted_in_total = 13 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 54 / 99 avg score was: 0.5429273504273505.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.692 total time=   0.6s
Parameter choice num 55 / 99 - starting...
275 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 1 0 1 1]
scoring metric: precision, score: 0.6923076923076923 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.692 total time=   4.4s
276 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.667 total time=   4.4s
277 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.47058823529411764 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.471 total time=   4.8s
278 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.444 total time=   6.6s
279 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.7272727272727273 
>>>
predicted correctly / predicted_in_total = 13 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 55 / 99 avg score was: 0.6002559531971297.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.727 total time=   4.2s
Parameter choice num 56 / 99 - starting...
280 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 1 0 0 0 1 1 1 0 1 0 1 0 1 1]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.667 total time=   1.0s
281 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.667 total time=   1.0s
282 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.47058823529411764 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.471 total time=   1.1s
283 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.444 total time=   1.0s
284 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.7272727272727273 
>>>
predicted correctly / predicted_in_total = 13 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 56 / 99 avg score was: 0.5951277480689245.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.727 total time=   1.1s
Parameter choice num 57 / 99 - starting...
285 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 0 1 0]
scoring metric: precision, score: 0.5454545454545454 
>>>
predicted correctly / predicted_in_total = 10 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.545 total time=   0.4s
286 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.625 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.625 total time=   0.4s
287 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 0 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: precision, score: 0.4 
>>>
predicted correctly / predicted_in_total = 6 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.400 total time=   0.4s
288 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 1 0 1 1 1]
scoring metric: precision, score: 0.25 
>>>
predicted correctly / predicted_in_total = 5 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.250 total time=   0.4s
289 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 57 / 99 avg score was: 0.49136363636363634.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.636 total time=   0.4s
Parameter choice num 58 / 99 - starting...
290 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   1.0s
291 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6428571428571429 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.643 total time=   1.0s
292 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.47058823529411764 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.471 total time=   1.4s
293 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.5555555555555556 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.556 total time=   1.3s
294 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.7 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 58 / 99 avg score was: 0.5738001867413633.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.700 total time=   1.2s
Parameter choice num 59 / 99 - starting...
295 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 0 0 0 0 1 1 0 1 1 1 0 1 0]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.636 total time=   0.4s
296 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0]
scoring metric: precision, score: 0.6923076923076923 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.692 total time=   0.4s
297 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.500 total time=   0.4s
298 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.444 total time=   0.5s
299 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 59 / 99 avg score was: 0.5879564879564879.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.667 total time=   0.4s
Parameter choice num 60 / 99 - starting...
300 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.444 total time=   3.4s
301 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.625 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.625 total time=   3.4s
302 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: precision, score: 0.4375 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.438 total time=   3.6s
303 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.375 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.375 total time=   3.2s
304 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 60 / 99 avg score was: 0.5036616161616162.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.636 total time=   3.2s
Parameter choice num 61 / 99 - starting...
305 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 1 0]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.636 total time=   1.0s
306 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.667 total time=   1.1s
307 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.47058823529411764 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.471 total time=   1.1s
308 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.444 total time=   1.1s
309 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.7 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 61 / 99 avg score was: 0.5836125965537731.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.700 total time=   1.1s
Parameter choice num 62 / 99 - starting...
310 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.636 total time=   1.0s
311 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.600 total time=   1.0s
312 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: precision, score: 0.35714285714285715 
>>>
predicted correctly / predicted_in_total = 5 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.357 total time=   1.1s
313 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1]
scoring metric: precision, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 6 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.364 total time=   1.4s
314 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0]
scoring metric: precision, score: 0.75 
>>>
predicted correctly / predicted_in_total = 14 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 62 / 99 avg score was: 0.5414285714285715.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.750 total time=   1.3s
Parameter choice num 63 / 99 - starting...
315 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.667 total time=   3.1s
316 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.5625 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.562 total time=   3.3s
317 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: precision, score: 0.3076923076923077 
>>>
predicted correctly / predicted_in_total = 4 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.308 total time=   3.4s
318 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1]
scoring metric: precision, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 6 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.364 total time=   4.1s
319 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0]
scoring metric: precision, score: 0.75 
>>>
predicted correctly / predicted_in_total = 14 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 63 / 99 avg score was: 0.5300990675990676.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.750 total time=   3.7s
Parameter choice num 64 / 99 - starting...
320 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 1 1]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.667 total time=   1.1s
321 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.667 total time=   1.3s
322 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.47058823529411764 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.471 total time=   1.3s
323 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.444 total time=   1.3s
324 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 64 / 99 avg score was: 0.5830065359477123.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.667 total time=   1.7s
Parameter choice num 65 / 99 - starting...
325 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.636 total time=   1.4s
326 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.600 total time=   1.2s
327 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: precision, score: 0.35714285714285715 
>>>
predicted correctly / predicted_in_total = 5 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.357 total time=   1.0s
328 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1]
scoring metric: precision, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 6 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.364 total time=   1.0s
329 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0]
scoring metric: precision, score: 0.75 
>>>
predicted correctly / predicted_in_total = 14 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 65 / 99 avg score was: 0.5414285714285715.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.750 total time=   1.0s
Parameter choice num 66 / 99 - starting...
330 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.500 total time=   3.5s
331 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.600 total time=   3.6s
332 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: precision, score: 0.4375 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.438 total time=   3.5s
333 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.375 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.375 total time=   3.4s
334 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 66 / 99 avg score was: 0.5158333333333334.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.667 total time=   3.9s
Parameter choice num 67 / 99 - starting...
335 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1]
scoring metric: precision, score: 0.5833333333333334 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.583 total time=   1.1s
336 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.625 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.625 total time=   1.1s
337 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: precision, score: 0.4375 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.438 total time=   1.1s
338 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 1 0 1 1 1]
scoring metric: precision, score: 0.3333333333333333 
>>>
predicted correctly / predicted_in_total = 6 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.333 total time=   1.1s
339 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 1 0]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 67 / 99 avg score was: 0.5291666666666667.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.667 total time=   1.4s
Parameter choice num 68 / 99 - starting...
340 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.500 total time=   1.1s
341 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6428571428571429 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.643 total time=   1.7s
342 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.47058823529411764 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.471 total time=   1.7s
343 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.444 total time=   1.0s
344 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [0 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.6 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 68 / 99 avg score was: 0.531577964519141.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.600 total time=   1.1s
Parameter choice num 69 / 99 - starting...
345 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 1 0]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.636 total time=   1.0s
346 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.667 total time=   1.0s
347 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.47058823529411764 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.471 total time=   1.1s
348 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.444 total time=   1.0s
349 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 69 / 99 avg score was: 0.5708853238265003.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.636 total time=   1.0s
Parameter choice num 70 / 99 - starting...
350 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 1 1 1 0 0 0 1 0 0 1 1 1 1 1 0 0 0 1 1]
scoring metric: precision, score: 0.6153846153846154 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.615 total time=   3.4s
351 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 0 1 0]
scoring metric: precision, score: 0.6428571428571429 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.643 total time=   3.3s
352 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: precision, score: 0.4375 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.438 total time=   3.6s
353 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.375 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.375 total time=   3.5s
354 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 1 0]
scoring metric: precision, score: 0.6923076923076923 
>>>
predicted correctly / predicted_in_total = 13 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 70 / 99 avg score was: 0.5526098901098901.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.692 total time=   3.4s
Parameter choice num 71 / 99 - starting...
355 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 1 1 1]
scoring metric: precision, score: 0.6428571428571429 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.643 total time=   0.4s
356 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.600 total time=   0.4s
357 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: precision, score: 0.3076923076923077 
>>>
predicted correctly / predicted_in_total = 4 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.308 total time=   0.4s
358 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 0 1 1 1]
scoring metric: precision, score: 0.4166666666666667 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.417 total time=   0.4s
359 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 0 1 1 0 0 0 0 1 1 0]
scoring metric: precision, score: 0.8181818181818182 
>>>
predicted correctly / predicted_in_total = 15 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 71 / 99 avg score was: 0.5570795870795872.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.818 total time=   0.4s
Parameter choice num 72 / 99 - starting...
360 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.444 total time=   4.0s
361 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.5714285714285714 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.571 total time=   3.5s
362 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 0 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: precision, score: 0.4 
>>>
predicted correctly / predicted_in_total = 6 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.400 total time=   3.8s
363 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.42857142857142855 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.429 total time=   4.1s
364 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0]
scoring metric: precision, score: 0.6 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 72 / 99 avg score was: 0.4888888888888888.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.600 total time=   4.1s
Parameter choice num 73 / 99 - starting...
365 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.444 total time=   1.2s
366 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.625 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.625 total time=   1.2s
367 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: precision, score: 0.4375 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.438 total time=   1.3s
368 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.42857142857142855 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.429 total time=   1.2s
369 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0]
scoring metric: precision, score: 0.6 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 73 / 99 avg score was: 0.5071031746031747.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.600 total time=   1.1s
Parameter choice num 74 / 99 - starting...
370 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 1 1 0 0 1 1 1]
scoring metric: precision, score: 0.6428571428571429 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.643 total time=   0.5s
371 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.600 total time=   0.6s
372 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: precision, score: 0.35714285714285715 
>>>
predicted correctly / predicted_in_total = 5 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.357 total time=   0.6s
373 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 1 0 0 1 0 1 0 1 1 0 0 0 0 0 1 0 1 1 1]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.500 total time=   0.6s
374 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0]
scoring metric: precision, score: 0.75 
>>>
predicted correctly / predicted_in_total = 14 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 74 / 99 avg score was: 0.5700000000000001.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.750 total time=   0.9s
Parameter choice num 75 / 99 - starting...
375 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.444 total time=   4.1s
376 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.625 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.625 total time=   4.3s
377 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: precision, score: 0.4375 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.438 total time=   3.4s
378 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.375 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.375 total time=   3.9s
379 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 75 / 99 avg score was: 0.5036616161616162.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.636 total time=   5.8s
Parameter choice num 76 / 99 - starting...
380 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1 0 1 1 1 0 1 1]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.667 total time=   0.6s
381 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 0]
scoring metric: precision, score: 0.7142857142857143 
>>>
predicted correctly / predicted_in_total = 15 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.714 total time=   0.8s
382 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.500 total time=   0.7s
383 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.444 total time=   0.6s
384 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.6112665112665112
In parameter choice num 76 / 99 avg score was: 0.5984126984126983.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.667 total time=   0.5s
Parameter choice num 77 / 99 - starting...
385 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1 0 1 0 1 1]
scoring metric: precision, score: 0.7142857142857143 
>>>
predicted correctly / predicted_in_total = 15 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.714 total time=   6.3s
386 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 0]
scoring metric: precision, score: 0.7142857142857143 
>>>
predicted correctly / predicted_in_total = 15 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.714 total time=   5.7s
387 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.47058823529411764 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.471 total time=   6.0s
388 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.444 total time=   5.4s
389 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.7272727272727273 
>>>
predicted correctly / predicted_in_total = 13 / 22
<<<
New improvement!
New best score is 0.6141753671165435
In parameter choice num 77 / 99 avg score was: 0.6141753671165435.
updating 2023-08-05 20_16_07_precision_100RF\search_statistics.txt...
statistics file updated successfully with new improvement in score message!
Best parameter choice score by now is 0.6141753671165435
In parameter choice num 77 / 99 avg score was: 0.6141753671165435.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.727 total time=   6.0s
Parameter choice num 78 / 99 - starting...
390 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.444 total time=   2.3s
391 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6428571428571429 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.643 total time=   1.9s
392 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.5263157894736842 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.526 total time=   1.2s
393 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.5555555555555556 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.556 total time=   1.5s
394 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.6141753671165435
In parameter choice num 78 / 99 avg score was: 0.5611073137388927.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.636 total time=   1.3s
Parameter choice num 79 / 99 - starting...
395 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 1 1]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.636 total time=   0.4s
396 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.667 total time=   0.5s
397 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.500 total time=   0.4s
398 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.444 total time=   0.5s
399 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.6141753671165435
In parameter choice num 79 / 99 avg score was: 0.5828282828282828.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.667 total time=   0.7s
Parameter choice num 80 / 99 - starting...
400 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.444 total time=   5.2s
401 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.667 total time=   4.7s
402 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.5263157894736842 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.526 total time=   4.9s
403 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   8.9s
404 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 1 0 1]
scoring metric: precision, score: 0.5833333333333334 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
Best parameter choice score by now is 0.6141753671165435
In parameter choice num 80 / 99 avg score was: 0.5441520467836257.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.583 total time=   4.4s
Parameter choice num 81 / 99 - starting...
405 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 1 0 0 0 1 1]
scoring metric: precision, score: 0.5833333333333334 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.583 total time=   0.5s
406 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.5714285714285714 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.571 total time=   0.6s
407 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: precision, score: 0.4375 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.438 total time=   0.4s
408 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 1 0 1 1 1]
scoring metric: precision, score: 0.3333333333333333 
>>>
predicted correctly / predicted_in_total = 6 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.333 total time=   0.6s
409 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.7142857142857143 
>>>
predicted correctly / predicted_in_total = 14 / 22
<<<
Best parameter choice score by now is 0.6141753671165435
In parameter choice num 81 / 99 avg score was: 0.5279761904761904.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.714 total time=   0.6s
Parameter choice num 82 / 99 - starting...
410 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 1 0 0 0 1 1 1 1 0 0 0 1 1]
scoring metric: precision, score: 0.5454545454545454 
>>>
predicted correctly / predicted_in_total = 10 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.545 total time=   3.6s
411 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6428571428571429 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.643 total time=   3.7s
412 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   3.6s
413 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   3.6s
414 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 1 0 1]
scoring metric: precision, score: 0.5833333333333334 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
Best parameter choice score by now is 0.6141753671165435
In parameter choice num 82 / 99 avg score was: 0.5543290043290043.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.583 total time=   5.4s
Parameter choice num 83 / 99 - starting...
415 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 0 1 0]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   5.2s
416 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.667 total time=   5.4s
417 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   4.4s
418 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.42857142857142855 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.429 total time=   4.1s
419 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.6141753671165435
In parameter choice num 83 / 99 avg score was: 0.5463203463203462.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.636 total time=   3.5s
Parameter choice num 84 / 99 - starting...
420 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.667 total time=   3.3s
421 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 1 0 0 0 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.5333333333333333 
>>>
predicted correctly / predicted_in_total = 10 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.533 total time=   3.6s
422 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: precision, score: 0.3076923076923077 
>>>
predicted correctly / predicted_in_total = 4 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.308 total time=   3.6s
423 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.3333333333333333 
>>>
predicted correctly / predicted_in_total = 6 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.333 total time=   3.6s
424 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 1 0]
scoring metric: precision, score: 0.6923076923076923 
>>>
predicted correctly / predicted_in_total = 13 / 22
<<<
Best parameter choice score by now is 0.6141753671165435
In parameter choice num 84 / 99 avg score was: 0.5066666666666666.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.692 total time=   3.5s
Parameter choice num 85 / 99 - starting...
425 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.444 total time=   0.4s
426 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.625 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.625 total time=   0.4s
427 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1]
scoring metric: precision, score: 0.47058823529411764 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.471 total time=   0.4s
428 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 1 0 1 1 1]
scoring metric: precision, score: 0.4 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.400 total time=   0.4s
429 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.6141753671165435
In parameter choice num 85 / 99 avg score was: 0.5152792632204396.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.636 total time=   0.4s
Parameter choice num 86 / 99 - starting...
430 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 1 1]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.636 total time=   0.5s
431 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.667 total time=   0.4s
432 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.500 total time=   0.4s
433 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.444 total time=   0.4s
434 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.6141753671165435
In parameter choice num 86 / 99 avg score was: 0.5828282828282828.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.667 total time=   0.5s
Parameter choice num 87 / 99 - starting...
435 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.444 total time=   1.0s
436 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6428571428571429 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.643 total time=   1.0s
437 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   1.0s
438 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.42857142857142855 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.429 total time=   1.1s
439 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.6141753671165435
In parameter choice num 87 / 99 avg score was: 0.5304473304473304.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.636 total time=   1.0s
Parameter choice num 88 / 99 - starting...
440 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.444 total time=   3.6s
441 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.625 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.625 total time=   4.4s
442 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: precision, score: 0.4375 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.438 total time=   3.5s
443 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.375 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.375 total time=   4.0s
444 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.6141753671165435
In parameter choice num 88 / 99 avg score was: 0.5036616161616162.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.636 total time=   3.5s
Parameter choice num 89 / 99 - starting...
445 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.500 total time=   4.0s
446 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.600 total time=   4.7s
447 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: precision, score: 0.4375 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.438 total time=   4.4s
448 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.375 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.375 total time=   3.9s
449 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 1 0]
scoring metric: precision, score: 0.6923076923076923 
>>>
predicted correctly / predicted_in_total = 13 / 22
<<<
Best parameter choice score by now is 0.6141753671165435
In parameter choice num 89 / 99 avg score was: 0.5209615384615385.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.692 total time=   4.2s
Parameter choice num 90 / 99 - starting...
450 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 1 1 0 0 0 1 1 0 1 0 1 0 1 1]
scoring metric: precision, score: 0.6923076923076923 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.692 total time=   1.8s
451 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.667 total time=   1.9s
452 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.500 total time=   1.3s
453 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.444 total time=   1.1s
454 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.6141753671165435
In parameter choice num 90 / 99 avg score was: 0.5879564879564879.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.636 total time=   1.5s
Parameter choice num 91 / 99 - starting...
455 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.636 total time=   1.3s
456 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.600 total time=   1.1s
457 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: precision, score: 0.35714285714285715 
>>>
predicted correctly / predicted_in_total = 5 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.357 total time=   1.0s
458 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1]
scoring metric: precision, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 6 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.364 total time=   1.0s
459 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0]
scoring metric: precision, score: 0.75 
>>>
predicted correctly / predicted_in_total = 14 / 22
<<<
Best parameter choice score by now is 0.6141753671165435
In parameter choice num 91 / 99 avg score was: 0.5414285714285715.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=100, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.750 total time=   1.0s
Parameter choice num 92 / 99 - starting...
460 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 0 0 0 1 1 0 0 1 1 1 0 1 1 1 0 1 1]
scoring metric: precision, score: 0.7857142857142857 
>>>
predicted correctly / predicted_in_total = 17 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.786 total time=   0.6s
461 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.667 total time=   0.5s
462 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.47058823529411764 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.471 total time=   0.4s
463 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.444 total time=   0.5s
464 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.7272727272727273 
>>>
predicted correctly / predicted_in_total = 13 / 22
<<<
New improvement!
New best score is 0.6189372718784483
In parameter choice num 92 / 99 avg score was: 0.6189372718784483.
updating 2023-08-05 20_16_07_precision_100RF\search_statistics.txt...
statistics file updated successfully with new improvement in score message!
Best parameter choice score by now is 0.6189372718784483
In parameter choice num 92 / 99 avg score was: 0.6189372718784483.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=6, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.727 total time=   0.5s
Parameter choice num 93 / 99 - starting...
465 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.500 total time=   1.2s
466 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6428571428571429 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.643 total time=   1.1s
467 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.47058823529411764 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.471 total time=   1.1s
468 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.444 total time=   1.1s
469 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [0 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.6 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
Best parameter choice score by now is 0.6189372718784483
In parameter choice num 93 / 99 avg score was: 0.531577964519141.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.600 total time=   1.1s
Parameter choice num 94 / 99 - starting...
470 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.444 total time=   5.5s
471 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6428571428571429 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.643 total time=   3.9s
472 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   4.3s
473 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   4.3s
474 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 1 0 1]
scoring metric: precision, score: 0.5833333333333334 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
Best parameter choice score by now is 0.6189372718784483
In parameter choice num 94 / 99 avg score was: 0.5341269841269842.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.583 total time=   3.8s
Parameter choice num 95 / 99 - starting...
475 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.500 total time=   1.1s
476 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6153846153846154 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.615 total time=   1.2s
477 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: precision, score: 0.47058823529411764 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.471 total time=   1.1s
478 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.42857142857142855 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.429 total time=   1.0s
479 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0]
scoring metric: precision, score: 0.6 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
Best parameter choice score by now is 0.6189372718784483
In parameter choice num 95 / 99 avg score was: 0.5229088558500323.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.600 total time=   1.1s
Parameter choice num 96 / 99 - starting...
480 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 1 0 1 0 1 0]
scoring metric: precision, score: 0.4166666666666667 
>>>
predicted correctly / predicted_in_total = 7 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.417 total time=   0.4s
481 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 0 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6923076923076923 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.692 total time=   0.5s
482 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.4375 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.438 total time=   0.4s
483 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   0.4s
484 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 0]
scoring metric: precision, score: 0.6 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
Best parameter choice score by now is 0.6189372718784483
In parameter choice num 96 / 99 avg score was: 0.5292948717948718.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.600 total time=   0.4s
Parameter choice num 97 / 99 - starting...
485 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.500 total time=   1.1s
486 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0]
scoring metric: precision, score: 0.6666666666666666 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.667 total time=   1.1s
487 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.47058823529411764 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.471 total time=   1.3s
488 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.444 total time=   1.1s
489 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.6189372718784483
In parameter choice num 97 / 99 avg score was: 0.5436125965537729.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.636 total time=   1.2s
Parameter choice num 98 / 99 - starting...
490 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.500 total time=   1.0s
491 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6428571428571429 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.643 total time=   1.0s
492 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: precision, score: 0.47058823529411764 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.471 total time=   1.0s
493 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: precision, score: 0.4444444444444444 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.444 total time=   1.3s
494 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [0 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.6 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
Best parameter choice score by now is 0.6189372718784483
In parameter choice num 98 / 99 avg score was: 0.531577964519141.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.600 total time=   1.0s
Parameter choice num 99 / 99 - starting...
495 / 499 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 1 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: precision, score: 0.5 
>>>
predicted correctly / predicted_in_total = 9 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   0.4s
496 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: precision, score: 0.6428571428571429 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.643 total time=   0.4s
497 / 499 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1]
scoring metric: precision, score: 0.47058823529411764 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.471 total time=   0.4s
498 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1]
scoring metric: precision, score: 0.5714285714285714 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.571 total time=   0.4s
499 / 499 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 1 0 1]
scoring metric: precision, score: 0.5833333333333334 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
Best parameter choice score by now is 0.6189372718784483
In parameter choice num 99 / 99 avg score was: 0.5536414565826331.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=3, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.583 total time=   0.4s
* Confusion matrix: 
 [[1613 2787]
 [3382 3418]]
[[TN FP
[FN TP]]
* CV Precision:  0.5508460918614021
* CV Recall:  0.5026470588235294
* CV Accuracy:  0.44919642857142855
* CV F1:  0.5256439830834294
-----------------------
 End of CV report 
----------------------- 



-----------------------
 New CV report 
-----------------------
* Classifier: 
 RandomForestClassifier(max_depth=6, max_features='log2', min_samples_leaf=2,
                       min_samples_split=5, n_jobs=-1, random_state=42)
* User arguments: 
 {'rs': 42, 'X_version': 1, 'split_rows': 'normal', 'drop_out_correlated': False, 'age_under_50': False, 'debug': False, 'exhaustive_grid_search': False, 'classification_type': 'normal', 'scoring_method': 'precision', 'both': True, 'cv': 5, 'n_iter': 100, 'n_jobs': 1, 'use_gamma_columns': True, 'classification': True, 'lite_mode': True, 'test_size': 0.15, 'stdout_to_file': True, 'significant': False, 'output_folder_label': '_precision_100RF'}
* Pipeline details: 
 Pipeline(steps=[('scaler', StandardScaler()),
                ('smote', SMOTE(random_state=42, sampling_strategy='minority')),
                ('kBest', SelectKBest()),
                ('classifier',
                 RandomForestClassifier(max_depth=6, max_features='log2',
                                        min_samples_leaf=2, min_samples_split=5,
                                        n_jobs=-1, random_state=42))])
* Best Hyperparametes picked in cross validation: (cv's best score): 
 {'kBest__k': 300, 'classifier__n_jobs': -1, 'classifier__n_estimators': 100, 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 2, 'classifier__max_features': 'log2', 'classifier__max_depth': 6, 'classifier': RandomForestClassifier(max_depth=6, max_features='log2', min_samples_leaf=2,
                       min_samples_split=5, n_jobs=-1, random_state=42)}
* Best features by (selectKbest): 
 ['Ratio_Relative_Power_Norm_Beta1 Over Beta2_AF3', 'Ratio_Relative_Power_Norm_Beta1 Over Beta2_AF4', 'Ratio_Relative_Power_Norm_Beta1 Over Beta2_AF7', 'Ratio_Relative_Power_Norm_Beta1 Over Beta2_AF8', 'Ratio_Relative_Power_Norm_Beta1 Over Beta2_AFz', 'Ratio_Relative_Power_Norm_Beta1 Over Beta2_C3', 'Ratio_Relative_Power_Norm_Beta1 Over Beta2_C5', 'Ratio_Relative_Power_Norm_Beta1 Over Beta2_F1', 'Ratio_Relative_Power_Norm_Beta1 Over Beta2_F2', 'Ratio_Relative_Power_Norm_Beta1 Over Beta2_F3', 'Ratio_Relative_Power_Norm_Beta1 Over Beta2_F4', 'Ratio_Relative_Power_Norm_Beta1 Over Beta2_F5', 'Ratio_Relative_Power_Norm_Beta1 Over Beta2_F6', 'Ratio_Relative_Power_Norm_Beta1 Over Beta2_F7', 'Ratio_Relative_Power_Norm_Beta1 Over Beta2_F8', 'Ratio_Relative_Power_Norm_Beta1 Over Beta2_FC3', 'Ratio_Relative_Power_Norm_Beta1 Over Beta2_FC4', 'Ratio_Relative_Power_Norm_Beta1 Over Beta2_FC5', 'Ratio_Relative_Power_Norm_Beta1 Over Beta2_FC6', 'Ratio_Relative_Power_Norm_Beta1 Over Beta2_FT7', 'Ratio_Relative_Power_Norm_Beta1 Over Beta2_Fp1', 'Ratio_Relative_Power_Norm_Beta1 Over Beta2_Fp2', 'Ratio_Relative_Power_Norm_Beta1 Over Beta2_Fpz', 'Ratio_Relative_Power_Norm_Beta1 Over Beta2_Fz', 'Ratio_Relative_Power_Norm_Delta Over Alpha_C5', 'Ratio_Relative_Power_Norm_Delta Over Alpha_F1', 'Ratio_Relative_Power_Norm_Delta Over Alpha_F4', 'Ratio_Relative_Power_Norm_Delta Over Alpha_F5', 'Ratio_Relative_Power_Norm_Delta Over Alpha_F6', 'Ratio_Relative_Power_Norm_Delta Over Alpha_F8', 'Ratio_Relative_Power_Norm_Delta Over Alpha_FC1', 'Ratio_Relative_Power_Norm_Delta Over Alpha_FC3', 'Ratio_Relative_Power_Norm_Delta Over Alpha_FC5', 'Ratio_Relative_Power_Norm_Delta Over Alpha_FC6', 'Ratio_Relative_Power_Norm_Delta Over Alpha_FT7', 'Ratio_Relative_Power_Norm_Delta Over Alpha_FT8', 'Ratio_Relative_Power_Norm_Delta Over Alpha_P10', 'Ratio_Relative_Power_Norm_Delta Over Alpha_P8', 'Ratio_Relative_Power_Norm_Delta Over Alpha_T7', 'Ratio_Relative_Power_Norm_Delta Over Alpha_T8', 'Ratio_Relative_Power_Norm_Delta Over Alpha_TP8', 'Ratio_Relative_Power_Norm_Delta Over Beta1_AF3', 'Ratio_Relative_Power_Norm_Delta Over Beta1_AF4', 'Ratio_Relative_Power_Norm_Delta Over Beta1_AFz', 'Ratio_Relative_Power_Norm_Delta Over Beta1_C1', 'Ratio_Relative_Power_Norm_Delta Over Beta1_C2', 'Ratio_Relative_Power_Norm_Delta Over Beta1_C3', 'Ratio_Relative_Power_Norm_Delta Over Beta1_C4', 'Ratio_Relative_Power_Norm_Delta Over Beta1_C5', 'Ratio_Relative_Power_Norm_Delta Over Beta1_C6', 'Ratio_Relative_Power_Norm_Delta Over Beta1_CP1', 'Ratio_Relative_Power_Norm_Delta Over Beta1_CP2', 'Ratio_Relative_Power_Norm_Delta Over Beta1_CP3', 'Ratio_Relative_Power_Norm_Delta Over Beta1_CP4', 'Ratio_Relative_Power_Norm_Delta Over Beta1_CP5', 'Ratio_Relative_Power_Norm_Delta Over Beta1_CP6', 'Ratio_Relative_Power_Norm_Delta Over Beta1_CPz', 'Ratio_Relative_Power_Norm_Delta Over Beta1_Cz', 'Ratio_Relative_Power_Norm_Delta Over Beta1_F1', 'Ratio_Relative_Power_Norm_Delta Over Beta1_F2', 'Ratio_Relative_Power_Norm_Delta Over Beta1_F3', 'Ratio_Relative_Power_Norm_Delta Over Beta1_F4', 'Ratio_Relative_Power_Norm_Delta Over Beta1_F5', 'Ratio_Relative_Power_Norm_Delta Over Beta1_F6', 'Ratio_Relative_Power_Norm_Delta Over Beta1_F8', 'Ratio_Relative_Power_Norm_Delta Over Beta1_FC1', 'Ratio_Relative_Power_Norm_Delta Over Beta1_FC2', 'Ratio_Relative_Power_Norm_Delta Over Beta1_FC3', 'Ratio_Relative_Power_Norm_Delta Over Beta1_FC4', 'Ratio_Relative_Power_Norm_Delta Over Beta1_FC5', 'Ratio_Relative_Power_Norm_Delta Over Beta1_FC6', 'Ratio_Relative_Power_Norm_Delta Over Beta1_FCz', 'Ratio_Relative_Power_Norm_Delta Over Beta1_FT8', 'Ratio_Relative_Power_Norm_Delta Over Beta1_Fz', 'Ratio_Relative_Power_Norm_Delta Over Beta1_Iz', 'Ratio_Relative_Power_Norm_Delta Over Beta1_O1', 'Ratio_Relative_Power_Norm_Delta Over Beta1_O2', 'Ratio_Relative_Power_Norm_Delta Over Beta1_Oz', 'Ratio_Relative_Power_Norm_Delta Over Beta1_P1', 'Ratio_Relative_Power_Norm_Delta Over Beta1_P10', 'Ratio_Relative_Power_Norm_Delta Over Beta1_P2', 'Ratio_Relative_Power_Norm_Delta Over Beta1_P3', 'Ratio_Relative_Power_Norm_Delta Over Beta1_P4', 'Ratio_Relative_Power_Norm_Delta Over Beta1_P5', 'Ratio_Relative_Power_Norm_Delta Over Beta1_P6', 'Ratio_Relative_Power_Norm_Delta Over Beta1_P7', 'Ratio_Relative_Power_Norm_Delta Over Beta1_P8', 'Ratio_Relative_Power_Norm_Delta Over Beta1_P9', 'Ratio_Relative_Power_Norm_Delta Over Beta1_PO3', 'Ratio_Relative_Power_Norm_Delta Over Beta1_PO4', 'Ratio_Relative_Power_Norm_Delta Over Beta1_PO7', 'Ratio_Relative_Power_Norm_Delta Over Beta1_PO8', 'Ratio_Relative_Power_Norm_Delta Over Beta1_POz', 'Ratio_Relative_Power_Norm_Delta Over Beta1_Pz', 'Ratio_Relative_Power_Norm_Delta Over Beta1_T7', 'Ratio_Relative_Power_Norm_Delta Over Beta1_T8', 'Ratio_Relative_Power_Norm_Delta Over Beta1_TP7', 'Ratio_Relative_Power_Norm_Delta Over Beta1_TP8', 'Ratio_Relative_Power_Norm_Delta Over Beta2_C1', 'Ratio_Relative_Power_Norm_Delta Over Beta2_C2', 'Ratio_Relative_Power_Norm_Delta Over Beta2_C3', 'Ratio_Relative_Power_Norm_Delta Over Beta2_C4', 'Ratio_Relative_Power_Norm_Delta Over Beta2_C5', 'Ratio_Relative_Power_Norm_Delta Over Beta2_C6', 'Ratio_Relative_Power_Norm_Delta Over Beta2_CP1', 'Ratio_Relative_Power_Norm_Delta Over Beta2_CP2', 'Ratio_Relative_Power_Norm_Delta Over Beta2_CP3', 'Ratio_Relative_Power_Norm_Delta Over Beta2_CP4', 'Ratio_Relative_Power_Norm_Delta Over Beta2_CP5', 'Ratio_Relative_Power_Norm_Delta Over Beta2_CP6', 'Ratio_Relative_Power_Norm_Delta Over Beta2_CPz', 'Ratio_Relative_Power_Norm_Delta Over Beta2_Cz', 'Ratio_Relative_Power_Norm_Delta Over Beta2_F4', 'Ratio_Relative_Power_Norm_Delta Over Beta2_FC1', 'Ratio_Relative_Power_Norm_Delta Over Beta2_FC2', 'Ratio_Relative_Power_Norm_Delta Over Beta2_FC4', 'Ratio_Relative_Power_Norm_Delta Over Beta2_FCz', 'Ratio_Relative_Power_Norm_Delta Over Beta2_FT8', 'Ratio_Relative_Power_Norm_Delta Over Beta2_Iz', 'Ratio_Relative_Power_Norm_Delta Over Beta2_O1', 'Ratio_Relative_Power_Norm_Delta Over Beta2_O2', 'Ratio_Relative_Power_Norm_Delta Over Beta2_Oz', 'Ratio_Relative_Power_Norm_Delta Over Beta2_P1', 'Ratio_Relative_Power_Norm_Delta Over Beta2_P10', 'Ratio_Relative_Power_Norm_Delta Over Beta2_P2', 'Ratio_Relative_Power_Norm_Delta Over Beta2_P3', 'Ratio_Relative_Power_Norm_Delta Over Beta2_P4', 'Ratio_Relative_Power_Norm_Delta Over Beta2_P5', 'Ratio_Relative_Power_Norm_Delta Over Beta2_P6', 'Ratio_Relative_Power_Norm_Delta Over Beta2_P7', 'Ratio_Relative_Power_Norm_Delta Over Beta2_P8', 'Ratio_Relative_Power_Norm_Delta Over Beta2_P9', 'Ratio_Relative_Power_Norm_Delta Over Beta2_PO3', 'Ratio_Relative_Power_Norm_Delta Over Beta2_PO4', 'Ratio_Relative_Power_Norm_Delta Over Beta2_PO7', 'Ratio_Relative_Power_Norm_Delta Over Beta2_PO8', 'Ratio_Relative_Power_Norm_Delta Over Beta2_POz', 'Ratio_Relative_Power_Norm_Delta Over Beta2_Pz', 'Ratio_Relative_Power_Norm_Delta Over Beta2_T7', 'Ratio_Relative_Power_Norm_Delta Over Beta2_T8', 'Ratio_Relative_Power_Norm_Delta Over Beta2_TP7', 'Ratio_Relative_Power_Norm_Delta Over Beta2_TP8', 'Ratio_Relative_Power_Norm_Theta Over Alpha_AF3', 'Ratio_Relative_Power_Norm_Theta Over Alpha_AF4', 'Ratio_Relative_Power_Norm_Theta Over Alpha_AF7', 'Ratio_Relative_Power_Norm_Theta Over Alpha_AF8', 'Ratio_Relative_Power_Norm_Theta Over Alpha_AFz', 'Ratio_Relative_Power_Norm_Theta Over Alpha_C1', 'Ratio_Relative_Power_Norm_Theta Over Alpha_C2', 'Ratio_Relative_Power_Norm_Theta Over Alpha_C3', 'Ratio_Relative_Power_Norm_Theta Over Alpha_C5', 'Ratio_Relative_Power_Norm_Theta Over Alpha_CPz', 'Ratio_Relative_Power_Norm_Theta Over Alpha_Cz', 'Ratio_Relative_Power_Norm_Theta Over Alpha_F1', 'Ratio_Relative_Power_Norm_Theta Over Alpha_F2', 'Ratio_Relative_Power_Norm_Theta Over Alpha_F3', 'Ratio_Relative_Power_Norm_Theta Over Alpha_F4', 'Ratio_Relative_Power_Norm_Theta Over Alpha_F5', 'Ratio_Relative_Power_Norm_Theta Over Alpha_F6', 'Ratio_Relative_Power_Norm_Theta Over Alpha_F7', 'Ratio_Relative_Power_Norm_Theta Over Alpha_F8', 'Ratio_Relative_Power_Norm_Theta Over Alpha_FC1', 'Ratio_Relative_Power_Norm_Theta Over Alpha_FC2', 'Ratio_Relative_Power_Norm_Theta Over Alpha_FC3', 'Ratio_Relative_Power_Norm_Theta Over Alpha_FC4', 'Ratio_Relative_Power_Norm_Theta Over Alpha_FC5', 'Ratio_Relative_Power_Norm_Theta Over Alpha_FC6', 'Ratio_Relative_Power_Norm_Theta Over Alpha_FCz', 'Ratio_Relative_Power_Norm_Theta Over Alpha_FT7', 'Ratio_Relative_Power_Norm_Theta Over Alpha_FT8', 'Ratio_Relative_Power_Norm_Theta Over Alpha_Fp1', 'Ratio_Relative_Power_Norm_Theta Over Alpha_Fp2', 'Ratio_Relative_Power_Norm_Theta Over Alpha_Fpz', 'Ratio_Relative_Power_Norm_Theta Over Alpha_Fz', 'Ratio_Relative_Power_Norm_Theta Over Alpha_P1', 'Ratio_Relative_Power_Norm_Theta Over Alpha_P3', 'Ratio_Relative_Power_Norm_Theta Over Alpha_P5', 'Ratio_Relative_Power_Norm_Theta Over Alpha_PO3', 'Ratio_Relative_Power_Norm_Theta Over Alpha_PO7', 'Ratio_Relative_Power_Norm_Theta Over Alpha_POz', 'Ratio_Relative_Power_Norm_Theta Over Alpha_Pz', 'Ratio_Relative_Power_Norm_Theta Over Alpha_T7', 'Ratio_Relative_Power_Norm_Theta Over Alpha_T8', 'Ratio_Relative_Power_Norm_Theta Over Alpha_TP7', 'Ratio_Relative_Power_Norm_Theta Over Beta1_AFz', 'Ratio_Relative_Power_Norm_Theta Over Beta1_C1', 'Ratio_Relative_Power_Norm_Theta Over Beta1_Cz', 'Ratio_Relative_Power_Norm_Theta Over Beta1_F1', 'Ratio_Relative_Power_Norm_Theta Over Beta1_F2', 'Ratio_Relative_Power_Norm_Theta Over Beta1_F3', 'Ratio_Relative_Power_Norm_Theta Over Beta1_F4', 'Ratio_Relative_Power_Norm_Theta Over Beta1_FC1', 'Ratio_Relative_Power_Norm_Theta Over Beta1_FCz', 'Ratio_Relative_Power_Norm_Theta Over Beta1_Fz', 'Ratio_Relative_Power_Norm_Theta Over Beta1_Iz', 'Ratio_Relative_Power_Norm_Theta Over Beta1_O1', 'Ratio_Relative_Power_Norm_Theta Over Beta1_O2', 'Ratio_Relative_Power_Norm_Theta Over Beta1_Oz', 'Ratio_Relative_Power_Norm_Theta Over Beta1_P2', 'Ratio_Relative_Power_Norm_Theta Over Beta1_P4', 'Ratio_Relative_Power_Norm_Theta Over Beta1_P5', 'Ratio_Relative_Power_Norm_Theta Over Beta1_P6', 'Ratio_Relative_Power_Norm_Theta Over Beta1_P7', 'Ratio_Relative_Power_Norm_Theta Over Beta1_P9', 'Ratio_Relative_Power_Norm_Theta Over Beta1_PO3', 'Ratio_Relative_Power_Norm_Theta Over Beta1_PO4', 'Ratio_Relative_Power_Norm_Theta Over Beta1_PO7', 'Ratio_Relative_Power_Norm_Theta Over Beta1_PO8', 'Ratio_Relative_Power_Norm_Theta Over Beta1_POz', 'Ratio_Relative_Power_Norm_Theta Over Beta1_T8', 'Ratio_Relative_Power_Norm_Theta Over Beta1_TP7', 'Single_Mean_Power_Abs_Delta_C2', 'Single_Mean_Power_Abs_Delta_C3', 'Single_Mean_Power_Abs_Delta_C4', 'Single_Mean_Power_Abs_Delta_C5', 'Single_Mean_Power_Abs_Delta_CP1', 'Single_Mean_Power_Abs_Delta_CP2', 'Single_Mean_Power_Abs_Delta_CP3', 'Single_Mean_Power_Abs_Delta_CP4', 'Single_Mean_Power_Abs_Delta_CP5', 'Single_Mean_Power_Abs_Delta_CP6', 'Single_Mean_Power_Abs_Delta_CPz', 'Single_Mean_Power_Abs_Delta_Iz', 'Single_Mean_Power_Abs_Delta_Oz', 'Single_Mean_Power_Abs_Delta_P1', 'Single_Mean_Power_Abs_Delta_P2', 'Single_Mean_Power_Abs_Delta_P3', 'Single_Mean_Power_Abs_Delta_P5', 'Single_Mean_Power_Abs_Delta_PO3', 'Single_Mean_Power_Abs_Delta_POz', 'Single_Mean_Power_Abs_Delta_Pz', 'Single_Relative_Power_Norm_Beta1_AFz', 'Single_Relative_Power_Norm_Beta1_C1', 'Single_Relative_Power_Norm_Beta1_C2', 'Single_Relative_Power_Norm_Beta1_C3', 'Single_Relative_Power_Norm_Beta1_C4', 'Single_Relative_Power_Norm_Beta1_C6', 'Single_Relative_Power_Norm_Beta1_CP1', 'Single_Relative_Power_Norm_Beta1_CP2', 'Single_Relative_Power_Norm_Beta1_CP3', 'Single_Relative_Power_Norm_Beta1_CP4', 'Single_Relative_Power_Norm_Beta1_CP5', 'Single_Relative_Power_Norm_Beta1_CP6', 'Single_Relative_Power_Norm_Beta1_CPz', 'Single_Relative_Power_Norm_Beta1_Cz', 'Single_Relative_Power_Norm_Beta1_F2', 'Single_Relative_Power_Norm_Beta1_F4', 'Single_Relative_Power_Norm_Beta1_F6', 'Single_Relative_Power_Norm_Beta1_FC2', 'Single_Relative_Power_Norm_Beta1_FC4', 'Single_Relative_Power_Norm_Beta1_FC6', 'Single_Relative_Power_Norm_Beta1_FCz', 'Single_Relative_Power_Norm_Beta1_FT8', 'Single_Relative_Power_Norm_Beta1_Fz', 'Single_Relative_Power_Norm_Beta1_P1', 'Single_Relative_Power_Norm_Beta1_P10', 'Single_Relative_Power_Norm_Beta1_P7', 'Single_Relative_Power_Norm_Beta1_P8', 'Single_Relative_Power_Norm_Beta1_P9', 'Single_Relative_Power_Norm_Beta1_T8', 'Single_Relative_Power_Norm_Beta1_TP8', 'Single_Relative_Power_Norm_Delta_C1', 'Single_Relative_Power_Norm_Delta_C2', 'Single_Relative_Power_Norm_Delta_C4', 'Single_Relative_Power_Norm_Delta_CP1', 'Single_Relative_Power_Norm_Delta_CP2', 'Single_Relative_Power_Norm_Delta_CP3', 'Single_Relative_Power_Norm_Delta_CP4', 'Single_Relative_Power_Norm_Delta_CP5', 'Single_Relative_Power_Norm_Delta_CP6', 'Single_Relative_Power_Norm_Delta_CPz', 'Single_Relative_Power_Norm_Delta_Cz', 'Single_Relative_Power_Norm_Delta_F4', 'Single_Relative_Power_Norm_Delta_FC1', 'Single_Relative_Power_Norm_Delta_FC6', 'Single_Relative_Power_Norm_Delta_FCz', 'Single_Relative_Power_Norm_Delta_FT8', 'Single_Relative_Power_Norm_Delta_Iz', 'Single_Relative_Power_Norm_Delta_O1', 'Single_Relative_Power_Norm_Delta_O2', 'Single_Relative_Power_Norm_Delta_Oz', 'Single_Relative_Power_Norm_Delta_P1', 'Single_Relative_Power_Norm_Delta_P10', 'Single_Relative_Power_Norm_Delta_P2', 'Single_Relative_Power_Norm_Delta_P3', 'Single_Relative_Power_Norm_Delta_P5', 'Single_Relative_Power_Norm_Delta_P6', 'Single_Relative_Power_Norm_Delta_P7', 'Single_Relative_Power_Norm_Delta_P8', 'Single_Relative_Power_Norm_Delta_P9', 'Single_Relative_Power_Norm_Delta_PO3', 'Single_Relative_Power_Norm_Delta_PO4', 'Single_Relative_Power_Norm_Delta_PO7', 'Single_Relative_Power_Norm_Delta_PO8', 'Single_Relative_Power_Norm_Delta_POz', 'Single_Relative_Power_Norm_Delta_Pz', 'Single_Relative_Power_Norm_Delta_T7', 'Single_Relative_Power_Norm_Delta_T8', 'Single_Relative_Power_Norm_Delta_TP7', 'Single_Relative_Power_Norm_Delta_TP8']
* Scorer_used: precision
* CV mean_test_score precision ( over 5 folds - (cv's best score for best hyperparametes): 0.619 +/- 0.137 (see score func in hyperparams)  

* Confusion matrix: 
 [[44  0]
 [ 0 68]]
[[TN FP
[FN TP]]
* Response rate:  0.6071428571428571
* CV Precision:  1.0
* CV Recall:  1.0
* CV Accuracy:  1.0
* CV F1:  1.0
train CV report saved to   2023-08-05 20_16_07_precision_100RF\tuning.csv
-----------------------
 End of CV report 
----------------------- 



* Confusion matrix: 
 [[1 7]
 [6 6]]
[[TN FP
[FN TP]]
* CV Precision:  0.46153846153846156
* CV Recall:  0.5
* CV Accuracy:  0.35
* CV F1:  0.48000000000000004
-----------------------
 End of CV report 
----------------------- 



<<<<<<<<<<<<<<<<<<<<< GSCVrunner.py finished successfuly<<<<<<<<<<<<<<<<<<<<<
