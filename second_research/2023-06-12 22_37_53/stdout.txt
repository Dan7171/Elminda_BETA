configs types debug
[<class 'pandas.core.frame.DataFrame'>, <class 'pandas.core.frame.DataFrame'>, <class 'pandas.core.frame.DataFrame'>, <class 'pandas.core.frame.DataFrame'>]
**************************************************
Distribution of categorial variables in data:**************************************************
Gender:
X['gender'].value_counts(): 0    78
1    54
Name: gender, dtype: int64
X_train['gender'].value_counts():
0    67
1    45
Name: gender, dtype: int64
X_test['gender'].value_counts():
0    11
1     9
Name: gender, dtype: int64

**************************************************
Treatment_group (coil):
X['Treatment_group'].value_counts(): 0    75
1    57
Name: Treatment_group, dtype: int64
X_train['Treatment_group'].value_counts():
0    65
1    47
Name: Treatment_group, dtype: int64
X_test['Treatment_group'].value_counts():
1    10
0    10
Name: Treatment_group, dtype: int64
Response to treatment:

**************************************************
['6-weeks_HDRS21_class'].value_counts():
1    80
0    52
Name: 6-weeks_HDRS21_class, dtype: int64
y_train['6-weeks_HDRS21_class'].value_counts():
1    68
0    44
Name: 6-weeks_HDRS21_class, dtype: int64
y_test['6-weeks_HDRS21_class'].value_counts():
1    12
0     8
Name: 6-weeks_HDRS21_class, dtype: int64

~~~~~~~~~~ RANDOMIZED SEARCH CV ~~~~~~~~~~
Fitting 5 folds for each of 1000 candidates, totalling 5000 fits
Parameter choice num 0 / 999 - starting...
0 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
New improvement!
New best score is 0.6588315879312682
In parameter choice num 0 / 999 avg score was: 0.6588315879312682. This is the best score so far
updating 2023-06-12 22_37_53\search_statistics.txt...
statistics file updated successfully with new improvement in score message!
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 0 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 1 / 999 - starting...
5 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
6 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
7 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
8 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
9 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 1 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 2 / 999 - starting...
10 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.4s
11 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.4s
12 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.4s
13 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.4s
14 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 2 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.686 total time=   0.4s
Parameter choice num 3 / 999 - starting...
15 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.5s
16 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.4s
17 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.5s
18 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.5s
19 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 3 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.686 total time=   0.5s
Parameter choice num 4 / 999 - starting...
20 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.0s
21 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.0s
22 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.0s
23 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.0s
24 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 4 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 5 / 999 - starting...
25 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
26 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
27 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
28 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
29 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 5 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 6 / 999 - starting...
30 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
31 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
32 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
33 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
34 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 6 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.686 total time=   0.1s
Parameter choice num 7 / 999 - starting...
35 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
36 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
37 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
38 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
39 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 7 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 8 / 999 - starting...
40 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
41 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
42 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
43 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
44 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 8 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 9 / 999 - starting...
45 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
46 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
47 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
48 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
49 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 9 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 10 / 999 - starting...
50 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.0s
51 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.0s
52 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.0s
53 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.0s
54 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 10 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 11 / 999 - starting...
55 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.3s
56 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.3s
57 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.3s
58 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.3s
59 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 11 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.686 total time=   0.3s
Parameter choice num 12 / 999 - starting...
60 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.0s
61 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.0s
62 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.0s
63 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.0s
64 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 12 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 13 / 999 - starting...
65 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.0s
66 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.0s
67 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.0s
68 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.0s
69 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 13 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 14 / 999 - starting...
70 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
71 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
72 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
73 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
74 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 14 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 15 / 999 - starting...
75 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.0s
76 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.0s
77 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.0s
78 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.0s
79 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 15 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 16 / 999 - starting...
80 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
81 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
82 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
83 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
84 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 16 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 17 / 999 - starting...
85 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
86 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
87 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
88 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
89 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 17 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 18 / 999 - starting...
90 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.3s
91 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.3s
92 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.4s
93 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.3s
94 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 18 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.686 total time=   0.3s
Parameter choice num 19 / 999 - starting...
95 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
96 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
97 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
98 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
99 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 19 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 20 / 999 - starting...
100 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
101 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
102 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
103 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
104 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 20 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 21 / 999 - starting...
105 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.4s
106 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.4s
107 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.4s
108 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.4s
109 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 21 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.686 total time=   0.4s
Parameter choice num 22 / 999 - starting...
110 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.3s
111 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.3s
112 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.3s
113 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.3s
114 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 22 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.686 total time=   0.3s
Parameter choice num 23 / 999 - starting...
115 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=70, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
116 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=70, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
117 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=70, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
118 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=70, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
119 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 23 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=70, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 24 / 999 - starting...
120 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=78, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
121 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=78, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
122 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=78, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
123 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=78, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
124 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 24 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=78, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 25 / 999 - starting...
125 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
126 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
127 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
128 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
129 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 25 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 26 / 999 - starting...
130 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
131 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
132 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
133 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
134 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 26 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 27 / 999 - starting...
135 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
136 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
137 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
138 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
139 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 27 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 28 / 999 - starting...
140 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.0s
141 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.0s
142 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.0s
143 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.0s
144 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 28 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 29 / 999 - starting...
145 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.0s
146 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.0s
147 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.0s
148 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.0s
149 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 29 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 30 / 999 - starting...
150 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
151 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
152 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
153 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
154 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 30 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.3s
Parameter choice num 31 / 999 - starting...
155 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
156 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
157 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
158 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
159 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 31 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 32 / 999 - starting...
160 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
161 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
162 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
163 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
164 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 32 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 33 / 999 - starting...
165 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.0s
166 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.0s
167 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.0s
168 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.0s
169 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 33 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 34 / 999 - starting...
170 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
171 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
172 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
173 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
174 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 34 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 35 / 999 - starting...
175 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.0s
176 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.0s
177 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.0s
178 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.0s
179 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 35 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 36 / 999 - starting...
180 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.0s
181 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.0s
182 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.0s
183 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.0s
184 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 36 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 37 / 999 - starting...
185 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.0s
186 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.0s
187 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.0s
188 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.0s
189 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 37 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 38 / 999 - starting...
190 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
191 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
192 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
193 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
194 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 38 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 39 / 999 - starting...
195 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
196 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
197 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
198 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
199 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 39 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 40 / 999 - starting...
200 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.0s
201 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.0s
202 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.0s
203 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.0s
204 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 40 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 41 / 999 - starting...
205 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
206 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
207 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
208 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
209 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 41 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 42 / 999 - starting...
210 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.0s
211 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.0s
212 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.0s
213 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.0s
214 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 42 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 43 / 999 - starting...
215 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
216 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
217 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
218 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
219 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 43 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 44 / 999 - starting...
220 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
221 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
222 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
223 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
224 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 44 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.3s
Parameter choice num 45 / 999 - starting...
225 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
226 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
227 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
228 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
229 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 45 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 46 / 999 - starting...
230 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.0s
231 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.0s
232 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.0s
233 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.0s
234 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 46 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 47 / 999 - starting...
235 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.0s
236 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.0s
237 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.0s
238 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.0s
239 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 47 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 48 / 999 - starting...
240 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.0s
241 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.0s
242 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.0s
243 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.0s
244 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 48 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 49 / 999 - starting...
245 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.0s
246 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.0s
247 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.0s
248 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.0s
249 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 49 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 50 / 999 - starting...
250 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
251 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
252 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
253 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
254 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 50 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 51 / 999 - starting...
255 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.0s
256 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.0s
257 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.0s
258 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.0s
259 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 51 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 52 / 999 - starting...
260 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
261 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
262 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
263 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
264 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 52 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 53 / 999 - starting...
265 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
266 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
267 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
268 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
269 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 53 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 54 / 999 - starting...
270 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.0s
271 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.0s
272 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.0s
273 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.0s
274 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 54 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 55 / 999 - starting...
275 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
276 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
277 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
278 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
279 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 55 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 56 / 999 - starting...
280 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
281 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
282 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
283 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
284 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 56 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 57 / 999 - starting...
285 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
286 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
287 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
288 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
289 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 57 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 58 / 999 - starting...
290 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
291 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
292 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
293 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
294 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 58 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 59 / 999 - starting...
295 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
296 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
297 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
298 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
299 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 59 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 60 / 999 - starting...
300 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
301 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
302 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
303 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
304 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 60 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 61 / 999 - starting...
305 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
306 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
307 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
308 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
309 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 61 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 62 / 999 - starting...
310 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=74, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
311 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=74, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
312 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=74, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
313 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=74, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
314 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 62 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=74, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 63 / 999 - starting...
315 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.0s
316 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.0s
317 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.0s
318 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.0s
319 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 63 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 64 / 999 - starting...
320 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
321 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
322 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
323 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
324 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 64 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 65 / 999 - starting...
325 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=94, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.0s
326 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=94, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.0s
327 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=94, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.0s
328 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=94, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.0s
329 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 65 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=94, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 66 / 999 - starting...
330 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=74, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.0s
331 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=74, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.0s
332 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=74, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.0s
333 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=74, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.0s
334 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 66 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=74, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 67 / 999 - starting...
335 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.1s
336 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.1s
337 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.1s
338 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.1s
339 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 67 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.686 total time=   0.1s
Parameter choice num 68 / 999 - starting...
340 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
341 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
342 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
343 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
344 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 68 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 69 / 999 - starting...
345 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.3s
346 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.3s
347 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.3s
348 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.3s
349 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 69 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.686 total time=   0.3s
Parameter choice num 70 / 999 - starting...
350 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.0s
351 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.0s
352 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.0s
353 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.0s
354 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 70 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 71 / 999 - starting...
355 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
356 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
357 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
358 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
359 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 71 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 72 / 999 - starting...
360 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
361 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
362 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
363 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
364 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 72 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 73 / 999 - starting...
365 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.5s
366 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.5s
367 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.5s
368 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.5s
369 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 73 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.686 total time=   0.5s
Parameter choice num 74 / 999 - starting...
370 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.0s
371 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.0s
372 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.0s
373 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.0s
374 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 74 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 75 / 999 - starting...
375 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.0s
376 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.0s
377 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.0s
378 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.0s
379 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 75 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 76 / 999 - starting...
380 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.0s
381 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.0s
382 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.0s
383 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.0s
384 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 76 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 77 / 999 - starting...
385 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
386 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
387 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
388 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
389 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 77 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 78 / 999 - starting...
390 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.2s
391 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.2s
392 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.2s
393 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.2s
394 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 78 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.686 total time=   0.2s
Parameter choice num 79 / 999 - starting...
395 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
396 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
397 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
398 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
399 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 79 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 80 / 999 - starting...
400 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
401 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
402 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
403 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
404 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 80 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 81 / 999 - starting...
405 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
406 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
407 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
408 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
409 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 81 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 82 / 999 - starting...
410 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.0s
411 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.0s
412 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.0s
413 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.0s
414 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 82 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 83 / 999 - starting...
415 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.0s
416 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.0s
417 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.0s
418 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.0s
419 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 83 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 84 / 999 - starting...
420 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
421 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
422 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
423 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
424 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 84 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 85 / 999 - starting...
425 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
426 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
427 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
428 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
429 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 85 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 86 / 999 - starting...
430 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.1s
431 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.1s
432 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.1s
433 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.1s
434 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 86 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.686 total time=   0.1s
Parameter choice num 87 / 999 - starting...
435 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=78, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.1s
436 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=78, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.1s
437 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=78, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.1s
438 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=78, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.1s
439 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 87 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=78, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.686 total time=   0.1s
Parameter choice num 88 / 999 - starting...
440 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.0s
441 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.0s
442 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.0s
443 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.0s
444 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 88 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 89 / 999 - starting...
445 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
446 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
447 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
448 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
449 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 89 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.686 total time=   0.1s
Parameter choice num 90 / 999 - starting...
450 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.2s
451 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.2s
452 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.2s
453 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.2s
454 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 90 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.686 total time=   0.2s
Parameter choice num 91 / 999 - starting...
455 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
456 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
457 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
458 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
459 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 91 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 92 / 999 - starting...
460 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
461 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
462 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
463 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
464 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 92 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 93 / 999 - starting...
465 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.0s
466 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.0s
467 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.0s
468 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.0s
469 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 93 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 94 / 999 - starting...
470 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.5s
471 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.5s
472 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.6s
473 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.5s
474 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 94 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.686 total time=   0.5s
Parameter choice num 95 / 999 - starting...
475 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
476 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
477 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
478 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
479 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 95 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 96 / 999 - starting...
480 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
481 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
482 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
483 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
484 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 96 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 97 / 999 - starting...
485 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
486 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
487 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
488 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
489 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 97 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 98 / 999 - starting...
490 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
491 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
492 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
493 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
494 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 98 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 99 / 999 - starting...
495 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.4s
496 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.4s
497 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.4s
498 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.4s
499 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 99 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.686 total time=   0.5s
Parameter choice num 100 / 999 - starting...
500 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.0s
501 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.0s
502 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.0s
503 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.0s
504 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 100 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 101 / 999 - starting...
505 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
506 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
507 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
508 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
509 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 101 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 102 / 999 - starting...
510 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
511 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
512 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
513 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
514 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 102 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 103 / 999 - starting...
515 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.0s
516 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.0s
517 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.0s
518 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.0s
519 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 103 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 104 / 999 - starting...
520 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=78, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.2s
521 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=78, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.2s
522 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=78, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.2s
523 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=78, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.2s
524 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 104 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=78, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.686 total time=   0.2s
Parameter choice num 105 / 999 - starting...
525 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
526 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
527 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
528 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
529 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 105 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 106 / 999 - starting...
530 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.0s
531 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.0s
532 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.0s
533 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.0s
534 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 106 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 107 / 999 - starting...
535 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.0s
536 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.0s
537 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.0s
538 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.0s
539 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 107 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 108 / 999 - starting...
540 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
541 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
542 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
543 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
544 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 108 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 109 / 999 - starting...
545 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.0s
546 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.0s
547 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.0s
548 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.0s
549 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 109 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 110 / 999 - starting...
550 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
551 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
552 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
553 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
554 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 110 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 111 / 999 - starting...
555 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
556 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
557 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
558 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
559 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 111 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 112 / 999 - starting...
560 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
561 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
562 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
563 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
564 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 112 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 113 / 999 - starting...
565 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.0s
566 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.0s
567 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.0s
568 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.0s
569 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 113 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 114 / 999 - starting...
570 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
571 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
572 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
573 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
574 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 114 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 115 / 999 - starting...
575 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
576 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
577 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
578 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
579 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 115 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 116 / 999 - starting...
580 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.0s
581 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.0s
582 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.0s
583 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.0s
584 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 116 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 117 / 999 - starting...
585 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
586 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
587 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
588 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
589 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 117 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 118 / 999 - starting...
590 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
591 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
592 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
593 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
594 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 118 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 119 / 999 - starting...
595 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.2s
596 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.2s
597 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.2s
598 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.2s
599 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 119 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.686 total time=   0.2s
Parameter choice num 120 / 999 - starting...
600 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.0s
601 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.0s
602 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.0s
603 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.0s
604 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 120 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 121 / 999 - starting...
605 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
606 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
607 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
608 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
609 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 121 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 122 / 999 - starting...
610 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
611 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
612 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
613 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
614 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 122 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 123 / 999 - starting...
615 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.2s
616 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.2s
617 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.2s
618 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.2s
619 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 123 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.686 total time=   0.2s
Parameter choice num 124 / 999 - starting...
620 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
621 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
622 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
623 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
624 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 124 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 125 / 999 - starting...
625 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
626 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
627 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
628 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
629 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 125 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 126 / 999 - starting...
630 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
631 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
632 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
633 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
634 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 126 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 127 / 999 - starting...
635 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.0s
636 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.0s
637 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.0s
638 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.0s
639 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 127 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 128 / 999 - starting...
640 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.0s
641 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.0s
642 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.0s
643 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.0s
644 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 128 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 129 / 999 - starting...
645 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.2s
646 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.2s
647 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.2s
648 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.2s
649 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 129 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.686 total time=   0.2s
Parameter choice num 130 / 999 - starting...
650 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
651 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.4s
652 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.4s
653 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
654 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 130 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.3s
Parameter choice num 131 / 999 - starting...
655 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.0s
656 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.1s
657 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.1s
658 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.1s
659 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 131 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.686 total time=   0.1s
Parameter choice num 132 / 999 - starting...
660 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.0s
661 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.0s
662 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.0s
663 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.0s
664 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 132 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 133 / 999 - starting...
665 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
666 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
667 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
668 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
669 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 133 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 134 / 999 - starting...
670 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=94, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
671 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=94, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
672 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=94, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
673 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=94, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
674 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 134 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=94, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 135 / 999 - starting...
675 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.5s
676 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.5s
677 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.5s
678 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.5s
679 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 135 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.686 total time=   0.5s
Parameter choice num 136 / 999 - starting...
680 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=86, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.0s
681 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=86, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.0s
682 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=86, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.0s
683 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=86, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.0s
684 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 136 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=86, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 137 / 999 - starting...
685 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
686 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
687 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
688 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
689 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 137 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 138 / 999 - starting...
690 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
691 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
692 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
693 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
694 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 138 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 139 / 999 - starting...
695 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
696 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
697 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
698 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
699 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 139 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 140 / 999 - starting...
700 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
701 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
702 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
703 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
704 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 140 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 141 / 999 - starting...
705 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
706 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
707 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
708 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
709 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 141 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 142 / 999 - starting...
710 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
711 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
712 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
713 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
714 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 142 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 143 / 999 - starting...
715 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
716 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
717 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
718 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
719 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 143 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 144 / 999 - starting...
720 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.0s
721 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.0s
722 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.0s
723 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.0s
724 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 144 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 145 / 999 - starting...
725 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.4s
726 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.4s
727 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.4s
728 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.4s
729 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 145 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.686 total time=   0.4s
Parameter choice num 146 / 999 - starting...
730 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.2s
731 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.2s
732 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.3s
733 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.3s
734 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 146 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.686 total time=   0.2s
Parameter choice num 147 / 999 - starting...
735 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
736 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
737 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
738 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
739 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 147 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 148 / 999 - starting...
740 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
741 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
742 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
743 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
744 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 148 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 149 / 999 - starting...
745 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.4s
746 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.4s
747 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.4s
748 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.4s
749 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 149 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.686 total time=   0.4s
Parameter choice num 150 / 999 - starting...
750 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
751 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
752 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
753 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
754 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 150 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 151 / 999 - starting...
755 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.4s
756 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.4s
757 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.5s
758 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.4s
759 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 151 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.686 total time=   0.4s
Parameter choice num 152 / 999 - starting...
760 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
761 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
762 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
763 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
764 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 152 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.3s
Parameter choice num 153 / 999 - starting...
765 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
766 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
767 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
768 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
769 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 153 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.686 total time=   0.1s
Parameter choice num 154 / 999 - starting...
770 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.5s
771 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.5s
772 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.5s
773 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.5s
774 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 154 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.686 total time=   0.5s
Parameter choice num 155 / 999 - starting...
775 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
776 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
777 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
778 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
779 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 155 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 156 / 999 - starting...
780 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.0s
781 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.0s
782 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.0s
783 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.0s
784 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 156 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 157 / 999 - starting...
785 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.0s
786 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.0s
787 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.0s
788 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.0s
789 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 157 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 158 / 999 - starting...
790 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
791 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
792 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
793 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
794 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 158 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 159 / 999 - starting...
795 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.0s
796 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.0s
797 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.0s
798 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.0s
799 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 159 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 160 / 999 - starting...
800 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.0s
801 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.0s
802 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.0s
803 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.0s
804 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 160 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 161 / 999 - starting...
805 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.0s
806 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.0s
807 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.0s
808 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.0s
809 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 161 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 162 / 999 - starting...
810 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.2s
811 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.2s
812 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.2s
813 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.2s
814 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 162 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.686 total time=   0.2s
Parameter choice num 163 / 999 - starting...
815 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.5s
816 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.4s
817 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.5s
818 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.4s
819 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 163 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.686 total time=   0.5s
Parameter choice num 164 / 999 - starting...
820 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
821 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
822 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
823 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
824 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 164 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 165 / 999 - starting...
825 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=74, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
826 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=74, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
827 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=74, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
828 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=74, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
829 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 165 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=74, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 166 / 999 - starting...
830 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.1s
831 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.1s
832 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.1s
833 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.1s
834 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 166 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.686 total time=   0.1s
Parameter choice num 167 / 999 - starting...
835 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.1s
836 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.1s
837 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.1s
838 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.1s
839 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 167 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.686 total time=   0.1s
Parameter choice num 168 / 999 - starting...
840 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.0s
841 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.0s
842 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.0s
843 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.0s
844 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 168 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 169 / 999 - starting...
845 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
846 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
847 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
848 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
849 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 169 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 170 / 999 - starting...
850 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=82, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
851 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=82, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
852 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=82, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
853 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=82, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
854 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 170 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=82, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 171 / 999 - starting...
855 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.2s
856 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.2s
857 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.2s
858 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.2s
859 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 171 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.686 total time=   0.2s
Parameter choice num 172 / 999 - starting...
860 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=70, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
861 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=70, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
862 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=70, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
863 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=70, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
864 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 172 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=70, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 173 / 999 - starting...
865 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
866 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
867 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
868 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
869 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 173 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 174 / 999 - starting...
870 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.0s
871 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.0s
872 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.0s
873 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.0s
874 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 174 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 175 / 999 - starting...
875 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
876 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
877 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
878 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
879 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 175 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 176 / 999 - starting...
880 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.0s
881 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.0s
882 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.0s
883 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.0s
884 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 176 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 177 / 999 - starting...
885 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
886 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
887 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
888 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
889 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 177 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 178 / 999 - starting...
890 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.4s
891 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.4s
892 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.4s
893 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.4s
894 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 178 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.686 total time=   0.4s
Parameter choice num 179 / 999 - starting...
895 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.0s
896 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.0s
897 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.0s
898 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.0s
899 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 179 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 180 / 999 - starting...
900 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=70, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
901 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=70, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
902 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=70, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
903 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=70, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
904 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 180 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=70, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 181 / 999 - starting...
905 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.0s
906 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.0s
907 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.0s
908 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.0s
909 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 181 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 182 / 999 - starting...
910 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=70, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.1s
911 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=70, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.1s
912 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=70, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.1s
913 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=70, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.1s
914 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 182 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=70, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.686 total time=   0.1s
Parameter choice num 183 / 999 - starting...
915 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
916 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
917 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
918 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
919 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 183 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 184 / 999 - starting...
920 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.1s
921 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.1s
922 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.1s
923 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.1s
924 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 184 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.686 total time=   0.1s
Parameter choice num 185 / 999 - starting...
925 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.0s
926 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.0s
927 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.0s
928 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.0s
929 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 185 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 186 / 999 - starting...
930 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.0s
931 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.0s
932 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.0s
933 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.0s
934 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 186 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 187 / 999 - starting...
935 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.0s
936 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.0s
937 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.0s
938 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.0s
939 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 187 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 188 / 999 - starting...
940 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.3s
941 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.3s
942 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.3s
943 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.3s
944 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 188 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.686 total time=   0.3s
Parameter choice num 189 / 999 - starting...
945 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.0s
946 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.0s
947 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.0s
948 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.0s
949 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 189 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 190 / 999 - starting...
950 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.1s
951 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.1s
952 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.1s
953 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.1s
954 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 190 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.686 total time=   0.1s
Parameter choice num 191 / 999 - starting...
955 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
956 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
957 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
958 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
959 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 191 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 192 / 999 - starting...
960 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.3s
961 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.3s
962 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.3s
963 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.3s
964 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 192 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.686 total time=   0.3s
Parameter choice num 193 / 999 - starting...
965 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
966 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
967 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
968 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
969 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 193 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 194 / 999 - starting...
970 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.0s
971 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.0s
972 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.0s
973 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.0s
974 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 194 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 195 / 999 - starting...
975 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.0s
976 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.0s
977 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.0s
978 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.0s
979 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 195 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 196 / 999 - starting...
980 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.0s
981 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.0s
982 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.0s
983 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.0s
984 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 196 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 197 / 999 - starting...
985 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
986 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
987 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
988 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
989 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 197 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 198 / 999 - starting...
990 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
991 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
992 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
993 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
994 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 198 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 199 / 999 - starting...
995 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.0s
996 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.0s
997 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.0s
998 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.0s
999 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 199 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 200 / 999 - starting...
1000 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.2s
1001 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.2s
1002 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.3s
1003 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.2s
1004 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 200 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.686 total time=   0.2s
Parameter choice num 201 / 999 - starting...
1005 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1006 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1007 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1008 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1009 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 201 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 202 / 999 - starting...
1010 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=94, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1011 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=94, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1012 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=94, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1013 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=94, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1014 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 202 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=94, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 203 / 999 - starting...
1015 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1016 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1017 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1018 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1019 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 203 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 204 / 999 - starting...
1020 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1021 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1022 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1023 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1024 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 204 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 205 / 999 - starting...
1025 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1026 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1027 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1028 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1029 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 205 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 206 / 999 - starting...
1030 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1031 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1032 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1033 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1034 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 206 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 207 / 999 - starting...
1035 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.4s
1036 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.4s
1037 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.4s
1038 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.4s
1039 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 207 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.686 total time=   0.4s
Parameter choice num 208 / 999 - starting...
1040 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
1041 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
1042 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
1043 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
1044 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 208 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.3s
Parameter choice num 209 / 999 - starting...
1045 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1046 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1047 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1048 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1049 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 209 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 210 / 999 - starting...
1050 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1051 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1052 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1053 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1054 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 210 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 211 / 999 - starting...
1055 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
1056 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
1057 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
1058 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
1059 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 211 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.3s
Parameter choice num 212 / 999 - starting...
1060 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1061 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1062 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1063 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1064 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 212 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 213 / 999 - starting...
1065 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1066 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1067 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1068 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1069 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 213 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 214 / 999 - starting...
1070 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.2s
1071 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.2s
1072 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.2s
1073 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.2s
1074 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 214 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.686 total time=   0.2s
Parameter choice num 215 / 999 - starting...
1075 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1076 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1077 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1078 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1079 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 215 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 216 / 999 - starting...
1080 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1081 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1082 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1083 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1084 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 216 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 217 / 999 - starting...
1085 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1086 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1087 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.1s
1088 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.1s
1089 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 217 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.686 total time=   0.1s
Parameter choice num 218 / 999 - starting...
1090 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1091 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1092 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1093 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1094 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 218 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 219 / 999 - starting...
1095 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1096 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1097 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1098 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1099 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 219 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 220 / 999 - starting...
1100 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1101 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1102 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1103 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1104 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 220 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 221 / 999 - starting...
1105 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.5s
1106 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.5s
1107 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.5s
1108 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.5s
1109 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 221 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.686 total time=   0.5s
Parameter choice num 222 / 999 - starting...
1110 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1111 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1112 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1113 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1114 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 222 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 223 / 999 - starting...
1115 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1116 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1117 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1118 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1119 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 223 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 224 / 999 - starting...
1120 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.3s
1121 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.3s
1122 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.3s
1123 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.3s
1124 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 224 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.686 total time=   0.3s
Parameter choice num 225 / 999 - starting...
1125 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1126 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1127 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1128 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1129 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 225 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 226 / 999 - starting...
1130 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1131 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1132 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1133 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1134 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 226 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 227 / 999 - starting...
1135 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1136 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1137 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1138 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1139 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 227 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 228 / 999 - starting...
1140 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1141 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1142 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1143 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1144 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 228 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 229 / 999 - starting...
1145 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1146 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1147 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1148 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1149 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 229 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 230 / 999 - starting...
1150 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1151 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1152 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1153 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1154 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 230 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 231 / 999 - starting...
1155 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1156 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1157 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1158 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1159 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 231 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 232 / 999 - starting...
1160 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1161 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1162 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1163 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1164 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 232 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 233 / 999 - starting...
1165 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1166 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1167 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1168 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1169 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 233 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 234 / 999 - starting...
1170 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1171 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1172 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1173 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1174 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 234 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 235 / 999 - starting...
1175 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1176 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1177 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1178 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1179 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 235 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 236 / 999 - starting...
1180 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1181 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1182 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1183 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1184 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 236 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 237 / 999 - starting...
1185 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.5s
1186 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.5s
1187 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.5s
1188 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.5s
1189 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 237 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.686 total time=   0.5s
Parameter choice num 238 / 999 - starting...
1190 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1191 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1192 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1193 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1194 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 238 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 239 / 999 - starting...
1195 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.2s
1196 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.2s
1197 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.2s
1198 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.2s
1199 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 239 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.686 total time=   0.2s
Parameter choice num 240 / 999 - starting...
1200 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=78, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1201 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=78, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1202 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=78, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1203 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=78, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1204 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 240 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=78, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 241 / 999 - starting...
1205 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1206 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1207 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1208 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1209 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 241 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 242 / 999 - starting...
1210 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=70, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.5s
1211 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=70, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.5s
1212 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=70, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.5s
1213 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=70, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.5s
1214 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 242 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=70, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.686 total time=   0.5s
Parameter choice num 243 / 999 - starting...
1215 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.2s
1216 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.3s
1217 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.3s
1218 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.3s
1219 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 243 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.686 total time=   0.3s
Parameter choice num 244 / 999 - starting...
1220 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1221 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1222 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1223 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1224 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 244 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 245 / 999 - starting...
1225 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
1226 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
1227 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
1228 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
1229 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 245 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.686 total time=   0.1s
Parameter choice num 246 / 999 - starting...
1230 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=78, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1231 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=78, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1232 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=78, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1233 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=78, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1234 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 246 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=78, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 247 / 999 - starting...
1235 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.4s
1236 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.4s
1237 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.4s
1238 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.4s
1239 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 247 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.686 total time=   0.4s
Parameter choice num 248 / 999 - starting...
1240 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1241 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1242 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1243 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1244 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 248 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 249 / 999 - starting...
1245 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1246 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1247 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1248 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1249 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 249 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 250 / 999 - starting...
1250 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1251 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1252 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1253 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1254 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 250 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 251 / 999 - starting...
1255 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1256 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1257 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1258 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1259 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 251 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 252 / 999 - starting...
1260 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=82, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1261 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=82, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1262 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=82, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1263 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=82, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1264 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 252 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=82, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 253 / 999 - starting...
1265 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1266 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1267 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1268 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1269 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 253 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 254 / 999 - starting...
1270 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1271 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1272 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1273 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1274 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 254 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 255 / 999 - starting...
1275 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1276 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1277 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1278 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1279 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 255 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 256 / 999 - starting...
1280 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.2s
1281 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.2s
1282 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.2s
1283 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.2s
1284 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 256 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.686 total time=   0.2s
Parameter choice num 257 / 999 - starting...
1285 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=74, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1286 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=74, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1287 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=74, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1288 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=74, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1289 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 257 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=74, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 258 / 999 - starting...
1290 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1291 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1292 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1293 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1294 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 258 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 259 / 999 - starting...
1295 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1296 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1297 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1298 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1299 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 259 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 260 / 999 - starting...
1300 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1301 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1302 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1303 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1304 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 260 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 261 / 999 - starting...
1305 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1306 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1307 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1308 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1309 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 261 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 262 / 999 - starting...
1310 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1311 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1312 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1313 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1314 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 262 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 263 / 999 - starting...
1315 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1316 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1317 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1318 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1319 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 263 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 264 / 999 - starting...
1320 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1321 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1322 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1323 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1324 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 264 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 265 / 999 - starting...
1325 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.4s
1326 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.4s
1327 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.4s
1328 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.4s
1329 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 265 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.686 total time=   0.4s
Parameter choice num 266 / 999 - starting...
1330 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1331 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1332 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1333 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1334 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 266 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 267 / 999 - starting...
1335 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1336 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1337 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1338 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1339 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 267 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 268 / 999 - starting...
1340 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1341 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1342 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1343 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1344 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 268 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 269 / 999 - starting...
1345 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1346 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1347 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.2s
1348 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.2s
1349 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 269 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.686 total time=   0.2s
Parameter choice num 270 / 999 - starting...
1350 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.4s
1351 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.4s
1352 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.4s
1353 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.4s
1354 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 270 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.686 total time=   0.4s
Parameter choice num 271 / 999 - starting...
1355 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1356 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1357 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1358 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1359 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 271 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 272 / 999 - starting...
1360 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1361 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1362 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1363 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1364 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 272 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 273 / 999 - starting...
1365 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.1s
1366 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.1s
1367 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.1s
1368 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.1s
1369 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 273 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.686 total time=   0.1s
Parameter choice num 274 / 999 - starting...
1370 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.1s
1371 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.1s
1372 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.1s
1373 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.1s
1374 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 274 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.686 total time=   0.1s
Parameter choice num 275 / 999 - starting...
1375 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1376 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1377 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.3s
1378 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.3s
1379 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 275 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.686 total time=   0.3s
Parameter choice num 276 / 999 - starting...
1380 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1381 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1382 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1383 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1384 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 276 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 277 / 999 - starting...
1385 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.4s
1386 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.4s
1387 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.5s
1388 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.4s
1389 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 277 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.686 total time=   0.4s
Parameter choice num 278 / 999 - starting...
1390 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1391 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1392 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1393 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1394 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 278 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 279 / 999 - starting...
1395 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1396 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1397 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1398 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1399 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 279 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 280 / 999 - starting...
1400 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1401 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1402 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1403 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1404 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 280 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 281 / 999 - starting...
1405 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1406 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1407 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1408 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1409 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 281 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 282 / 999 - starting...
1410 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1411 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1412 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1413 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1414 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 282 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 283 / 999 - starting...
1415 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1416 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1417 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1418 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1419 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 283 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 284 / 999 - starting...
1420 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1421 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1422 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1423 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1424 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 284 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 285 / 999 - starting...
1425 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1426 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1427 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1428 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1429 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 285 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 286 / 999 - starting...
1430 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1431 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1432 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1433 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1434 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 286 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 287 / 999 - starting...
1435 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1436 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1437 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1438 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1439 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 287 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 288 / 999 - starting...
1440 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.5s
1441 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.5s
1442 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.5s
1443 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.5s
1444 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 288 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.686 total time=   0.5s
Parameter choice num 289 / 999 - starting...
1445 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=74, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1446 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=74, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1447 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=74, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1448 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=74, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1449 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 289 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=74, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 290 / 999 - starting...
1450 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1451 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1452 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1453 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1454 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 290 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 291 / 999 - starting...
1455 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1456 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1457 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1458 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1459 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 291 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 292 / 999 - starting...
1460 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=78, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1461 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=78, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1462 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=78, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1463 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=78, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1464 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 292 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=78, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 293 / 999 - starting...
1465 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1466 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1467 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1468 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1469 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 293 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 294 / 999 - starting...
1470 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
1471 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
1472 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
1473 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
1474 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 294 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.686 total time=   0.1s
Parameter choice num 295 / 999 - starting...
1475 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1476 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1477 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1478 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1479 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 295 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 296 / 999 - starting...
1480 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1481 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1482 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1483 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1484 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 296 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 297 / 999 - starting...
1485 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1486 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1487 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1488 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1489 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 297 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 298 / 999 - starting...
1490 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.1s
1491 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.1s
1492 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.1s
1493 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.1s
1494 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 298 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.686 total time=   0.1s
Parameter choice num 299 / 999 - starting...
1495 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1496 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1497 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1498 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1499 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 299 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 300 / 999 - starting...
1500 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.2s
1501 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.3s
1502 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.3s
1503 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.3s
1504 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 300 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.686 total time=   0.3s
Parameter choice num 301 / 999 - starting...
1505 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1506 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1507 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1508 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1509 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 301 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 302 / 999 - starting...
1510 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1511 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1512 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1513 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1514 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 302 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 303 / 999 - starting...
1515 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1516 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1517 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1518 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1519 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 303 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 304 / 999 - starting...
1520 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.5s
1521 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.5s
1522 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.5s
1523 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.5s
1524 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 304 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.686 total time=   0.5s
Parameter choice num 305 / 999 - starting...
1525 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.2s
1526 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.2s
1527 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.2s
1528 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.2s
1529 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 305 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.686 total time=   0.2s
Parameter choice num 306 / 999 - starting...
1530 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
1531 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
1532 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
1533 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
1534 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 306 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.686 total time=   0.1s
Parameter choice num 307 / 999 - starting...
1535 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.3s
1536 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.2s
1537 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.3s
1538 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.3s
1539 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 307 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.686 total time=   0.3s
Parameter choice num 308 / 999 - starting...
1540 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1541 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1542 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1543 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1544 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 308 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 309 / 999 - starting...
1545 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1546 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1547 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1548 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1549 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 309 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 310 / 999 - starting...
1550 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.4s
1551 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.4s
1552 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.4s
1553 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.4s
1554 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 310 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.686 total time=   0.4s
Parameter choice num 311 / 999 - starting...
1555 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.5s
1556 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.5s
1557 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.5s
1558 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.5s
1559 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 311 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.686 total time=   0.5s
Parameter choice num 312 / 999 - starting...
1560 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1561 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1562 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1563 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1564 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 312 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 313 / 999 - starting...
1565 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.1s
1566 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.1s
1567 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.1s
1568 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.1s
1569 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 313 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.686 total time=   0.1s
Parameter choice num 314 / 999 - starting...
1570 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1571 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1572 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1573 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1574 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 314 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 315 / 999 - starting...
1575 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1576 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1577 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1578 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1579 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 315 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 316 / 999 - starting...
1580 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.2s
1581 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.2s
1582 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.2s
1583 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.2s
1584 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 316 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.686 total time=   0.2s
Parameter choice num 317 / 999 - starting...
1585 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1586 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1587 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1588 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1589 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 317 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 318 / 999 - starting...
1590 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1591 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1592 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1593 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1594 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 318 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 319 / 999 - starting...
1595 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1596 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1597 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1598 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1599 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 319 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 320 / 999 - starting...
1600 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.1s
1601 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.1s
1602 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.1s
1603 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.1s
1604 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 320 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.686 total time=   0.1s
Parameter choice num 321 / 999 - starting...
1605 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1606 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1607 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1608 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1609 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 321 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 322 / 999 - starting...
1610 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1611 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1612 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1613 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1614 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 322 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 323 / 999 - starting...
1615 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1616 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1617 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1618 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1619 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 323 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 324 / 999 - starting...
1620 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.1s
1621 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.1s
1622 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.1s
1623 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.1s
1624 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 324 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.686 total time=   0.1s
Parameter choice num 325 / 999 - starting...
1625 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1626 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1627 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1628 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1629 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 325 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 326 / 999 - starting...
1630 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1631 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1632 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1633 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1634 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 326 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 327 / 999 - starting...
1635 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=98, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1636 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=98, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1637 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=98, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1638 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=98, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1639 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 327 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=98, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 328 / 999 - starting...
1640 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1641 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1642 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1643 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1644 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 328 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 329 / 999 - starting...
1645 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.2s
1646 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.2s
1647 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.2s
1648 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.2s
1649 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 329 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.686 total time=   0.2s
Parameter choice num 330 / 999 - starting...
1650 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
1651 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
1652 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
1653 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
1654 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 330 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.3s
Parameter choice num 331 / 999 - starting...
1655 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.4s
1656 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.5s
1657 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.5s
1658 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.5s
1659 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 331 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.686 total time=   0.5s
Parameter choice num 332 / 999 - starting...
1660 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1661 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1662 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1663 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1664 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 332 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 333 / 999 - starting...
1665 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1666 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1667 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1668 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1669 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 333 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 334 / 999 - starting...
1670 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1671 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1672 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1673 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1674 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 334 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 335 / 999 - starting...
1675 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1676 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1677 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1678 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1679 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 335 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 336 / 999 - starting...
1680 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.2s
1681 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.2s
1682 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.2s
1683 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.2s
1684 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 336 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.686 total time=   0.2s
Parameter choice num 337 / 999 - starting...
1685 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1686 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1687 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1688 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1689 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 337 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 338 / 999 - starting...
1690 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1691 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1692 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1693 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1694 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 338 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 339 / 999 - starting...
1695 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.1s
1696 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.1s
1697 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.1s
1698 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.1s
1699 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 339 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.686 total time=   0.1s
Parameter choice num 340 / 999 - starting...
1700 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1701 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1702 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1703 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1704 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 340 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 341 / 999 - starting...
1705 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1706 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1707 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1708 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1709 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 341 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 342 / 999 - starting...
1710 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1711 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1712 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1713 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1714 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 342 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 343 / 999 - starting...
1715 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=90, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1716 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=90, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1717 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=90, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1718 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=90, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1719 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 343 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=90, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 344 / 999 - starting...
1720 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1721 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1722 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1723 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1724 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 344 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 345 / 999 - starting...
1725 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.2s
1726 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.2s
1727 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.2s
1728 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.2s
1729 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 345 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.686 total time=   0.2s
Parameter choice num 346 / 999 - starting...
1730 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1731 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1732 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1733 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1734 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 346 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 347 / 999 - starting...
1735 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=98, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1736 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=98, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1737 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=98, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1738 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=98, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1739 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 347 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=98, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 348 / 999 - starting...
1740 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1741 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1742 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1743 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1744 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 348 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 349 / 999 - starting...
1745 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1746 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1747 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1748 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1749 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 349 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 350 / 999 - starting...
1750 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.2s
1751 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.2s
1752 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.2s
1753 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.2s
1754 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 350 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.686 total time=   0.2s
Parameter choice num 351 / 999 - starting...
1755 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=78, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1756 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=78, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1757 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=78, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1758 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=78, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1759 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 351 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=78, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 352 / 999 - starting...
1760 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1761 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1762 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1763 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1764 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 352 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 353 / 999 - starting...
1765 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1766 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1767 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1768 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1769 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 353 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 354 / 999 - starting...
1770 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1771 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1772 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1773 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1774 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 354 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 355 / 999 - starting...
1775 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.2s
1776 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.2s
1777 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.2s
1778 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.2s
1779 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 355 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.686 total time=   0.2s
Parameter choice num 356 / 999 - starting...
1780 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1781 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1782 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1783 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1784 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 356 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 357 / 999 - starting...
1785 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1786 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1787 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1788 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1789 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 357 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 358 / 999 - starting...
1790 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1791 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1792 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1793 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1794 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 358 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 359 / 999 - starting...
1795 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.3s
1796 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.3s
1797 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.3s
1798 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.3s
1799 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 359 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.686 total time=   0.3s
Parameter choice num 360 / 999 - starting...
1800 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1801 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1802 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1803 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1804 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 360 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 361 / 999 - starting...
1805 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.3s
1806 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.3s
1807 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.4s
1808 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.3s
1809 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 361 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.686 total time=   0.3s
Parameter choice num 362 / 999 - starting...
1810 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1811 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1812 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1813 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1814 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 362 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 363 / 999 - starting...
1815 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1816 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1817 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1818 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1819 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 363 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 364 / 999 - starting...
1820 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1821 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1822 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1823 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1824 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 364 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 365 / 999 - starting...
1825 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=70, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.2s
1826 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=70, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.2s
1827 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=70, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.2s
1828 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=70, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.2s
1829 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 365 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=70, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.686 total time=   0.2s
Parameter choice num 366 / 999 - starting...
1830 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1831 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1832 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1833 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1834 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 366 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 367 / 999 - starting...
1835 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1836 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1837 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1838 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1839 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 367 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 368 / 999 - starting...
1840 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1841 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1842 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1843 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1844 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 368 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 369 / 999 - starting...
1845 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1846 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1847 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1848 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1849 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 369 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 370 / 999 - starting...
1850 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1851 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1852 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1853 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1854 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 370 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 371 / 999 - starting...
1855 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1856 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1857 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1858 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1859 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 371 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 372 / 999 - starting...
1860 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.2s
1861 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.2s
1862 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.2s
1863 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.2s
1864 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 372 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.686 total time=   0.2s
Parameter choice num 373 / 999 - starting...
1865 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=70, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.3s
1866 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=70, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.3s
1867 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=70, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.3s
1868 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=70, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.3s
1869 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 373 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=70, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.686 total time=   0.4s
Parameter choice num 374 / 999 - starting...
1870 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1871 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1872 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1873 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1874 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 374 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 375 / 999 - starting...
1875 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1876 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1877 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1878 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1879 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 375 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 376 / 999 - starting...
1880 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1881 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1882 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1883 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1884 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 376 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 377 / 999 - starting...
1885 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=70, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1886 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=70, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1887 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=70, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1888 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=70, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1889 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 377 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=70, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 378 / 999 - starting...
1890 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.3s
1891 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.3s
1892 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.4s
1893 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.4s
1894 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 378 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.686 total time=   0.4s
Parameter choice num 379 / 999 - starting...
1895 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
1896 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
1897 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
1898 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
1899 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 379 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.3s
Parameter choice num 380 / 999 - starting...
1900 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1901 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1902 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1903 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1904 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 380 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 381 / 999 - starting...
1905 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.2s
1906 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.2s
1907 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.2s
1908 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.2s
1909 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 381 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.686 total time=   0.2s
Parameter choice num 382 / 999 - starting...
1910 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1911 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1912 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1913 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1914 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 382 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 383 / 999 - starting...
1915 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1916 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1917 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1918 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1919 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 383 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 384 / 999 - starting...
1920 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=70, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.2s
1921 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=70, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.2s
1922 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=70, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.2s
1923 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=70, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.2s
1924 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 384 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=70, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.686 total time=   0.2s
Parameter choice num 385 / 999 - starting...
1925 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1926 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1927 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1928 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1929 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 385 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 386 / 999 - starting...
1930 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.4s
1931 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.4s
1932 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.4s
1933 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.4s
1934 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 386 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.686 total time=   0.4s
Parameter choice num 387 / 999 - starting...
1935 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
1936 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
1937 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
1938 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
1939 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 387 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.3s
Parameter choice num 388 / 999 - starting...
1940 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1941 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
1942 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1943 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
1944 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 388 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 389 / 999 - starting...
1945 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.1s
1946 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.1s
1947 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.1s
1948 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.1s
1949 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 389 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.686 total time=   0.2s
Parameter choice num 390 / 999 - starting...
1950 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1951 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1952 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1953 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1954 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 390 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 391 / 999 - starting...
1955 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1956 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1957 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1958 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1959 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 391 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 392 / 999 - starting...
1960 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1961 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
1962 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1963 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
1964 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 392 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 393 / 999 - starting...
1965 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1966 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1967 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1968 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1969 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 393 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 394 / 999 - starting...
1970 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
1971 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
1972 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
1973 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.4s
1974 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 394 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.3s
Parameter choice num 395 / 999 - starting...
1975 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.5s
1976 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.5s
1977 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.5s
1978 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.5s
1979 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 395 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.686 total time=   0.5s
Parameter choice num 396 / 999 - starting...
1980 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1981 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
1982 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1983 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
1984 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 396 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 397 / 999 - starting...
1985 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.3s
1986 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.3s
1987 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.4s
1988 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.4s
1989 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 397 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.686 total time=   0.3s
Parameter choice num 398 / 999 - starting...
1990 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.2s
1991 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.2s
1992 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.2s
1993 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.2s
1994 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 398 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.686 total time=   0.3s
Parameter choice num 399 / 999 - starting...
1995 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.3s
1996 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.3s
1997 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.3s
1998 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.3s
1999 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 399 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.686 total time=   0.3s
Parameter choice num 400 / 999 - starting...
2000 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2001 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2002 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2003 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2004 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 400 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 401 / 999 - starting...
2005 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2006 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2007 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2008 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2009 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 401 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 402 / 999 - starting...
2010 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.4s
2011 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.5s
2012 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.5s
2013 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.5s
2014 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 402 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.686 total time=   0.5s
Parameter choice num 403 / 999 - starting...
2015 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.4s
2016 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.4s
2017 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.4s
2018 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.4s
2019 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 403 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.686 total time=   0.4s
Parameter choice num 404 / 999 - starting...
2020 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2021 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2022 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2023 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2024 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 404 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 405 / 999 - starting...
2025 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2026 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2027 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2028 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2029 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 405 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 406 / 999 - starting...
2030 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2031 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2032 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2033 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2034 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 406 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 407 / 999 - starting...
2035 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2036 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2037 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2038 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2039 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 407 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 408 / 999 - starting...
2040 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2041 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2042 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2043 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2044 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 408 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 409 / 999 - starting...
2045 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2046 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2047 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2048 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2049 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 409 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 410 / 999 - starting...
2050 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2051 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2052 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2053 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2054 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 410 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 411 / 999 - starting...
2055 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=94, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2056 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=94, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2057 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=94, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2058 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=94, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2059 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 411 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=94, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 412 / 999 - starting...
2060 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2061 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2062 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2063 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2064 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 412 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 413 / 999 - starting...
2065 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=70, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2066 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=70, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2067 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=70, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2068 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=70, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2069 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 413 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=70, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 414 / 999 - starting...
2070 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2071 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2072 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2073 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2074 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 414 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 415 / 999 - starting...
2075 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2076 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2077 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2078 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2079 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 415 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 416 / 999 - starting...
2080 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2081 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2082 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2083 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2084 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 416 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 417 / 999 - starting...
2085 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=98, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2086 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=98, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2087 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=98, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2088 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=98, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2089 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 417 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=98, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 418 / 999 - starting...
2090 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.2s
2091 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.2s
2092 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.2s
2093 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.2s
2094 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 418 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.686 total time=   0.2s
Parameter choice num 419 / 999 - starting...
2095 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2096 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2097 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2098 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2099 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 419 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 420 / 999 - starting...
2100 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2101 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2102 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2103 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2104 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 420 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 421 / 999 - starting...
2105 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2106 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2107 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2108 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2109 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 421 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 422 / 999 - starting...
2110 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.4s
2111 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.4s
2112 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.4s
2113 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.4s
2114 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 422 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.686 total time=   0.4s
Parameter choice num 423 / 999 - starting...
2115 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2116 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2117 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2118 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2119 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 423 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 424 / 999 - starting...
2120 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.3s
2121 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.3s
2122 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.3s
2123 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.3s
2124 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 424 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.686 total time=   0.3s
Parameter choice num 425 / 999 - starting...
2125 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2126 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2127 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2128 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2129 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 425 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 426 / 999 - starting...
2130 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
2131 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
2132 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
2133 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
2134 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 426 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.686 total time=   0.1s
Parameter choice num 427 / 999 - starting...
2135 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.4s
2136 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.4s
2137 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.4s
2138 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.4s
2139 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 427 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.686 total time=   0.4s
Parameter choice num 428 / 999 - starting...
2140 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2141 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2142 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2143 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2144 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 428 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 429 / 999 - starting...
2145 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2146 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2147 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2148 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2149 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 429 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 430 / 999 - starting...
2150 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.4s
2151 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.4s
2152 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.4s
2153 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.4s
2154 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 430 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.686 total time=   0.4s
Parameter choice num 431 / 999 - starting...
2155 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2156 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2157 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2158 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2159 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 431 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 432 / 999 - starting...
2160 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2161 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2162 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2163 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2164 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 432 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 433 / 999 - starting...
2165 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2166 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2167 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2168 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2169 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 433 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 434 / 999 - starting...
2170 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.1s
2171 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.1s
2172 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.1s
2173 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.1s
2174 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 434 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.686 total time=   0.1s
Parameter choice num 435 / 999 - starting...
2175 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2176 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2177 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2178 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2179 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 435 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 436 / 999 - starting...
2180 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2181 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2182 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2183 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2184 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 436 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 437 / 999 - starting...
2185 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2186 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2187 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2188 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2189 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 437 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 438 / 999 - starting...
2190 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2191 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2192 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2193 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2194 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 438 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 439 / 999 - starting...
2195 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2196 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2197 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2198 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2199 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 439 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 440 / 999 - starting...
2200 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2201 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2202 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2203 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2204 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 440 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 441 / 999 - starting...
2205 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
2206 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
2207 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
2208 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
2209 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 441 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.686 total time=   0.1s
Parameter choice num 442 / 999 - starting...
2210 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2211 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2212 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2213 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2214 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 442 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 443 / 999 - starting...
2215 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2216 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2217 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2218 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2219 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 443 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 444 / 999 - starting...
2220 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.3s
2221 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.3s
2222 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.3s
2223 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.4s
2224 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 444 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.686 total time=   0.3s
Parameter choice num 445 / 999 - starting...
2225 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2226 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2227 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2228 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2229 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 445 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 446 / 999 - starting...
2230 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2231 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2232 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2233 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2234 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 446 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 447 / 999 - starting...
2235 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.3s
2236 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.3s
2237 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.3s
2238 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.3s
2239 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 447 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.686 total time=   0.3s
Parameter choice num 448 / 999 - starting...
2240 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=74, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2241 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=74, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2242 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=74, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2243 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=74, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2244 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 448 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=74, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 449 / 999 - starting...
2245 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2246 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2247 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2248 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2249 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 449 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 450 / 999 - starting...
2250 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2251 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2252 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2253 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2254 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 450 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 451 / 999 - starting...
2255 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2256 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2257 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2258 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2259 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 451 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 452 / 999 - starting...
2260 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2261 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2262 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2263 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2264 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 452 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 453 / 999 - starting...
2265 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.2s
2266 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.2s
2267 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.2s
2268 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.2s
2269 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 453 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.686 total time=   0.2s
Parameter choice num 454 / 999 - starting...
2270 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2271 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2272 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2273 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2274 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 454 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 455 / 999 - starting...
2275 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2276 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2277 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2278 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2279 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 455 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 456 / 999 - starting...
2280 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2281 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2282 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2283 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2284 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 456 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 457 / 999 - starting...
2285 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=74, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2286 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=74, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2287 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=74, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2288 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=74, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2289 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 457 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=74, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 458 / 999 - starting...
2290 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2291 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2292 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2293 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2294 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 458 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 459 / 999 - starting...
2295 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=66, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.4s
2296 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=66, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.4s
2297 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=66, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.4s
2298 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=66, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.4s
2299 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 459 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=66, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.686 total time=   0.4s
Parameter choice num 460 / 999 - starting...
2300 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2301 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2302 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2303 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2304 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 460 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 461 / 999 - starting...
2305 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2306 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2307 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2308 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2309 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 461 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 462 / 999 - starting...
2310 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2311 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2312 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2313 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2314 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 462 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 463 / 999 - starting...
2315 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.5s
2316 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.5s
2317 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.5s
2318 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.5s
2319 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 463 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.686 total time=   0.5s
Parameter choice num 464 / 999 - starting...
2320 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2321 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2322 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2323 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2324 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 464 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 465 / 999 - starting...
2325 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.1s
2326 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.1s
2327 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.1s
2328 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.1s
2329 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 465 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.686 total time=   0.1s
Parameter choice num 466 / 999 - starting...
2330 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2331 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2332 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2333 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2334 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 466 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 467 / 999 - starting...
2335 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2336 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2337 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2338 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2339 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 467 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 468 / 999 - starting...
2340 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2341 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2342 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2343 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2344 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 468 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 469 / 999 - starting...
2345 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2346 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2347 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2348 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2349 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 469 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 470 / 999 - starting...
2350 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.3s
2351 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.3s
2352 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.3s
2353 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.3s
2354 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 470 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.686 total time=   0.3s
Parameter choice num 471 / 999 - starting...
2355 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2356 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2357 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2358 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2359 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 471 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 472 / 999 - starting...
2360 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
2361 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
2362 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
2363 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
2364 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 472 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.686 total time=   0.1s
Parameter choice num 473 / 999 - starting...
2365 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=82, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2366 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=82, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2367 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=82, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2368 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=82, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2369 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 473 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=82, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 474 / 999 - starting...
2370 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2371 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2372 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2373 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2374 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 474 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 475 / 999 - starting...
2375 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2376 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2377 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2378 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2379 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 475 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 476 / 999 - starting...
2380 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.2s
2381 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.2s
2382 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.2s
2383 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.2s
2384 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 476 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.686 total time=   0.2s
Parameter choice num 477 / 999 - starting...
2385 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.1s
2386 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.1s
2387 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.1s
2388 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.1s
2389 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 477 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.686 total time=   0.1s
Parameter choice num 478 / 999 - starting...
2390 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2391 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2392 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2393 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2394 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 478 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 479 / 999 - starting...
2395 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2396 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2397 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2398 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2399 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 479 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 480 / 999 - starting...
2400 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2401 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2402 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2403 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2404 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 480 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 481 / 999 - starting...
2405 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.3s
2406 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.3s
2407 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.3s
2408 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.3s
2409 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 481 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.686 total time=   0.3s
Parameter choice num 482 / 999 - starting...
2410 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.2s
2411 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.2s
2412 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.2s
2413 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.2s
2414 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 482 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.686 total time=   0.2s
Parameter choice num 483 / 999 - starting...
2415 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2416 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2417 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2418 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2419 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 483 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 484 / 999 - starting...
2420 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.4s
2421 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.4s
2422 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.4s
2423 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.4s
2424 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 484 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.686 total time=   0.4s
Parameter choice num 485 / 999 - starting...
2425 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2426 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2427 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2428 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2429 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 485 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 486 / 999 - starting...
2430 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2431 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2432 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2433 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2434 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 486 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 487 / 999 - starting...
2435 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2436 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2437 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2438 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2439 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 487 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 488 / 999 - starting...
2440 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.1s
2441 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.1s
2442 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.1s
2443 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.1s
2444 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 488 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.686 total time=   0.1s
Parameter choice num 489 / 999 - starting...
2445 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2446 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2447 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2448 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2449 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 489 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 490 / 999 - starting...
2450 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2451 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2452 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2453 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2454 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 490 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 491 / 999 - starting...
2455 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2456 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2457 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2458 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2459 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 491 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 492 / 999 - starting...
2460 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2461 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2462 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2463 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2464 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 492 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 493 / 999 - starting...
2465 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2466 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2467 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2468 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2469 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 493 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 494 / 999 - starting...
2470 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=70, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.5s
2471 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=70, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.5s
2472 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=70, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.5s
2473 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=70, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.5s
2474 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 494 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=70, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.686 total time=   0.5s
Parameter choice num 495 / 999 - starting...
2475 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2476 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2477 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2478 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2479 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 495 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 496 / 999 - starting...
2480 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2481 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2482 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2483 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2484 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 496 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 497 / 999 - starting...
2485 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.1s
2486 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.1s
2487 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.1s
2488 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.1s
2489 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 497 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.686 total time=   0.1s
Parameter choice num 498 / 999 - starting...
2490 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2491 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2492 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2493 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2494 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 498 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 499 / 999 - starting...
2495 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2496 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2497 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2498 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2499 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 499 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 500 / 999 - starting...
2500 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.1s
2501 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.1s
2502 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.1s
2503 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.1s
2504 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 500 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.686 total time=   0.1s
Parameter choice num 501 / 999 - starting...
2505 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2506 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2507 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2508 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2509 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 501 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 502 / 999 - starting...
2510 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2511 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2512 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2513 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2514 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 502 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 503 / 999 - starting...
2515 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2516 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2517 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2518 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2519 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 503 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 504 / 999 - starting...
2520 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2521 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2522 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2523 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2524 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 504 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 505 / 999 - starting...
2525 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=74, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2526 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=74, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2527 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=74, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2528 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=74, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2529 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 505 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=74, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 506 / 999 - starting...
2530 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.3s
2531 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.3s
2532 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.3s
2533 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.3s
2534 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 506 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.686 total time=   0.3s
Parameter choice num 507 / 999 - starting...
2535 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2536 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2537 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2538 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2539 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 507 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 508 / 999 - starting...
2540 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2541 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2542 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2543 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2544 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 508 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 509 / 999 - starting...
2545 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2546 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2547 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2548 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2549 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 509 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 510 / 999 - starting...
2550 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2551 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2552 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2553 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2554 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 510 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 511 / 999 - starting...
2555 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2556 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2557 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2558 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2559 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 511 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 512 / 999 - starting...
2560 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2561 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2562 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2563 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2564 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 512 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 513 / 999 - starting...
2565 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2566 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2567 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2568 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2569 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 513 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 514 / 999 - starting...
2570 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=82, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2571 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=82, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2572 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=82, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2573 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=82, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2574 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 514 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=82, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 515 / 999 - starting...
2575 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2576 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2577 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2578 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2579 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 515 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 516 / 999 - starting...
2580 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2581 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2582 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2583 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2584 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 516 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 517 / 999 - starting...
2585 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2586 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2587 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2588 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2589 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 517 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 518 / 999 - starting...
2590 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2591 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2592 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2593 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2594 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 518 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 519 / 999 - starting...
2595 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.4s
2596 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.4s
2597 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.4s
2598 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.3s
2599 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 519 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.686 total time=   0.4s
Parameter choice num 520 / 999 - starting...
2600 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2601 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2602 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2603 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2604 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 520 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 521 / 999 - starting...
2605 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2606 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2607 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2608 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2609 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 521 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 522 / 999 - starting...
2610 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2611 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2612 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2613 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2614 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 522 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 523 / 999 - starting...
2615 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2616 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2617 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2618 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2619 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 523 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 524 / 999 - starting...
2620 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2621 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2622 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2623 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2624 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 524 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 525 / 999 - starting...
2625 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2626 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2627 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2628 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2629 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 525 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 526 / 999 - starting...
2630 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2631 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2632 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.3s
2633 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.3s
2634 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 526 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.686 total time=   0.3s
Parameter choice num 527 / 999 - starting...
2635 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.4s
2636 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.4s
2637 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.4s
2638 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.4s
2639 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 527 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.686 total time=   0.4s
Parameter choice num 528 / 999 - starting...
2640 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2641 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2642 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2643 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2644 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 528 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 529 / 999 - starting...
2645 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=94, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2646 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=94, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2647 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=94, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2648 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=94, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2649 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 529 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=94, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 530 / 999 - starting...
2650 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2651 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2652 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2653 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2654 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 530 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 531 / 999 - starting...
2655 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=78, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.2s
2656 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=78, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.2s
2657 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=78, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.2s
2658 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=78, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.2s
2659 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 531 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=78, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.686 total time=   0.2s
Parameter choice num 532 / 999 - starting...
2660 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
2661 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
2662 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
2663 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
2664 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 532 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.686 total time=   0.1s
Parameter choice num 533 / 999 - starting...
2665 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.5s
2666 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.5s
2667 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.5s
2668 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.5s
2669 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 533 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.686 total time=   0.5s
Parameter choice num 534 / 999 - starting...
2670 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2671 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2672 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2673 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2674 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 534 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 535 / 999 - starting...
2675 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.4s
2676 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.4s
2677 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.4s
2678 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.4s
2679 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 535 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.686 total time=   0.4s
Parameter choice num 536 / 999 - starting...
2680 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2681 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2682 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2683 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2684 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 536 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 537 / 999 - starting...
2685 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
2686 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
2687 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
2688 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
2689 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 537 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.686 total time=   0.1s
Parameter choice num 538 / 999 - starting...
2690 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2691 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2692 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2693 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2694 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 538 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 539 / 999 - starting...
2695 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2696 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2697 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2698 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2699 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 539 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 540 / 999 - starting...
2700 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2701 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2702 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2703 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2704 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 540 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 541 / 999 - starting...
2705 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.3s
2706 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.3s
2707 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.3s
2708 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.3s
2709 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 541 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.686 total time=   0.3s
Parameter choice num 542 / 999 - starting...
2710 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.4s
2711 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.4s
2712 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.4s
2713 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.4s
2714 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 542 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.686 total time=   0.4s
Parameter choice num 543 / 999 - starting...
2715 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2716 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2717 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2718 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2719 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 543 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 544 / 999 - starting...
2720 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.5s
2721 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.5s
2722 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.5s
2723 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.5s
2724 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 544 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.686 total time=   0.5s
Parameter choice num 545 / 999 - starting...
2725 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2726 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2727 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2728 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2729 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 545 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 546 / 999 - starting...
2730 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2731 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2732 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2733 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2734 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 546 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 547 / 999 - starting...
2735 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2736 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2737 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2738 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2739 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 547 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 548 / 999 - starting...
2740 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2741 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2742 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2743 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2744 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 548 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 549 / 999 - starting...
2745 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.3s
2746 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.3s
2747 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.3s
2748 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.3s
2749 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 549 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.686 total time=   0.3s
Parameter choice num 550 / 999 - starting...
2750 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2751 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2752 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2753 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2754 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 550 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 551 / 999 - starting...
2755 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.4s
2756 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.3s
2757 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.3s
2758 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.3s
2759 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 551 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.686 total time=   0.3s
Parameter choice num 552 / 999 - starting...
2760 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2761 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2762 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2763 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2764 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 552 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 553 / 999 - starting...
2765 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2766 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2767 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2768 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2769 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 553 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 554 / 999 - starting...
2770 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.2s
2771 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.2s
2772 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.2s
2773 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.2s
2774 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 554 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.686 total time=   0.2s
Parameter choice num 555 / 999 - starting...
2775 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2776 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2777 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2778 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2779 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 555 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 556 / 999 - starting...
2780 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2781 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2782 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2783 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2784 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 556 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 557 / 999 - starting...
2785 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2786 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2787 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2788 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2789 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 557 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 558 / 999 - starting...
2790 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2791 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2792 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2793 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2794 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 558 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 559 / 999 - starting...
2795 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.1s
2796 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.1s
2797 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.1s
2798 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.1s
2799 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 559 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.686 total time=   0.1s
Parameter choice num 560 / 999 - starting...
2800 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2801 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2802 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2803 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2804 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 560 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 561 / 999 - starting...
2805 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2806 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2807 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2808 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2809 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 561 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 562 / 999 - starting...
2810 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2811 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2812 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2813 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2814 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 562 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 563 / 999 - starting...
2815 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.2s
2816 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.2s
2817 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.2s
2818 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.3s
2819 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 563 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.686 total time=   0.3s
Parameter choice num 564 / 999 - starting...
2820 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2821 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2822 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2823 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2824 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 564 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 565 / 999 - starting...
2825 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2826 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.1s
2827 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2828 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2829 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 565 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 566 / 999 - starting...
2830 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=74, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2831 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=74, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2832 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=74, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2833 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=74, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2834 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 566 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=74, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 567 / 999 - starting...
2835 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.4s
2836 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.3s
2837 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.3s
2838 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.3s
2839 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 567 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.686 total time=   0.3s
Parameter choice num 568 / 999 - starting...
2840 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2841 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2842 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2843 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2844 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 568 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 569 / 999 - starting...
2845 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2846 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2847 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2848 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2849 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 569 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 570 / 999 - starting...
2850 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2851 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2852 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2853 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2854 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 570 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 571 / 999 - starting...
2855 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.1s
2856 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.1s
2857 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.1s
2858 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.1s
2859 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 571 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.686 total time=   0.1s
Parameter choice num 572 / 999 - starting...
2860 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=98, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2861 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=98, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2862 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=98, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2863 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=98, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2864 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 572 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=98, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 573 / 999 - starting...
2865 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2866 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2867 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2868 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2869 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 573 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 574 / 999 - starting...
2870 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2871 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2872 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2873 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2874 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 574 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 575 / 999 - starting...
2875 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.2s
2876 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.2s
2877 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.2s
2878 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.2s
2879 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 575 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.686 total time=   0.3s
Parameter choice num 576 / 999 - starting...
2880 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2881 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2882 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2883 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.1s
2884 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 576 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 577 / 999 - starting...
2885 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2886 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2887 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2888 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2889 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 577 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 578 / 999 - starting...
2890 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2891 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2892 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2893 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2894 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 578 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 579 / 999 - starting...
2895 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.1s
2896 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.1s
2897 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.1s
2898 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.1s
2899 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 579 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.686 total time=   0.1s
Parameter choice num 580 / 999 - starting...
2900 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.3s
2901 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.3s
2902 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.3s
2903 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.3s
2904 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 580 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.686 total time=   0.3s
Parameter choice num 581 / 999 - starting...
2905 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.2s
2906 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.2s
2907 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.2s
2908 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.2s
2909 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 581 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.686 total time=   0.2s
Parameter choice num 582 / 999 - starting...
2910 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2911 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2912 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2913 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2914 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 582 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 583 / 999 - starting...
2915 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2916 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2917 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2918 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2919 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 583 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 584 / 999 - starting...
2920 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2921 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2922 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2923 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2924 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 584 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 585 / 999 - starting...
2925 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.3s
2926 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.3s
2927 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.3s
2928 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.3s
2929 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 585 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.686 total time=   0.3s
Parameter choice num 586 / 999 - starting...
2930 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2931 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2932 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2933 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2934 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 586 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 587 / 999 - starting...
2935 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=62, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.1s
2936 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=62, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.1s
2937 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=62, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.1s
2938 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=62, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.1s
2939 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 587 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=62, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.686 total time=   0.1s
Parameter choice num 588 / 999 - starting...
2940 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.1s
2941 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.1s
2942 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.1s
2943 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.1s
2944 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 588 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.686 total time=   0.1s
Parameter choice num 589 / 999 - starting...
2945 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2946 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2947 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2948 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2949 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 589 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 590 / 999 - starting...
2950 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=98, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2951 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=98, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2952 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=98, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2953 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=98, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2954 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 590 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=98, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 591 / 999 - starting...
2955 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2956 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2957 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2958 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2959 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 591 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 592 / 999 - starting...
2960 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2961 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2962 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2963 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2964 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 592 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 593 / 999 - starting...
2965 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.2s
2966 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.2s
2967 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.2s
2968 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.2s
2969 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 593 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.686 total time=   0.2s
Parameter choice num 594 / 999 - starting...
2970 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2971 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2972 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2973 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2974 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 594 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 595 / 999 - starting...
2975 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2976 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2977 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2978 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2979 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 595 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 596 / 999 - starting...
2980 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2981 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2982 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2983 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2984 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 596 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 597 / 999 - starting...
2985 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2986 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
2987 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2988 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
2989 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 597 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 598 / 999 - starting...
2990 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2991 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.0s
2992 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2993 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.0s
2994 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 598 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=78, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 599 / 999 - starting...
2995 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2996 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.0s
2997 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2998 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.0s
2999 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 599 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 600 / 999 - starting...
3000 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3001 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3002 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3003 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3004 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 600 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 601 / 999 - starting...
3005 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.3s
3006 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.3s
3007 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.3s
3008 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.3s
3009 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 601 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.686 total time=   0.3s
Parameter choice num 602 / 999 - starting...
3010 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3011 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3012 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3013 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3014 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 602 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 603 / 999 - starting...
3015 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.1s
3016 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.1s
3017 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.1s
3018 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.1s
3019 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 603 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.686 total time=   0.1s
Parameter choice num 604 / 999 - starting...
3020 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3021 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3022 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3023 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3024 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 604 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 605 / 999 - starting...
3025 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3026 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3027 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3028 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3029 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 605 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 606 / 999 - starting...
3030 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3031 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3032 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3033 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3034 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 606 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 607 / 999 - starting...
3035 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
3036 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
3037 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
3038 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
3039 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 607 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.3s
Parameter choice num 608 / 999 - starting...
3040 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3041 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3042 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3043 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3044 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 608 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 609 / 999 - starting...
3045 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3046 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3047 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3048 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3049 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 609 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 610 / 999 - starting...
3050 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=70, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3051 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=70, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3052 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=70, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3053 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=70, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3054 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 610 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=70, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 611 / 999 - starting...
3055 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.5s
3056 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.5s
3057 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.5s
3058 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.5s
3059 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 611 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.686 total time=   0.5s
Parameter choice num 612 / 999 - starting...
3060 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3061 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3062 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3063 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3064 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 612 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 613 / 999 - starting...
3065 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3066 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3067 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3068 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3069 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 613 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 614 / 999 - starting...
3070 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3071 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3072 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3073 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3074 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 614 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 615 / 999 - starting...
3075 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3076 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3077 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3078 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3079 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 615 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 616 / 999 - starting...
3080 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3081 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3082 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3083 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3084 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 616 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 617 / 999 - starting...
3085 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3086 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3087 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3088 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3089 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 617 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 618 / 999 - starting...
3090 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3091 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3092 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3093 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3094 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 618 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 619 / 999 - starting...
3095 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3096 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3097 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3098 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3099 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 619 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 620 / 999 - starting...
3100 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=70, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3101 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=70, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3102 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=70, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3103 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=70, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3104 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 620 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=70, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 621 / 999 - starting...
3105 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3106 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3107 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3108 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3109 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 621 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 622 / 999 - starting...
3110 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3111 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3112 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3113 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3114 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 622 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 623 / 999 - starting...
3115 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3116 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3117 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3118 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3119 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 623 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 624 / 999 - starting...
3120 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3121 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3122 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3123 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3124 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 624 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 625 / 999 - starting...
3125 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3126 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3127 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3128 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3129 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 625 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 626 / 999 - starting...
3130 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=78, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3131 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=78, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3132 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=78, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3133 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=78, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3134 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 626 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=78, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 627 / 999 - starting...
3135 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3136 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3137 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3138 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3139 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 627 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 628 / 999 - starting...
3140 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3141 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3142 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3143 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3144 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 628 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 629 / 999 - starting...
3145 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3146 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3147 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3148 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3149 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 629 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 630 / 999 - starting...
3150 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3151 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3152 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3153 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3154 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 630 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 631 / 999 - starting...
3155 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3156 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3157 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3158 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3159 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 631 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 632 / 999 - starting...
3160 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3161 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3162 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3163 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3164 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 632 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 633 / 999 - starting...
3165 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3166 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3167 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3168 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3169 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 633 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 634 / 999 - starting...
3170 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3171 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3172 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3173 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3174 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 634 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 635 / 999 - starting...
3175 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
3176 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
3177 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
3178 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
3179 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 635 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.686 total time=   0.1s
Parameter choice num 636 / 999 - starting...
3180 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3181 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3182 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3183 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3184 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 636 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 637 / 999 - starting...
3185 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3186 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3187 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3188 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3189 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 637 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 638 / 999 - starting...
3190 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3191 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3192 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3193 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3194 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 638 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 639 / 999 - starting...
3195 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3196 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3197 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3198 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3199 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 639 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 640 / 999 - starting...
3200 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3201 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3202 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3203 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3204 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 640 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 641 / 999 - starting...
3205 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.2s
3206 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.2s
3207 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.2s
3208 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.2s
3209 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 641 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.686 total time=   0.2s
Parameter choice num 642 / 999 - starting...
3210 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3211 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3212 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3213 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3214 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 642 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 643 / 999 - starting...
3215 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3216 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3217 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3218 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3219 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 643 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 644 / 999 - starting...
3220 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3221 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3222 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3223 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3224 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 644 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 645 / 999 - starting...
3225 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3226 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3227 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3228 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3229 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 645 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 646 / 999 - starting...
3230 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3231 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3232 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3233 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3234 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 646 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=86, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 647 / 999 - starting...
3235 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3236 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3237 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3238 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3239 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 647 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=82, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 648 / 999 - starting...
3240 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3241 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3242 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3243 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3244 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 648 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 649 / 999 - starting...
3245 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.2s
3246 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.2s
3247 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.2s
3248 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.2s
3249 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 649 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.686 total time=   0.2s
Parameter choice num 650 / 999 - starting...
3250 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3251 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3252 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.2s
3253 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.2s
3254 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 650 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.686 total time=   0.2s
Parameter choice num 651 / 999 - starting...
3255 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=58, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.2s
3256 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=58, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.2s
3257 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=58, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.2s
3258 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=58, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.2s
3259 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 651 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=58, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.686 total time=   0.2s
Parameter choice num 652 / 999 - starting...
3260 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=82, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3261 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=82, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3262 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=82, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3263 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=82, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3264 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 652 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=82, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 653 / 999 - starting...
3265 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=78, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.4s
3266 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=78, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.4s
3267 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=78, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.4s
3268 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=78, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.4s
3269 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 653 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=78, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.686 total time=   0.4s
Parameter choice num 654 / 999 - starting...
3270 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3271 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3272 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3273 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3274 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 654 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 655 / 999 - starting...
3275 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3276 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3277 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3278 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3279 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 655 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 656 / 999 - starting...
3280 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.4s
3281 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.4s
3282 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.4s
3283 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.4s
3284 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 656 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.686 total time=   0.5s
Parameter choice num 657 / 999 - starting...
3285 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=90, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3286 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=90, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3287 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=90, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3288 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=90, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3289 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 657 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=90, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 658 / 999 - starting...
3290 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=98, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3291 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=98, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3292 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=98, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3293 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=98, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3294 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 658 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=98, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 659 / 999 - starting...
3295 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=58, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.2s
3296 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=58, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.2s
3297 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=58, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.2s
3298 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=58, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.2s
3299 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 659 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=58, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.686 total time=   0.2s
Parameter choice num 660 / 999 - starting...
3300 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3301 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3302 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3303 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3304 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 660 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 661 / 999 - starting...
3305 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3306 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3307 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3308 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3309 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 661 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 662 / 999 - starting...
3310 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=78, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3311 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=78, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3312 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=78, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3313 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=78, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3314 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 662 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=78, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 663 / 999 - starting...
3315 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.3s
3316 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.2s
3317 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.3s
3318 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.3s
3319 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 663 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.686 total time=   0.3s
Parameter choice num 664 / 999 - starting...
3320 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3321 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3322 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3323 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3324 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 664 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 665 / 999 - starting...
3325 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3326 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3327 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3328 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3329 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 665 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 666 / 999 - starting...
3330 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.2s
3331 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.2s
3332 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.2s
3333 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.2s
3334 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 666 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.686 total time=   0.2s
Parameter choice num 667 / 999 - starting...
3335 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3336 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3337 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3338 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3339 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 667 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 668 / 999 - starting...
3340 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.2s
3341 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.2s
3342 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.2s
3343 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.2s
3344 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 668 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.686 total time=   0.2s
Parameter choice num 669 / 999 - starting...
3345 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3346 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3347 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3348 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3349 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 669 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 670 / 999 - starting...
3350 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
3351 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
3352 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
3353 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
3354 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 670 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.3s
Parameter choice num 671 / 999 - starting...
3355 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3356 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3357 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3358 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3359 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 671 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 672 / 999 - starting...
3360 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3361 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3362 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3363 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3364 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 672 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 673 / 999 - starting...
3365 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.4s
3366 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.4s
3367 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.4s
3368 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.4s
3369 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 673 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.686 total time=   0.4s
Parameter choice num 674 / 999 - starting...
3370 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.2s
3371 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.2s
3372 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.3s
3373 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.2s
3374 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 674 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.686 total time=   0.2s
Parameter choice num 675 / 999 - starting...
3375 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
3376 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
3377 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
3378 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
3379 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 675 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.686 total time=   0.1s
Parameter choice num 676 / 999 - starting...
3380 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3381 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3382 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3383 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3384 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 676 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 677 / 999 - starting...
3385 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3386 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3387 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3388 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3389 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 677 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 678 / 999 - starting...
3390 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3391 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3392 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3393 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3394 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 678 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 679 / 999 - starting...
3395 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3396 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3397 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3398 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3399 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 679 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 680 / 999 - starting...
3400 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=70, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.3s
3401 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=70, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.3s
3402 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=70, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.3s
3403 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=70, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.3s
3404 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 680 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=70, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.686 total time=   0.3s
Parameter choice num 681 / 999 - starting...
3405 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3406 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3407 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3408 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3409 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 681 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 682 / 999 - starting...
3410 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.1s
3411 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.1s
3412 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.1s
3413 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.1s
3414 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 682 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.686 total time=   0.1s
Parameter choice num 683 / 999 - starting...
3415 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.4s
3416 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.4s
3417 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.4s
3418 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.4s
3419 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 683 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.686 total time=   0.4s
Parameter choice num 684 / 999 - starting...
3420 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3421 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3422 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3423 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3424 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 684 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 685 / 999 - starting...
3425 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3426 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3427 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3428 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3429 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 685 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 686 / 999 - starting...
3430 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3431 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3432 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3433 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3434 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 686 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 687 / 999 - starting...
3435 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3436 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3437 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3438 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3439 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 687 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 688 / 999 - starting...
3440 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3441 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3442 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3443 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3444 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 688 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 689 / 999 - starting...
3445 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3446 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3447 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3448 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3449 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 689 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 690 / 999 - starting...
3450 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3451 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3452 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3453 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3454 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 690 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 691 / 999 - starting...
3455 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3456 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3457 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3458 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3459 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 691 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 692 / 999 - starting...
3460 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3461 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3462 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3463 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3464 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 692 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 693 / 999 - starting...
3465 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.2s
3466 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.2s
3467 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.2s
3468 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.2s
3469 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 693 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.686 total time=   0.2s
Parameter choice num 694 / 999 - starting...
3470 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3471 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3472 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3473 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3474 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 694 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 695 / 999 - starting...
3475 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3476 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3477 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3478 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3479 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 695 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 696 / 999 - starting...
3480 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3481 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3482 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3483 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3484 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 696 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 697 / 999 - starting...
3485 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3486 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3487 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3488 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3489 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 697 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 698 / 999 - starting...
3490 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3491 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3492 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3493 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3494 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 698 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 699 / 999 - starting...
3495 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3496 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3497 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3498 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3499 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 699 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 700 / 999 - starting...
3500 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3501 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3502 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3503 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3504 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 700 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 701 / 999 - starting...
3505 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.2s
3506 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.2s
3507 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.2s
3508 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.2s
3509 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 701 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.686 total time=   0.2s
Parameter choice num 702 / 999 - starting...
3510 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.1s
3511 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.2s
3512 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.2s
3513 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.2s
3514 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 702 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.686 total time=   0.2s
Parameter choice num 703 / 999 - starting...
3515 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3516 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3517 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3518 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3519 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 703 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 704 / 999 - starting...
3520 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.1s
3521 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.1s
3522 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.1s
3523 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.1s
3524 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 704 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.686 total time=   0.1s
Parameter choice num 705 / 999 - starting...
3525 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.2s
3526 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.2s
3527 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.2s
3528 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.2s
3529 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 705 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.686 total time=   0.2s
Parameter choice num 706 / 999 - starting...
3530 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3531 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3532 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3533 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3534 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 706 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 707 / 999 - starting...
3535 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3536 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3537 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3538 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3539 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 707 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 708 / 999 - starting...
3540 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3541 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3542 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3543 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3544 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 708 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 709 / 999 - starting...
3545 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=94, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3546 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=94, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3547 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=94, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3548 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=94, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3549 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 709 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=94, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 710 / 999 - starting...
3550 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3551 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3552 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3553 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3554 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 710 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 711 / 999 - starting...
3555 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3556 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3557 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3558 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3559 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 711 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 712 / 999 - starting...
3560 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.3s
3561 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.3s
3562 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.3s
3563 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.3s
3564 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 712 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.686 total time=   0.3s
Parameter choice num 713 / 999 - starting...
3565 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3566 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3567 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3568 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3569 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 713 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 714 / 999 - starting...
3570 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3571 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3572 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3573 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3574 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 714 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 715 / 999 - starting...
3575 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3576 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3577 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3578 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3579 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 715 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 716 / 999 - starting...
3580 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3581 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3582 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3583 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3584 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 716 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 717 / 999 - starting...
3585 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3586 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3587 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3588 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3589 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 717 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=94, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 718 / 999 - starting...
3590 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3591 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3592 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3593 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3594 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 718 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 719 / 999 - starting...
3595 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.2s
3596 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.2s
3597 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.2s
3598 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.2s
3599 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 719 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.686 total time=   0.2s
Parameter choice num 720 / 999 - starting...
3600 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.4s
3601 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.4s
3602 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.4s
3603 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.4s
3604 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 720 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.686 total time=   0.4s
Parameter choice num 721 / 999 - starting...
3605 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.2s
3606 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.2s
3607 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.2s
3608 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.2s
3609 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 721 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.686 total time=   0.2s
Parameter choice num 722 / 999 - starting...
3610 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
3611 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
3612 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
3613 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
3614 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 722 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.3s
Parameter choice num 723 / 999 - starting...
3615 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3616 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3617 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3618 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3619 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 723 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 724 / 999 - starting...
3620 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3621 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3622 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3623 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3624 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 724 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 725 / 999 - starting...
3625 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=98, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3626 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=98, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3627 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=98, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3628 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=98, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3629 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 725 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=98, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 726 / 999 - starting...
3630 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3631 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3632 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3633 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3634 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 726 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 727 / 999 - starting...
3635 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.3s
3636 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.3s
3637 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.3s
3638 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.3s
3639 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 727 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.686 total time=   0.3s
Parameter choice num 728 / 999 - starting...
3640 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.4s
3641 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.4s
3642 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.4s
3643 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.4s
3644 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 728 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.686 total time=   0.4s
Parameter choice num 729 / 999 - starting...
3645 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.2s
3646 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.2s
3647 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.2s
3648 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.2s
3649 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 729 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.686 total time=   0.2s
Parameter choice num 730 / 999 - starting...
3650 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3651 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3652 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3653 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3654 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 730 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 731 / 999 - starting...
3655 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3656 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3657 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3658 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3659 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 731 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 732 / 999 - starting...
3660 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=70, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.2s
3661 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=70, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.2s
3662 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=70, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.2s
3663 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=70, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.2s
3664 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 732 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=70, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.686 total time=   0.2s
Parameter choice num 733 / 999 - starting...
3665 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3666 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3667 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3668 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3669 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 733 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 734 / 999 - starting...
3670 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3671 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3672 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3673 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3674 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 734 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 735 / 999 - starting...
3675 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3676 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3677 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3678 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3679 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 735 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 736 / 999 - starting...
3680 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3681 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3682 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3683 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3684 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 736 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 737 / 999 - starting...
3685 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3686 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3687 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3688 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3689 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 737 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=42, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 738 / 999 - starting...
3690 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
3691 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
3692 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
3693 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
3694 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 738 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.686 total time=   0.1s
Parameter choice num 739 / 999 - starting...
3695 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3696 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3697 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3698 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3699 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 739 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 740 / 999 - starting...
3700 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
3701 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
3702 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
3703 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
3704 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 740 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.686 total time=   0.1s
Parameter choice num 741 / 999 - starting...
3705 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
3706 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
3707 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
3708 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
3709 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 741 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.3s
Parameter choice num 742 / 999 - starting...
3710 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3711 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3712 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3713 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3714 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 742 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 743 / 999 - starting...
3715 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=70, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3716 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=70, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3717 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=70, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3718 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=70, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3719 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 743 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=70, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 744 / 999 - starting...
3720 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=74, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3721 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=74, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3722 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=74, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3723 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=74, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3724 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 744 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=74, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 745 / 999 - starting...
3725 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3726 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3727 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3728 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3729 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 745 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 746 / 999 - starting...
3730 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3731 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3732 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3733 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3734 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 746 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 747 / 999 - starting...
3735 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=62, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3736 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=62, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3737 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=62, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3738 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=62, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3739 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 747 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=62, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 748 / 999 - starting...
3740 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3741 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3742 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3743 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3744 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 748 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 749 / 999 - starting...
3745 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.1s
3746 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.1s
3747 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.1s
3748 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.1s
3749 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 749 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.686 total time=   0.1s
Parameter choice num 750 / 999 - starting...
3750 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3751 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3752 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3753 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3754 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 750 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 751 / 999 - starting...
3755 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3756 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3757 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.1s
3758 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.1s
3759 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 751 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.686 total time=   0.1s
Parameter choice num 752 / 999 - starting...
3760 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.2s
3761 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.2s
3762 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.2s
3763 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.2s
3764 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 752 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.686 total time=   0.2s
Parameter choice num 753 / 999 - starting...
3765 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3766 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3767 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3768 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3769 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 753 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 754 / 999 - starting...
3770 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3771 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3772 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3773 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3774 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 754 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 755 / 999 - starting...
3775 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3776 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3777 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3778 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3779 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 755 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 756 / 999 - starting...
3780 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3781 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3782 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3783 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3784 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 756 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 757 / 999 - starting...
3785 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.2s
3786 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.2s
3787 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.2s
3788 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.2s
3789 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 757 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.686 total time=   0.2s
Parameter choice num 758 / 999 - starting...
3790 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3791 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3792 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3793 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3794 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 758 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 759 / 999 - starting...
3795 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=58, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.1s
3796 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=58, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.2s
3797 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=58, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.2s
3798 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=58, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.2s
3799 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 759 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=58, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.686 total time=   0.2s
Parameter choice num 760 / 999 - starting...
3800 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3801 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3802 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3803 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3804 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 760 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 761 / 999 - starting...
3805 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3806 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3807 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3808 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3809 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 761 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 762 / 999 - starting...
3810 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3811 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3812 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3813 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3814 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 762 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 763 / 999 - starting...
3815 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3816 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3817 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3818 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3819 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 763 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 764 / 999 - starting...
3820 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3821 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3822 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3823 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3824 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 764 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 765 / 999 - starting...
3825 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3826 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3827 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3828 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3829 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 765 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 766 / 999 - starting...
3830 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3831 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3832 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3833 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3834 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 766 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 767 / 999 - starting...
3835 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.4s
3836 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.4s
3837 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.4s
3838 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.4s
3839 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 767 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.686 total time=   0.4s
Parameter choice num 768 / 999 - starting...
3840 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.3s
3841 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.3s
3842 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.4s
3843 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.4s
3844 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 768 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.686 total time=   0.3s
Parameter choice num 769 / 999 - starting...
3845 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3846 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3847 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3848 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3849 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 769 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 770 / 999 - starting...
3850 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3851 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3852 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3853 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3854 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 770 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 771 / 999 - starting...
3855 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3856 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3857 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3858 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3859 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 771 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 772 / 999 - starting...
3860 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.5s
3861 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.5s
3862 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.5s
3863 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.5s
3864 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 772 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.686 total time=   0.5s
Parameter choice num 773 / 999 - starting...
3865 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3866 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3867 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3868 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3869 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 773 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 774 / 999 - starting...
3870 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3871 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3872 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3873 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3874 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 774 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 775 / 999 - starting...
3875 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.4s
3876 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.4s
3877 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.4s
3878 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.4s
3879 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 775 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.686 total time=   0.4s
Parameter choice num 776 / 999 - starting...
3880 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3881 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3882 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3883 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3884 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 776 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 777 / 999 - starting...
3885 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3886 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3887 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3888 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3889 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 777 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 778 / 999 - starting...
3890 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.3s
3891 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.3s
3892 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.3s
3893 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.3s
3894 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 778 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.686 total time=   0.3s
Parameter choice num 779 / 999 - starting...
3895 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3896 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3897 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3898 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3899 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 779 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 780 / 999 - starting...
3900 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.2s
3901 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.2s
3902 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.2s
3903 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.2s
3904 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 780 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.686 total time=   0.2s
Parameter choice num 781 / 999 - starting...
3905 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.3s
3906 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.3s
3907 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.3s
3908 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.3s
3909 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 781 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.686 total time=   0.4s
Parameter choice num 782 / 999 - starting...
3910 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3911 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3912 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3913 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3914 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 782 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 783 / 999 - starting...
3915 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
3916 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
3917 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
3918 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
3919 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 783 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.686 total time=   0.1s
Parameter choice num 784 / 999 - starting...
3920 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=98, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3921 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=98, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3922 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=98, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3923 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=98, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3924 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 784 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=98, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 785 / 999 - starting...
3925 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3926 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3927 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3928 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3929 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 785 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 786 / 999 - starting...
3930 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.2s
3931 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.2s
3932 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.2s
3933 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.2s
3934 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 786 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.686 total time=   0.2s
Parameter choice num 787 / 999 - starting...
3935 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.1s
3936 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.1s
3937 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.1s
3938 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.1s
3939 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 787 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.686 total time=   0.1s
Parameter choice num 788 / 999 - starting...
3940 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3941 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3942 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3943 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3944 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 788 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 789 / 999 - starting...
3945 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3946 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
3947 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3948 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
3949 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 789 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 790 / 999 - starting...
3950 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3951 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3952 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3953 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3954 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 790 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 791 / 999 - starting...
3955 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
3956 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
3957 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
3958 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
3959 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 791 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.3s
Parameter choice num 792 / 999 - starting...
3960 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.1s
3961 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.1s
3962 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.1s
3963 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.1s
3964 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 792 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.686 total time=   0.1s
Parameter choice num 793 / 999 - starting...
3965 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3966 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3967 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3968 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3969 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 793 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 794 / 999 - starting...
3970 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.4s
3971 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.4s
3972 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.4s
3973 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.4s
3974 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 794 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.686 total time=   0.4s
Parameter choice num 795 / 999 - starting...
3975 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3976 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3977 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3978 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3979 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 795 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 796 / 999 - starting...
3980 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3981 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.0s
3982 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3983 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.0s
3984 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 796 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 797 / 999 - starting...
3985 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
3986 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
3987 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
3988 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
3989 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 797 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.686 total time=   0.1s
Parameter choice num 798 / 999 - starting...
3990 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.4s
3991 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.4s
3992 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.4s
3993 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.4s
3994 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 798 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.686 total time=   0.4s
Parameter choice num 799 / 999 - starting...
3995 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3996 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
3997 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3998 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
3999 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 799 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 800 / 999 - starting...
4000 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=98, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4001 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=98, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4002 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=98, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4003 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=98, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4004 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 800 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=98, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 801 / 999 - starting...
4005 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4006 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4007 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4008 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4009 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 801 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 802 / 999 - starting...
4010 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.2s
4011 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.2s
4012 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.2s
4013 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.2s
4014 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 802 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.686 total time=   0.2s
Parameter choice num 803 / 999 - starting...
4015 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4016 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4017 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4018 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4019 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 803 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 804 / 999 - starting...
4020 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4021 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4022 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4023 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4024 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 804 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 805 / 999 - starting...
4025 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4026 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4027 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4028 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4029 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 805 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 806 / 999 - starting...
4030 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4031 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4032 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4033 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4034 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 806 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 807 / 999 - starting...
4035 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.2s
4036 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.2s
4037 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.2s
4038 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.2s
4039 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 807 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.686 total time=   0.2s
Parameter choice num 808 / 999 - starting...
4040 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4041 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4042 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4043 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4044 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 808 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 809 / 999 - starting...
4045 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4046 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4047 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4048 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4049 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 809 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 810 / 999 - starting...
4050 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4051 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4052 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4053 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4054 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 810 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 811 / 999 - starting...
4055 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4056 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4057 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4058 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4059 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 811 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 812 / 999 - starting...
4060 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=74, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4061 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=74, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4062 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=74, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4063 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=74, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4064 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 812 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=74, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 813 / 999 - starting...
4065 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4066 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4067 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4068 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4069 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 813 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 814 / 999 - starting...
4070 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4071 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4072 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4073 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4074 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 814 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 815 / 999 - starting...
4075 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4076 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4077 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4078 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4079 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 815 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 816 / 999 - starting...
4080 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4081 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4082 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4083 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4084 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 816 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 817 / 999 - starting...
4085 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=98, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4086 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=98, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4087 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=98, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4088 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=98, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4089 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 817 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=98, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 818 / 999 - starting...
4090 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=98, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4091 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=98, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4092 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=98, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4093 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=98, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4094 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 818 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=98, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 819 / 999 - starting...
4095 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4096 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4097 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4098 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4099 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 819 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 820 / 999 - starting...
4100 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4101 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4102 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4103 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4104 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 820 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 821 / 999 - starting...
4105 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4106 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4107 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4108 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4109 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 821 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 822 / 999 - starting...
4110 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.2s
4111 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.2s
4112 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.2s
4113 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.2s
4114 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 822 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.686 total time=   0.2s
Parameter choice num 823 / 999 - starting...
4115 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4116 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4117 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4118 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4119 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 823 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 824 / 999 - starting...
4120 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4121 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4122 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4123 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4124 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 824 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 825 / 999 - starting...
4125 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4126 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4127 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4128 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4129 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 825 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 826 / 999 - starting...
4130 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4131 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4132 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4133 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4134 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 826 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 827 / 999 - starting...
4135 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4136 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4137 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4138 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4139 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 827 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 828 / 999 - starting...
4140 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4141 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4142 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4143 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4144 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 828 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=90, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 829 / 999 - starting...
4145 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4146 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4147 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4148 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4149 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 829 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 830 / 999 - starting...
4150 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4151 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4152 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4153 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4154 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 830 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 831 / 999 - starting...
4155 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.2s
4156 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.2s
4157 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.2s
4158 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.2s
4159 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 831 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.686 total time=   0.2s
Parameter choice num 832 / 999 - starting...
4160 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.2s
4161 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.2s
4162 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.2s
4163 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.2s
4164 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 832 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.686 total time=   0.2s
Parameter choice num 833 / 999 - starting...
4165 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4166 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4167 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4168 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4169 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 833 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 834 / 999 - starting...
4170 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4171 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4172 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4173 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4174 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 834 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=66, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 835 / 999 - starting...
4175 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4176 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4177 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4178 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4179 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 835 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 836 / 999 - starting...
4180 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4181 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4182 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4183 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4184 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 836 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 837 / 999 - starting...
4185 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.3s
4186 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.3s
4187 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.3s
4188 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.3s
4189 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 837 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.686 total time=   0.3s
Parameter choice num 838 / 999 - starting...
4190 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4191 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4192 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4193 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4194 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 838 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 839 / 999 - starting...
4195 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.3s
4196 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.3s
4197 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.4s
4198 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.4s
4199 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 839 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=66, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.686 total time=   0.4s
Parameter choice num 840 / 999 - starting...
4200 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=98, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4201 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=98, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4202 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=98, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4203 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=98, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4204 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 840 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=98, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 841 / 999 - starting...
4205 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=78, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.2s
4206 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=78, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.2s
4207 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=78, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.3s
4208 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=78, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.2s
4209 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 841 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=78, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.686 total time=   0.2s
Parameter choice num 842 / 999 - starting...
4210 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4211 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4212 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4213 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4214 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 842 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 843 / 999 - starting...
4215 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4216 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4217 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4218 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4219 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 843 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 844 / 999 - starting...
4220 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
4221 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
4222 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
4223 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
4224 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 844 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=66, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.3s
Parameter choice num 845 / 999 - starting...
4225 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4226 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4227 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4228 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4229 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 845 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=74, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 846 / 999 - starting...
4230 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4231 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4232 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4233 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4234 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 846 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=66, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 847 / 999 - starting...
4235 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4236 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4237 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4238 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4239 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 847 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 848 / 999 - starting...
4240 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=62, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.1s
4241 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=62, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.1s
4242 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=62, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.1s
4243 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=62, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.1s
4244 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 848 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=62, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.686 total time=   0.1s
Parameter choice num 849 / 999 - starting...
4245 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4246 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4247 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4248 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4249 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 849 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=98, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 850 / 999 - starting...
4250 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.1s
4251 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.1s
4252 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.1s
4253 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.1s
4254 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 850 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.686 total time=   0.1s
Parameter choice num 851 / 999 - starting...
4255 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
4256 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
4257 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
4258 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
4259 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 851 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.3s
Parameter choice num 852 / 999 - starting...
4260 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4261 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4262 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4263 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4264 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 852 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 853 / 999 - starting...
4265 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=74, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.5s
4266 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=74, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.5s
4267 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=74, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.5s
4268 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=74, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.5s
4269 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 853 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=74, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.686 total time=   0.5s
Parameter choice num 854 / 999 - starting...
4270 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.1s
4271 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.1s
4272 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.1s
4273 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.1s
4274 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 854 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.686 total time=   0.1s
Parameter choice num 855 / 999 - starting...
4275 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4276 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4277 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4278 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4279 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 855 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 856 / 999 - starting...
4280 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4281 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4282 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4283 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4284 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 856 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 857 / 999 - starting...
4285 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4286 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4287 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4288 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4289 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 857 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=62, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 858 / 999 - starting...
4290 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.3s
4291 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.3s
4292 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.3s
4293 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.3s
4294 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 858 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.686 total time=   0.3s
Parameter choice num 859 / 999 - starting...
4295 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4296 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4297 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4298 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4299 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 859 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=70, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 860 / 999 - starting...
4300 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4301 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4302 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4303 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4304 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 860 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=86, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 861 / 999 - starting...
4305 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4306 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4307 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4308 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4309 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 861 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 862 / 999 - starting...
4310 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4311 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4312 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4313 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4314 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 862 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 863 / 999 - starting...
4315 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4316 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4317 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4318 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4319 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 863 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 864 / 999 - starting...
4320 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.1s
4321 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.1s
4322 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.1s
4323 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.1s
4324 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 864 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.686 total time=   0.1s
Parameter choice num 865 / 999 - starting...
4325 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4326 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4327 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4328 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4329 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 865 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 866 / 999 - starting...
4330 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4331 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4332 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4333 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4334 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 866 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 867 / 999 - starting...
4335 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.2s
4336 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.660 total time=   0.2s
4337 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.2s
4338 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.644 total time=   0.2s
4339 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 867 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.7;, score=0.686 total time=   0.2s
Parameter choice num 868 / 999 - starting...
4340 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.2s
4341 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.2s
4342 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.2s
4343 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.2s
4344 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 868 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.686 total time=   0.2s
Parameter choice num 869 / 999 - starting...
4345 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4346 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4347 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4348 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4349 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 869 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 870 / 999 - starting...
4350 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4351 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4352 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4353 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4354 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 870 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 871 / 999 - starting...
4355 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4356 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4357 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4358 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4359 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 871 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=94, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 872 / 999 - starting...
4360 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.4s
4361 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.4s
4362 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.4s
4363 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.4s
4364 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 872 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=62, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.686 total time=   0.4s
Parameter choice num 873 / 999 - starting...
4365 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
4366 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
4367 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
4368 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
4369 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 873 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=74, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.3s
Parameter choice num 874 / 999 - starting...
4370 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.2s
4371 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.2s
4372 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.2s
4373 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.2s
4374 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 874 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.686 total time=   0.2s
Parameter choice num 875 / 999 - starting...
4375 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4376 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4377 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4378 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4379 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 875 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 876 / 999 - starting...
4380 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4381 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4382 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4383 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4384 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 876 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 877 / 999 - starting...
4385 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4386 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4387 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4388 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4389 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 877 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 878 / 999 - starting...
4390 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4391 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4392 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4393 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4394 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 878 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 879 / 999 - starting...
4395 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=70, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.4s
4396 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=70, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.4s
4397 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=70, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.4s
4398 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=70, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.4s
4399 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 879 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=70, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.686 total time=   0.4s
Parameter choice num 880 / 999 - starting...
4400 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4401 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4402 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4403 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4404 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 880 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 881 / 999 - starting...
4405 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
4406 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
4407 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
4408 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
4409 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 881 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.686 total time=   0.1s
Parameter choice num 882 / 999 - starting...
4410 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4411 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4412 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4413 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4414 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 882 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 883 / 999 - starting...
4415 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
4416 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
4417 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
4418 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
4419 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 883 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.686 total time=   0.1s
Parameter choice num 884 / 999 - starting...
4420 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4421 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4422 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4423 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4424 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 884 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 885 / 999 - starting...
4425 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4426 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4427 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4428 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4429 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 885 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 886 / 999 - starting...
4430 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4431 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4432 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4433 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4434 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 886 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 887 / 999 - starting...
4435 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.1s
4436 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.1s
4437 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.1s
4438 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.1s
4439 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 887 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.686 total time=   0.1s
Parameter choice num 888 / 999 - starting...
4440 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4441 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4442 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4443 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4444 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 888 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 889 / 999 - starting...
4445 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.4s
4446 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.4s
4447 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.4s
4448 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.4s
4449 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 889 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=66, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.686 total time=   0.4s
Parameter choice num 890 / 999 - starting...
4450 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.1s
4451 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.1s
4452 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.1s
4453 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.1s
4454 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 890 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=66, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.686 total time=   0.2s
Parameter choice num 891 / 999 - starting...
4455 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4456 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4457 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4458 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4459 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 891 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 892 / 999 - starting...
4460 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4461 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4462 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4463 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4464 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 892 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=94, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 893 / 999 - starting...
4465 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4466 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4467 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4468 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4469 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 893 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 894 / 999 - starting...
4470 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4471 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4472 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4473 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4474 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 894 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 895 / 999 - starting...
4475 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4476 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4477 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4478 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4479 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 895 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=70, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 896 / 999 - starting...
4480 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.3s
4481 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.2s
4482 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.3s
4483 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.3s
4484 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 896 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.686 total time=   0.3s
Parameter choice num 897 / 999 - starting...
4485 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4486 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4487 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4488 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4489 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 897 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 898 / 999 - starting...
4490 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4491 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4492 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4493 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4494 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 898 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 899 / 999 - starting...
4495 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4496 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4497 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4498 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4499 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 899 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 900 / 999 - starting...
4500 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.2s
4501 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.660 total time=   0.2s
4502 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.2s
4503 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.644 total time=   0.2s
4504 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 900 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=22, classifier__subsample=0.9;, score=0.686 total time=   0.2s
Parameter choice num 901 / 999 - starting...
4505 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4506 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4507 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4508 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4509 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 901 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=78, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 902 / 999 - starting...
4510 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4511 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4512 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4513 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4514 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 902 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 903 / 999 - starting...
4515 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.3s
4516 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.3s
4517 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.4s
4518 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.4s
4519 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 903 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.686 total time=   0.4s
Parameter choice num 904 / 999 - starting...
4520 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.2s
4521 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.2s
4522 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.2s
4523 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.2s
4524 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 904 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.686 total time=   0.2s
Parameter choice num 905 / 999 - starting...
4525 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.4s
4526 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.4s
4527 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.4s
4528 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.4s
4529 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 905 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.686 total time=   0.4s
Parameter choice num 906 / 999 - starting...
4530 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4531 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4532 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4533 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4534 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 906 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 907 / 999 - starting...
4535 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4536 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4537 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4538 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4539 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 907 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=78, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 908 / 999 - starting...
4540 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4541 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4542 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4543 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4544 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 908 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 909 / 999 - starting...
4545 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4546 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4547 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4548 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4549 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 909 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=58, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 910 / 999 - starting...
4550 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4551 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4552 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4553 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4554 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 910 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 911 / 999 - starting...
4555 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4556 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4557 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4558 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4559 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 911 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 912 / 999 - starting...
4560 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4561 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4562 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4563 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4564 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 912 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 913 / 999 - starting...
4565 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4566 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4567 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4568 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4569 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 913 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 914 / 999 - starting...
4570 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4571 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4572 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4573 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4574 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 914 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 915 / 999 - starting...
4575 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4576 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4577 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4578 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4579 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 915 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=66, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 916 / 999 - starting...
4580 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.2s
4581 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.2s
4582 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.2s
4583 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.2s
4584 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 916 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.686 total time=   0.2s
Parameter choice num 917 / 999 - starting...
4585 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4586 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4587 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4588 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4589 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 917 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 918 / 999 - starting...
4590 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.3s
4591 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.3s
4592 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.3s
4593 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.3s
4594 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 918 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=58, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.686 total time=   0.3s
Parameter choice num 919 / 999 - starting...
4595 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4596 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4597 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4598 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4599 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 919 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 920 / 999 - starting...
4600 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4601 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4602 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4603 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4604 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 920 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 921 / 999 - starting...
4605 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=98, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4606 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=98, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4607 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=98, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4608 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=98, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4609 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 921 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=98, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 922 / 999 - starting...
4610 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4611 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4612 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4613 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4614 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 922 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 923 / 999 - starting...
4615 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4616 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4617 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4618 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4619 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 923 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 924 / 999 - starting...
4620 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
4621 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
4622 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
4623 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
4624 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 924 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.3s
Parameter choice num 925 / 999 - starting...
4625 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=70, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4626 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=70, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4627 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=70, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4628 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=70, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4629 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 925 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=70, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 926 / 999 - starting...
4630 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4631 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4632 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4633 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4634 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 926 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 927 / 999 - starting...
4635 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.1s
4636 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.660 total time=   0.1s
4637 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.1s
4638 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.644 total time=   0.1s
4639 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 927 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=58, classifier__n_estimators=18, classifier__subsample=0.8;, score=0.686 total time=   0.1s
Parameter choice num 928 / 999 - starting...
4640 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=66, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4641 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=66, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4642 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=66, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4643 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=66, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4644 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 928 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=66, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 929 / 999 - starting...
4645 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4646 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4647 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4648 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4649 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 929 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=90, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 930 / 999 - starting...
4650 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4651 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4652 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4653 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4654 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 930 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 931 / 999 - starting...
4655 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.1s
4656 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.660 total time=   0.1s
4657 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.2s
4658 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.644 total time=   0.1s
4659 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 931 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=14, classifier__subsample=0.9;, score=0.686 total time=   0.1s
Parameter choice num 932 / 999 - starting...
4660 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=70, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4661 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=70, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4662 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=70, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4663 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=70, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4664 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 932 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=70, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 933 / 999 - starting...
4665 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
4666 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
4667 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
4668 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
4669 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 933 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.686 total time=   0.1s
Parameter choice num 934 / 999 - starting...
4670 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.1s
4671 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.1s
4672 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4673 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4674 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 934 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 935 / 999 - starting...
4675 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4676 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4677 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4678 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4679 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 935 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 936 / 999 - starting...
4680 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=66, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
4681 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=66, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.1s
4682 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=66, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
4683 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=66, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.1s
4684 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 936 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=66, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.686 total time=   0.1s
Parameter choice num 937 / 999 - starting...
4685 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4686 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4687 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4688 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4689 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 937 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 938 / 999 - starting...
4690 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4691 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4692 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4693 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4694 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 938 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 939 / 999 - starting...
4695 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4696 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4697 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4698 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4699 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 939 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 940 / 999 - starting...
4700 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4701 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4702 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4703 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4704 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 940 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=26, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 941 / 999 - starting...
4705 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4706 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4707 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4708 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.1s
4709 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 941 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 942 / 999 - starting...
4710 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=70, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4711 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=70, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4712 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=70, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4713 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=70, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4714 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 942 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=70, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 943 / 999 - starting...
4715 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4716 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4717 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4718 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4719 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 943 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=36, classifier__min_samples_split=66, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 944 / 999 - starting...
4720 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4721 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4722 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4723 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4724 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 944 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=74, classifier__n_estimators=2, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 945 / 999 - starting...
4725 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4726 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4727 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4728 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4729 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 945 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=90, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 946 / 999 - starting...
4730 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4731 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4732 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4733 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4734 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 946 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 947 / 999 - starting...
4735 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4736 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4737 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4738 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4739 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 947 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 948 / 999 - starting...
4740 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.2s
4741 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.2s
4742 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.2s
4743 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.2s
4744 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 948 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.686 total time=   0.2s
Parameter choice num 949 / 999 - starting...
4745 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4746 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4747 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4748 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4749 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 949 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=90, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 950 / 999 - starting...
4750 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4751 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4752 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4753 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4754 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 950 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 951 / 999 - starting...
4755 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4756 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4757 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4758 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4759 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 951 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=86, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 952 / 999 - starting...
4760 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
4761 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
4762 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
4763 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
4764 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 952 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=74, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.3s
Parameter choice num 953 / 999 - starting...
4765 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4766 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4767 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4768 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4769 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 953 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=10, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 954 / 999 - starting...
4770 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4771 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4772 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4773 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4774 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 954 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=90, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 955 / 999 - starting...
4775 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.3s
4776 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.660 total time=   0.3s
4777 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.4s
4778 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.644 total time=   0.4s
4779 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 955 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=58, classifier__n_estimators=38, classifier__subsample=0.8;, score=0.686 total time=   0.3s
Parameter choice num 956 / 999 - starting...
4780 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4781 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4782 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4783 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4784 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 956 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=14, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 957 / 999 - starting...
4785 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4786 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4787 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4788 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4789 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 957 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 958 / 999 - starting...
4790 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4791 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4792 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4793 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4794 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 958 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=58, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 959 / 999 - starting...
4795 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4796 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4797 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4798 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4799 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 959 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=98, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 960 / 999 - starting...
4800 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4801 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4802 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4803 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4804 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 960 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 961 / 999 - starting...
4805 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4806 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4807 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4808 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4809 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 961 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=36, classifier__min_samples_split=98, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 962 / 999 - starting...
4810 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4811 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4812 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4813 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4814 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 962 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=98, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 963 / 999 - starting...
4815 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=98, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4816 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=98, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4817 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=98, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4818 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=98, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4819 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 963 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=98, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 964 / 999 - starting...
4820 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4821 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4822 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4823 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4824 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 964 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=82, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 965 / 999 - starting...
4825 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.3s
4826 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.3s
4827 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.3s
4828 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.3s
4829 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 965 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=58, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.686 total time=   0.3s
Parameter choice num 966 / 999 - starting...
4830 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.2s
4831 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.2s
4832 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.2s
4833 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.2s
4834 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 966 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.686 total time=   0.2s
Parameter choice num 967 / 999 - starting...
4835 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4836 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4837 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4838 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4839 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 967 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=74, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 968 / 999 - starting...
4840 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4841 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4842 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4843 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4844 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 968 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=28, classifier__min_samples_split=82, classifier__n_estimators=2, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 969 / 999 - starting...
4845 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
4846 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.3s
4847 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
4848 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.3s
4849 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 969 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.3s
Parameter choice num 970 / 999 - starting...
4850 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4851 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4852 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4853 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4854 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 970 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=82, classifier__n_estimators=42, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 971 / 999 - starting...
4855 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.2s
4856 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.2s
4857 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.2s
4858 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.2s
4859 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 971 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=58, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.686 total time=   0.2s
Parameter choice num 972 / 999 - starting...
4860 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.3s
4861 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.3s
4862 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.3s
4863 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.3s
4864 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 972 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=62, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.686 total time=   0.3s
Parameter choice num 973 / 999 - starting...
4865 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.3s
4866 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.660 total time=   0.3s
4867 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.3s
4868 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.644 total time=   0.3s
4869 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 973 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=130, classifier__max_features=None, classifier__min_samples_leaf=34, classifier__min_samples_split=62, classifier__n_estimators=34, classifier__subsample=0.8;, score=0.686 total time=   0.3s
Parameter choice num 974 / 999 - starting...
4870 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4871 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4872 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4873 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4874 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 974 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=78, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 975 / 999 - starting...
4875 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4876 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4877 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4878 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4879 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 975 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=74, classifier__n_estimators=46, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 976 / 999 - starting...
4880 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4881 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4882 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4883 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4884 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 976 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=30, classifier__min_samples_split=94, classifier__n_estimators=6, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 977 / 999 - starting...
4885 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4886 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4887 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4888 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4889 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 977 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 978 / 999 - starting...
4890 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=94, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4891 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=94, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4892 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=94, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4893 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=94, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4894 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 978 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=94, classifier__n_estimators=14, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 979 / 999 - starting...
4895 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.4s
4896 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.660 total time=   0.5s
4897 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.4s
4898 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.644 total time=   0.4s
4899 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 979 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=70, classifier__n_estimators=38, classifier__subsample=0.9;, score=0.686 total time=   0.4s
Parameter choice num 980 / 999 - starting...
4900 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.1s
4901 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.660 total time=   0.1s
4902 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.1s
4903 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.644 total time=   0.1s
4904 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 980 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=62, classifier__n_estimators=10, classifier__subsample=0.8;, score=0.686 total time=   0.1s
Parameter choice num 981 / 999 - starting...
4905 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4906 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4907 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4908 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4909 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 981 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 982 / 999 - starting...
4910 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4911 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4912 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4913 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4914 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 982 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=26, classifier__min_samples_split=78, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 983 / 999 - starting...
4915 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4916 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4917 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4918 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4919 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 983 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=22, classifier__min_samples_split=90, classifier__n_estimators=38, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 984 / 999 - starting...
4920 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4921 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4922 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4923 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4924 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 984 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=94, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 985 / 999 - starting...
4925 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4926 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4927 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4928 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4929 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 985 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=70, classifier__max_features=None, classifier__min_samples_leaf=24, classifier__min_samples_split=58, classifier__n_estimators=10, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 986 / 999 - starting...
4930 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4931 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4932 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4933 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4934 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 986 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=98, classifier__n_estimators=46, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 987 / 999 - starting...
4935 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=74, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4936 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=74, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4937 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=74, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4938 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=74, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4939 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 987 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=74, classifier__n_estimators=6, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 988 / 999 - starting...
4940 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4941 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4942 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4943 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4944 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 988 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=32, classifier__min_samples_split=66, classifier__n_estimators=2, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 989 / 999 - starting...
4945 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4946 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4947 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4948 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4949 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 989 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=80, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 990 / 999 - starting...
4950 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.4s
4951 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.660 total time=   0.4s
4952 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.4s
4953 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.644 total time=   0.4s
4954 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 990 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=24, classifier__min_samples_split=70, classifier__n_estimators=42, classifier__subsample=0.8;, score=0.686 total time=   0.4s
Parameter choice num 991 / 999 - starting...
4955 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4956 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4957 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4958 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4959 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 991 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=28, classifier__min_samples_split=78, classifier__n_estimators=18, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 992 / 999 - starting...
4960 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.2s
4961 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.660 total time=   0.2s
4962 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.2s
4963 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.644 total time=   0.2s
4964 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 992 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=34, classifier__min_samples_split=66, classifier__n_estimators=26, classifier__subsample=0.8;, score=0.686 total time=   0.2s
Parameter choice num 993 / 999 - starting...
4965 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=82, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4966 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=82, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4967 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=82, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4968 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=82, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4969 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 993 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=auto, classifier__min_samples_leaf=30, classifier__min_samples_split=82, classifier__n_estimators=18, classifier__subsample=0.9;, score=0.686 total time=   0.0s
Parameter choice num 994 / 999 - starting...
4970 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4971 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4972 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4973 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4974 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 994 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=90, classifier__max_features=None, classifier__min_samples_leaf=22, classifier__min_samples_split=86, classifier__n_estimators=6, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 995 / 999 - starting...
4975 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4976 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4977 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4978 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4979 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 995 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=100, classifier__max_features=auto, classifier__min_samples_leaf=20, classifier__min_samples_split=86, classifier__n_estimators=22, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 996 / 999 - starting...
4980 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=74, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4981 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=74, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.660 total time=   0.0s
4982 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=74, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4983 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=74, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.644 total time=   0.0s
4984 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 996 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=60, classifier__max_features=None, classifier__min_samples_leaf=20, classifier__min_samples_split=74, classifier__n_estimators=34, classifier__subsample=0.7;, score=0.686 total time=   0.0s
Parameter choice num 997 / 999 - starting...
4985 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4986 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4987 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4988 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4989 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 997 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=120, classifier__max_features=auto, classifier__min_samples_leaf=26, classifier__min_samples_split=86, classifier__n_estimators=30, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 998 / 999 - starting...
4990 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4991 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.660 total time=   0.0s
4992 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4993 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.644 total time=   0.0s
4994 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 998 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=auto, classifier__min_samples_leaf=38, classifier__min_samples_split=82, classifier__n_estimators=22, classifier__subsample=0.8;, score=0.686 total time=   0.0s
Parameter choice num 999 / 999 - starting...
4995 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 1/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4996 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6603773584905661 
[CV 2/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.660 total time=   0.0s
4997 / 4999 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 3/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4998 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6435643564356436 
[CV 4/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.644 total time=   0.0s
4999 / 4999 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
scoring metric: f_beta, score: 0.6862745098039215 
Best parameter choice score by now is 0.6588315879312682
In parameter choice num 999 / 999 avg score was: 0.6588315879312682. This is the best score so far
[CV 5/5] END classifier=GradientBoostingClassifier(random_state=42), classifier__learning_rate=0.0001, classifier__max_depth=110, classifier__max_features=None, classifier__min_samples_leaf=38, classifier__min_samples_split=86, classifier__n_estimators=34, classifier__subsample=0.9;, score=0.686 total time=   0.0s
-----------------------
 New CV report 
-----------------------
* Classifier: 
 GradientBoostingClassifier(learning_rate=0.0001, max_depth=130,
                           max_features='auto', min_samples_leaf=20,
                           min_samples_split=78, n_estimators=38,
                           random_state=42, subsample=0.8)
* User arguments: 
 {'rs': 42, 'X_version': 1, 'split_rows': 'normal', 'drop_out_correlated': False, 'age_under_50': False, 'debug': False, 'exhaustive_grid_search': False, 'classification_type': 'normal', 'scoring_method': 'f_beta', 'both': True, 'cv': 5, 'n_iter': 1000, 'n_jobs': 1, 'use_gamma_columns': True, 'classification': True, 'lite_mode': True, 'test_size': 0.15, 'stdout_to_file': True, 'beta': 0.5}
* Pipeline details: 
 Pipeline(steps=[('scaler', StandardScaler()),
                ('classifier',
                 GradientBoostingClassifier(learning_rate=0.0001, max_depth=130,
                                            max_features='auto',
                                            min_samples_leaf=20,
                                            min_samples_split=78,
                                            n_estimators=38, random_state=42,
                                            subsample=0.8))])
* Best Hyperparametes picked in cross validation: (cv's best score): 
 {'classifier__subsample': 0.8, 'classifier__n_estimators': 38, 'classifier__min_samples_split': 78, 'classifier__min_samples_leaf': 20, 'classifier__max_features': 'auto', 'classifier__max_depth': 130, 'classifier__learning_rate': 0.0001, 'classifier': GradientBoostingClassifier(learning_rate=0.0001, max_depth=130,
                           max_features='auto', min_samples_leaf=20,
                           min_samples_split=78, n_estimators=38,
                           random_state=42, subsample=0.8)}
* Best features by (selectKbest): 
 
* Scorer_used: f_beta
* CV Score (cv's best score for best hyperparametes): 0.659 +/- 0.016 (see score func in hyperparams)  

* Confusion matrix: 
 [[ 0 44]
 [ 0 68]]
[[TN FP
[FN TP]]
* Response rate:  0.6071428571428571
* CV Precision:  0.6071428571428571
* CV Recall:  1.0
* CV Accuracy:  0.6071428571428571
* CV F1:  0.7555555555555554
<<<<<<<<<<<<<<<<<<<<< GSCVrunner.py finished successfuly<<<<<<<<<<<<<<<<<<<<<
