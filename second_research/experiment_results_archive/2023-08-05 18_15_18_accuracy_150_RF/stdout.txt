~~~~~~~~~~ RANDOMIZED SEARCH CV ~~~~~~~~~~
Fitting 5 folds for each of 150 candidates, totalling 750 fits
Parameter choice num 0 / 149 - starting...
0 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.522 total time=  20.1s
1 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.609 total time=   4.7s
2 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   8.9s
3 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=  10.7s
4 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
New improvement!
New best score is 0.47154150197628464
In parameter choice num 0 / 149 avg score was: 0.47154150197628464.
updating 2023-08-05 18_15_18_accuracy_150_RF\search_statistics.txt...
statistics file updated successfully with new improvement in score message!
Best parameter choice score by now is 0.47154150197628464
In parameter choice num 0 / 149 avg score was: 0.47154150197628464.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.500 total time=  12.3s
Parameter choice num 1 / 149 - starting...
5 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 0 0 0 1 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.6521739130434783 
>>>
predicted correctly / predicted_in_total = 15 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.652 total time=   4.0s
6 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.522 total time=   1.8s
7 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 0 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.18181818181818182 
>>>
predicted correctly / predicted_in_total = 4 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.182 total time=   1.9s
8 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 1 1 0 0 1 1 0 1 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.364 total time=   2.3s
9 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 0 1 1 0 0 0 0 1 1 0]
scoring metric: accuracy, score: 0.6818181818181818 
>>>
predicted correctly / predicted_in_total = 15 / 22
<<<
New improvement!
New best score is 0.4802371541501976
In parameter choice num 1 / 149 avg score was: 0.4802371541501976.
updating 2023-08-05 18_15_18_accuracy_150_RF\search_statistics.txt...
statistics file updated successfully with new improvement in score message!
Best parameter choice score by now is 0.4802371541501976
In parameter choice num 1 / 149 avg score was: 0.4802371541501976.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.682 total time=   3.0s
Parameter choice num 2 / 149 - starting...
10 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.4782608695652174 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.478 total time=   2.5s
11 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.565 total time=   3.4s
12 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   2.1s
13 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.2727272727272727 
>>>
predicted correctly / predicted_in_total = 6 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.273 total time=   1.3s
14 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 1 0]
scoring metric: accuracy, score: 0.5454545454545454 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.4802371541501976
In parameter choice num 2 / 149 avg score was: 0.43596837944664024.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.545 total time=   1.2s
Parameter choice num 3 / 149 - starting...
15 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: accuracy, score: 0.34782608695652173 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.348 total time=   4.1s
16 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.565 total time=   3.5s
17 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   3.4s
18 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   3.5s
19 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0]
scoring metric: accuracy, score: 0.5454545454545454 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.4802371541501976
In parameter choice num 3 / 149 avg score was: 0.41897233201581024.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.545 total time=   4.5s
Parameter choice num 4 / 149 - starting...
20 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 1 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.565 total time=   0.9s
21 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.4782608695652174 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.478 total time=   0.5s
22 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: accuracy, score: 0.22727272727272727 
>>>
predicted correctly / predicted_in_total = 5 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.227 total time=   0.9s
23 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 1 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.364 total time=   0.8s
24 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 1 0]
scoring metric: accuracy, score: 0.5909090909090909 
>>>
predicted correctly / predicted_in_total = 13 / 22
<<<
Best parameter choice score by now is 0.4802371541501976
In parameter choice num 4 / 149 avg score was: 0.4450592885375494.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.591 total time=   0.4s
Parameter choice num 5 / 149 - starting...
25 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.609 total time=   1.0s
26 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.522 total time=   1.1s
27 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: accuracy, score: 0.18181818181818182 
>>>
predicted correctly / predicted_in_total = 4 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.182 total time=   1.1s
28 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.318 total time=   1.1s
29 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0]
scoring metric: accuracy, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 14 / 22
<<<
Best parameter choice score by now is 0.4802371541501976
In parameter choice num 5 / 149 avg score was: 0.4533596837944664.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.636 total time=   1.0s
Parameter choice num 6 / 149 - starting...
30 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 0 1 0]
scoring metric: accuracy, score: 0.43478260869565216 
>>>
predicted correctly / predicted_in_total = 10 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.435 total time=   0.4s
31 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.565 total time=   0.4s
32 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 0 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.2727272727272727 
>>>
predicted correctly / predicted_in_total = 6 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.273 total time=   0.4s
33 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.22727272727272727 
>>>
predicted correctly / predicted_in_total = 5 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.227 total time=   0.4s
34 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.4802371541501976
In parameter choice num 6 / 149 avg score was: 0.4.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.500 total time=   0.5s
Parameter choice num 7 / 149 - starting...
35 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 1 1]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.522 total time=   3.8s
36 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.609 total time=   4.2s
37 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   3.9s
38 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   3.7s
39 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5454545454545454 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
New improvement!
New best score is 0.48063241106719373
In parameter choice num 7 / 149 avg score was: 0.48063241106719373.
updating 2023-08-05 18_15_18_accuracy_150_RF\search_statistics.txt...
statistics file updated successfully with new improvement in score message!
Best parameter choice score by now is 0.48063241106719373
In parameter choice num 7 / 149 avg score was: 0.48063241106719373.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.545 total time=   4.9s
Parameter choice num 8 / 149 - starting...
40 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 0 0 0 0 0 0 0 1 1 1 0 1 1 1 0 1 1]
scoring metric: accuracy, score: 0.6521739130434783 
>>>
predicted correctly / predicted_in_total = 15 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.652 total time=   0.7s
41 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.609 total time=   1.3s
42 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.409 total time=   0.6s
43 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   0.4s
44 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5909090909090909 
>>>
predicted correctly / predicted_in_total = 13 / 22
<<<
New improvement!
New best score is 0.524901185770751
In parameter choice num 8 / 149 avg score was: 0.524901185770751.
updating 2023-08-05 18_15_18_accuracy_150_RF\search_statistics.txt...
statistics file updated successfully with new improvement in score message!
Best parameter choice score by now is 0.524901185770751
In parameter choice num 8 / 149 avg score was: 0.524901185770751.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.591 total time=   0.5s
Parameter choice num 9 / 149 - starting...
45 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.565 total time=   0.4s
46 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.565 total time=   0.7s
47 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.364 total time=   0.6s
48 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   0.6s
49 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 1 0]
scoring metric: accuracy, score: 0.5454545454545454 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 9 / 149 avg score was: 0.4715415019762846.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.545 total time=   0.8s
Parameter choice num 10 / 149 - starting...
50 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.4782608695652174 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.478 total time=   2.5s
51 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.522 total time=   3.7s
52 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   3.4s
53 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.364 total time=   2.1s
54 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0]
scoring metric: accuracy, score: 0.5454545454545454 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 10 / 149 avg score was: 0.44545454545454544.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.545 total time=   1.6s
Parameter choice num 11 / 149 - starting...
55 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.565 total time=   1.0s
56 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.522 total time=   1.7s
57 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   1.6s
58 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   2.0s
59 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 11 / 149 avg score was: 0.44466403162055335.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.500 total time=   2.1s
Parameter choice num 12 / 149 - starting...
60 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 1 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.522 total time=   5.0s
61 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.522 total time=   4.4s
62 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   4.0s
63 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   5.7s
64 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0]
scoring metric: accuracy, score: 0.5454545454545454 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 12 / 149 avg score was: 0.4450592885375494.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.545 total time=   4.5s
Parameter choice num 13 / 149 - starting...
65 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: accuracy, score: 0.34782608695652173 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.348 total time=   5.2s
66 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.565 total time=   3.9s
67 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   3.7s
68 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   4.0s
69 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 13 / 149 avg score was: 0.40988142292490115.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.500 total time=   4.6s
Parameter choice num 14 / 149 - starting...
70 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 1 1 0 0 0 1 1 0 1 0 1 0 1 1]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.609 total time=   1.7s
71 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.609 total time=   1.3s
72 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.409 total time=   1.2s
73 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   1.2s
74 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 14 / 149 avg score was: 0.49802371541501983.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.500 total time=   1.2s
Parameter choice num 15 / 149 - starting...
75 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 1 1 0 0 0 1 1 0 1 0 1 0 1 1]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.609 total time=   1.2s
76 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.609 total time=   1.5s
77 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.409 total time=   3.2s
78 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   2.9s
79 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 15 / 149 avg score was: 0.49802371541501983.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.500 total time=   2.0s
Parameter choice num 16 / 149 - starting...
80 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 1 0 1 0 1 1]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.522 total time=   0.5s
81 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 0 0 0 0 1 1 1 1 1 1 0 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.565 total time=   0.5s
82 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.318 total time=   0.5s
83 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.409 total time=   0.6s
84 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 16 / 149 avg score was: 0.4628458498023715.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   0.5s
Parameter choice num 17 / 149 - starting...
85 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 1 0 0 0 1 1 1 1 0 1 0 1 0]
scoring metric: accuracy, score: 0.43478260869565216 
>>>
predicted correctly / predicted_in_total = 10 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.435 total time=   4.2s
86 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 0]
scoring metric: accuracy, score: 0.6521739130434783 
>>>
predicted correctly / predicted_in_total = 15 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.652 total time=   3.7s
87 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.364 total time=   3.5s
88 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.364 total time=   3.6s
89 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 17 / 149 avg score was: 0.4628458498023716.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   3.8s
Parameter choice num 18 / 149 - starting...
90 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 1 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.522 total time=   3.7s
91 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.522 total time=   4.2s
92 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   4.8s
93 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   3.7s
94 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0]
scoring metric: accuracy, score: 0.5454545454545454 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 18 / 149 avg score was: 0.4450592885375494.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.545 total time=   4.6s
Parameter choice num 19 / 149 - starting...
95 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 1 0 1 0 1 1]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.522 total time=   4.6s
96 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 0]
scoring metric: accuracy, score: 0.6521739130434783 
>>>
predicted correctly / predicted_in_total = 15 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.652 total time=   5.0s
97 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.409 total time=   6.8s
98 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   5.4s
99 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 1 0 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 19 / 149 avg score was: 0.4984189723320158.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   3.7s
Parameter choice num 20 / 149 - starting...
100 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.609 total time=   0.9s
101 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.522 total time=   1.0s
102 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: accuracy, score: 0.18181818181818182 
>>>
predicted correctly / predicted_in_total = 4 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.182 total time=   1.0s
103 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.318 total time=   1.0s
104 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0]
scoring metric: accuracy, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 14 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 20 / 149 avg score was: 0.4533596837944664.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.636 total time=   0.9s
Parameter choice num 21 / 149 - starting...
105 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 1 1 0 0 0 1 1 0 1 0 1 0 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.565 total time=   0.4s
106 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 0 1 1 1 1 1 0 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.609 total time=   0.4s
107 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.409 total time=   0.4s
108 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   0.4s
109 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5454545454545454 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 21 / 149 avg score was: 0.4984189723320158.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.545 total time=   0.4s
Parameter choice num 22 / 149 - starting...
110 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.522 total time=   1.0s
111 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 0 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.565 total time=   1.0s
112 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   1.1s
113 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   1.1s
114 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 1 0]
scoring metric: accuracy, score: 0.5454545454545454 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 22 / 149 avg score was: 0.4537549407114624.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.545 total time=   1.4s
Parameter choice num 23 / 149 - starting...
115 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 0 1 0]
scoring metric: accuracy, score: 0.391304347826087 
>>>
predicted correctly / predicted_in_total = 9 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.391 total time=   1.6s
116 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.565 total time=   1.3s
117 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   1.9s
118 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   1.9s
119 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 23 / 149 avg score was: 0.47312252964426876.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   1.1s
Parameter choice num 24 / 149 - starting...
120 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.522 total time=   1.1s
121 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.4782608695652174 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.478 total time=   1.1s
122 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: accuracy, score: 0.18181818181818182 
>>>
predicted correctly / predicted_in_total = 4 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.182 total time=   1.0s
123 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.318 total time=   1.0s
124 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0]
scoring metric: accuracy, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 14 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 24 / 149 avg score was: 0.42727272727272725.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.636 total time=   1.0s
Parameter choice num 25 / 149 - starting...
125 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 1 0 0 0 1 1 1 1 0 1 0 1 1]
scoring metric: accuracy, score: 0.4782608695652174 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.478 total time=   4.2s
126 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 0]
scoring metric: accuracy, score: 0.6521739130434783 
>>>
predicted correctly / predicted_in_total = 15 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.652 total time=   4.2s
127 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.409 total time=   6.7s
128 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   3.6s
129 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 25 / 149 avg score was: 0.4988142292490119.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   3.5s
Parameter choice num 26 / 149 - starting...
130 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: accuracy, score: 0.391304347826087 
>>>
predicted correctly / predicted_in_total = 9 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.391 total time=   3.4s
131 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.522 total time=   3.3s
132 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   3.3s
133 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   3.5s
134 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0]
scoring metric: accuracy, score: 0.5454545454545454 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 26 / 149 avg score was: 0.41897233201581024.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.545 total time=   3.9s
Parameter choice num 27 / 149 - starting...
135 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: accuracy, score: 0.34782608695652173 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.348 total time=   4.5s
136 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.609 total time=   3.8s
137 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   5.1s
138 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.409 total time=   3.6s
139 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 1 0 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 27 / 149 avg score was: 0.4549407114624506.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   3.4s
Parameter choice num 28 / 149 - starting...
140 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.522 total time=   0.4s
141 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.565 total time=   0.4s
142 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.409 total time=   0.4s
143 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   0.4s
144 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5454545454545454 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 28 / 149 avg score was: 0.4810276679841897.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.545 total time=   0.4s
Parameter choice num 29 / 149 - starting...
145 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 1 1 0 0 0 1 1 0 1 0 1 0 1 1]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.609 total time=   1.1s
146 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.609 total time=   1.1s
147 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.409 total time=   1.2s
148 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   1.2s
149 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 29 / 149 avg score was: 0.49802371541501983.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.500 total time=   1.1s
Parameter choice num 30 / 149 - starting...
150 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 0 1 0]
scoring metric: accuracy, score: 0.391304347826087 
>>>
predicted correctly / predicted_in_total = 9 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.391 total time=   4.2s
151 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.609 total time=   4.8s
152 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.409 total time=   5.6s
153 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.364 total time=   3.5s
154 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 30 / 149 avg score was: 0.4545454545454546.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   3.5s
Parameter choice num 31 / 149 - starting...
155 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1 0]
scoring metric: accuracy, score: 0.4782608695652174 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.478 total time=   1.0s
156 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.609 total time=   1.2s
157 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   1.1s
158 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   1.2s
159 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 31 / 149 avg score was: 0.4628458498023716.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.500 total time=   1.1s
Parameter choice num 32 / 149 - starting...
160 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.43478260869565216 
>>>
predicted correctly / predicted_in_total = 10 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.435 total time=   1.0s
161 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.565 total time=   1.0s
162 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.409 total time=   1.0s
163 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.409 total time=   1.1s
164 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 32 / 149 avg score was: 0.4636363636363637.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   1.1s
Parameter choice num 33 / 149 - starting...
165 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 1 0 1 0 1 0]
scoring metric: accuracy, score: 0.34782608695652173 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.348 total time=   4.3s
166 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.565 total time=   4.8s
167 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.409 total time=   4.0s
168 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.409 total time=   3.7s
169 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 33 / 149 avg score was: 0.4462450592885375.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   3.8s
Parameter choice num 34 / 149 - starting...
170 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.565 total time=   5.6s
171 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.522 total time=   6.1s
172 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.13636363636363635 
>>>
predicted correctly / predicted_in_total = 3 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.136 total time=   5.8s
173 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.364 total time=   5.7s
174 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 0 1 1 0 0 0 0 1 1 0]
scoring metric: accuracy, score: 0.6818181818181818 
>>>
predicted correctly / predicted_in_total = 15 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 34 / 149 avg score was: 0.4537549407114624.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.682 total time=   3.5s
Parameter choice num 35 / 149 - starting...
175 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: accuracy, score: 0.43478260869565216 
>>>
predicted correctly / predicted_in_total = 10 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.435 total time=   0.9s
176 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.565 total time=   1.1s
177 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   1.0s
178 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.364 total time=   1.0s
179 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 35 / 149 avg score was: 0.43636363636363634.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.500 total time=   1.0s
Parameter choice num 36 / 149 - starting...
180 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.43478260869565216 
>>>
predicted correctly / predicted_in_total = 10 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.435 total time=   0.4s
181 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 0]
scoring metric: accuracy, score: 0.6521739130434783 
>>>
predicted correctly / predicted_in_total = 15 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.652 total time=   0.4s
182 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.409 total time=   0.4s
183 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.364 total time=   0.4s
184 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5909090909090909 
>>>
predicted correctly / predicted_in_total = 13 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 36 / 149 avg score was: 0.4901185770750988.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.591 total time=   0.4s
Parameter choice num 37 / 149 - starting...
185 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 1 1]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.565 total time=   0.4s
186 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.609 total time=   0.4s
187 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   0.4s
188 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 1 1 1 0 1 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.455 total time=   0.5s
189 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5909090909090909 
>>>
predicted correctly / predicted_in_total = 13 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 37 / 149 avg score was: 0.516600790513834.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.591 total time=   0.5s
Parameter choice num 38 / 149 - starting...
190 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: accuracy, score: 0.34782608695652173 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.348 total time=   1.2s
191 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.565 total time=   1.5s
192 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.364 total time=   1.1s
193 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.364 total time=   1.7s
194 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 38 / 149 avg score was: 0.42806324110671934.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   2.0s
Parameter choice num 39 / 149 - starting...
195 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 1 0 1 1]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.565 total time=   1.3s
196 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 0]
scoring metric: accuracy, score: 0.6521739130434783 
>>>
predicted correctly / predicted_in_total = 15 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.652 total time=   0.9s
197 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.364 total time=   0.9s
198 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.409 total time=   0.7s
199 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 39 / 149 avg score was: 0.49802371541501983.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   0.6s
Parameter choice num 40 / 149 - starting...
200 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: accuracy, score: 0.391304347826087 
>>>
predicted correctly / predicted_in_total = 9 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.391 total time=   3.7s
201 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.522 total time=   3.6s
202 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   3.4s
203 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   3.1s
204 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 1 0]
scoring metric: accuracy, score: 0.5909090909090909 
>>>
predicted correctly / predicted_in_total = 13 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 40 / 149 avg score was: 0.42806324110671934.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.591 total time=   3.6s
Parameter choice num 41 / 149 - starting...
205 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 0 1 0]
scoring metric: accuracy, score: 0.43478260869565216 
>>>
predicted correctly / predicted_in_total = 10 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.435 total time=   0.9s
206 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 0 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.565 total time=   0.5s
207 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.364 total time=   0.4s
208 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   0.4s
209 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 1 0]
scoring metric: accuracy, score: 0.5454545454545454 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 41 / 149 avg score was: 0.4454545454545455.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.545 total time=   0.4s
Parameter choice num 42 / 149 - starting...
210 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: accuracy, score: 0.34782608695652173 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.348 total time=   1.2s
211 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.609 total time=   1.6s
212 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   1.1s
213 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.409 total time=   1.0s
214 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 42 / 149 avg score was: 0.4640316205533598.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   1.1s
Parameter choice num 43 / 149 - starting...
215 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.522 total time=   1.2s
216 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.522 total time=   1.1s
217 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: accuracy, score: 0.22727272727272727 
>>>
predicted correctly / predicted_in_total = 5 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.227 total time=   1.1s
218 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.2727272727272727 
>>>
predicted correctly / predicted_in_total = 6 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.273 total time=   1.0s
219 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0]
scoring metric: accuracy, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 14 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 43 / 149 avg score was: 0.43596837944664035.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.636 total time=   1.3s
Parameter choice num 44 / 149 - starting...
220 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.522 total time=   1.1s
221 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.522 total time=   1.0s
222 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: accuracy, score: 0.18181818181818182 
>>>
predicted correctly / predicted_in_total = 4 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.182 total time=   0.9s
223 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 0 1 1 0 1 0 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.2727272727272727 
>>>
predicted correctly / predicted_in_total = 6 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.273 total time=   1.1s
224 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0]
scoring metric: accuracy, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 14 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 44 / 149 avg score was: 0.42687747035573126.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.636 total time=   1.4s
Parameter choice num 45 / 149 - starting...
225 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 1 0 1 0]
scoring metric: accuracy, score: 0.43478260869565216 
>>>
predicted correctly / predicted_in_total = 10 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.435 total time=   0.4s
226 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 0 0 0 0 1 1 1 1 1 1 0 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.565 total time=   0.9s
227 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.364 total time=   0.8s
228 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 0 0 1 0 1 1 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   0.7s
229 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 1 0 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 45 / 149 avg score was: 0.4545454545454546.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   0.6s
Parameter choice num 46 / 149 - starting...
230 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.522 total time=   1.5s
231 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.522 total time=   1.1s
232 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: accuracy, score: 0.22727272727272727 
>>>
predicted correctly / predicted_in_total = 5 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.227 total time=   1.1s
233 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.2727272727272727 
>>>
predicted correctly / predicted_in_total = 6 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.273 total time=   1.0s
234 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0]
scoring metric: accuracy, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 14 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 46 / 149 avg score was: 0.43596837944664035.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.636 total time=   1.1s
Parameter choice num 47 / 149 - starting...
235 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1 0]
scoring metric: accuracy, score: 0.4782608695652174 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.478 total time=   1.7s
236 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.609 total time=   1.1s
237 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   1.1s
238 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   1.2s
239 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 47 / 149 avg score was: 0.4628458498023716.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.500 total time=   1.4s
Parameter choice num 48 / 149 - starting...
240 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.522 total time=   1.0s
241 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.522 total time=   0.9s
242 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: accuracy, score: 0.22727272727272727 
>>>
predicted correctly / predicted_in_total = 5 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.227 total time=   1.0s
243 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.2727272727272727 
>>>
predicted correctly / predicted_in_total = 6 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.273 total time=   1.0s
244 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0]
scoring metric: accuracy, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 14 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 48 / 149 avg score was: 0.43596837944664035.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.636 total time=   1.0s
Parameter choice num 49 / 149 - starting...
245 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 1 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.522 total time=   1.0s
246 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 0 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.565 total time=   1.0s
247 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   1.1s
248 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   1.1s
249 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 49 / 149 avg score was: 0.44466403162055335.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.500 total time=   1.1s
Parameter choice num 50 / 149 - starting...
250 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.522 total time=   1.0s
251 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.609 total time=   1.0s
252 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   1.0s
253 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   1.2s
254 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 50 / 149 avg score was: 0.47154150197628464.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.500 total time=   1.0s
Parameter choice num 51 / 149 - starting...
255 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: accuracy, score: 0.34782608695652173 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.348 total time=   1.6s
256 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.609 total time=   2.2s
257 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   2.4s
258 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.409 total time=   1.5s
259 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 51 / 149 avg score was: 0.4640316205533598.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   1.1s
Parameter choice num 52 / 149 - starting...
260 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.565 total time=   1.0s
261 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.4782608695652174 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.478 total time=   1.0s
262 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: accuracy, score: 0.22727272727272727 
>>>
predicted correctly / predicted_in_total = 5 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.227 total time=   0.9s
263 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.2727272727272727 
>>>
predicted correctly / predicted_in_total = 6 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.273 total time=   1.0s
264 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0]
scoring metric: accuracy, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 14 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 52 / 149 avg score was: 0.43596837944664035.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.636 total time=   1.2s
Parameter choice num 53 / 149 - starting...
265 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.522 total time=   0.5s
266 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.565 total time=   0.5s
267 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   0.4s
268 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.409 total time=   0.4s
269 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 1 0]
scoring metric: accuracy, score: 0.5909090909090909 
>>>
predicted correctly / predicted_in_total = 13 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 53 / 149 avg score was: 0.4810276679841897.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.591 total time=   0.4s
Parameter choice num 54 / 149 - starting...
270 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 0 1 1]
scoring metric: accuracy, score: 0.43478260869565216 
>>>
predicted correctly / predicted_in_total = 10 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.435 total time=   1.0s
271 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.609 total time=   1.3s
272 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.409 total time=   1.2s
273 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   1.7s
274 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 54 / 149 avg score was: 0.48142292490118577.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   1.2s
Parameter choice num 55 / 149 - starting...
275 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 0 0 0 1 0 0 0 1 1 1 0 1 0 1 0 1 1]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.609 total time=   0.4s
276 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 0]
scoring metric: accuracy, score: 0.6521739130434783 
>>>
predicted correctly / predicted_in_total = 15 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.652 total time=   0.4s
277 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 0 1 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   0.5s
278 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 1 0 1 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.409 total time=   0.4s
279 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0]
scoring metric: accuracy, score: 0.5454545454545454 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 55 / 149 avg score was: 0.5158102766798419.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.545 total time=   0.4s
Parameter choice num 56 / 149 - starting...
280 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.565 total time=   3.6s
281 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 1 0 0 0 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.43478260869565216 
>>>
predicted correctly / predicted_in_total = 10 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.435 total time=   3.5s
282 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: accuracy, score: 0.18181818181818182 
>>>
predicted correctly / predicted_in_total = 4 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.182 total time=   3.3s
283 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.22727272727272727 
>>>
predicted correctly / predicted_in_total = 5 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.227 total time=   3.1s
284 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0]
scoring metric: accuracy, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 14 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 56 / 149 avg score was: 0.40909090909090906.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.636 total time=   3.3s
Parameter choice num 57 / 149 - starting...
285 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: accuracy, score: 0.34782608695652173 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.348 total time=   4.5s
286 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.609 total time=   3.4s
287 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.409 total time=   4.3s
288 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.364 total time=   4.0s
289 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 1 0 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 57 / 149 avg score was: 0.43675889328063244.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   5.7s
Parameter choice num 58 / 149 - starting...
290 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.565 total time=   4.4s
291 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.522 total time=   3.3s
292 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: accuracy, score: 0.18181818181818182 
>>>
predicted correctly / predicted_in_total = 4 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.182 total time=   4.1s
293 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.318 total time=   4.4s
294 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 0 1 1 0 0 0 0 1 1 0]
scoring metric: accuracy, score: 0.6818181818181818 
>>>
predicted correctly / predicted_in_total = 15 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 58 / 149 avg score was: 0.4537549407114624.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.682 total time=   5.2s
Parameter choice num 59 / 149 - starting...
295 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.565 total time=   0.8s
296 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.522 total time=   0.6s
297 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: accuracy, score: 0.18181818181818182 
>>>
predicted correctly / predicted_in_total = 4 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.182 total time=   0.7s
298 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.318 total time=   0.6s
299 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 0 1 1 0 0 0 0 1 1 0]
scoring metric: accuracy, score: 0.6818181818181818 
>>>
predicted correctly / predicted_in_total = 15 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 59 / 149 avg score was: 0.4537549407114624.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.682 total time=   0.6s
Parameter choice num 60 / 149 - starting...
300 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: accuracy, score: 0.34782608695652173 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.348 total time=   1.7s
301 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.609 total time=   1.0s
302 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   1.0s
303 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.409 total time=   1.0s
304 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 60 / 149 avg score was: 0.4640316205533598.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   1.4s
Parameter choice num 61 / 149 - starting...
305 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0]
scoring metric: accuracy, score: 0.43478260869565216 
>>>
predicted correctly / predicted_in_total = 10 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.435 total time=   1.0s
306 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 0 0 0 0 1 1 1 1 1 1 0 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.565 total time=   0.9s
307 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.364 total time=   0.6s
308 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 0 1 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.5454545454545454 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.545 total time=   0.9s
309 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 1 0 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 61 / 149 avg score was: 0.4727272727272728.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   0.7s
Parameter choice num 62 / 149 - starting...
310 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: accuracy, score: 0.391304347826087 
>>>
predicted correctly / predicted_in_total = 9 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.391 total time=   1.5s
311 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.565 total time=   1.2s
312 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   1.2s
313 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   1.0s
314 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 62 / 149 avg score was: 0.4094861660079051.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.455 total time=   1.3s
Parameter choice num 63 / 149 - starting...
315 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 1 1]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.565 total time=   1.7s
316 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.609 total time=   2.0s
317 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   2.1s
318 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   2.2s
319 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5454545454545454 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 63 / 149 avg score was: 0.4893280632411067.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.545 total time=   2.2s
Parameter choice num 64 / 149 - starting...
320 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.522 total time=   4.3s
321 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.522 total time=   2.8s
322 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: accuracy, score: 0.18181818181818182 
>>>
predicted correctly / predicted_in_total = 4 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.182 total time=   2.6s
323 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.318 total time=   1.5s
324 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0]
scoring metric: accuracy, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 14 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 64 / 149 avg score was: 0.43596837944664035.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.636 total time=   1.9s
Parameter choice num 65 / 149 - starting...
325 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 1 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.565 total time=   0.5s
326 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.4782608695652174 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.478 total time=   0.6s
327 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: accuracy, score: 0.22727272727272727 
>>>
predicted correctly / predicted_in_total = 5 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.227 total time=   0.6s
328 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 1 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.364 total time=   0.6s
329 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 1 0]
scoring metric: accuracy, score: 0.5909090909090909 
>>>
predicted correctly / predicted_in_total = 13 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 65 / 149 avg score was: 0.4450592885375494.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.591 total time=   0.7s
Parameter choice num 66 / 149 - starting...
330 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.522 total time=   0.6s
331 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.565 total time=   0.6s
332 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.318 total time=   0.7s
333 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   0.6s
334 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5454545454545454 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 66 / 149 avg score was: 0.48102766798418967.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.545 total time=   0.6s
Parameter choice num 67 / 149 - starting...
335 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.609 total time=   1.7s
336 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.522 total time=   1.5s
337 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: accuracy, score: 0.18181818181818182 
>>>
predicted correctly / predicted_in_total = 4 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.182 total time=   1.8s
338 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.318 total time=   1.5s
339 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0]
scoring metric: accuracy, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 14 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 67 / 149 avg score was: 0.4533596837944664.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.636 total time=   1.7s
Parameter choice num 68 / 149 - starting...
340 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 1 1]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.565 total time=   1.9s
341 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.609 total time=   1.9s
342 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   1.8s
343 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   1.8s
344 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5454545454545454 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 68 / 149 avg score was: 0.4893280632411067.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.545 total time=   1.2s
Parameter choice num 69 / 149 - starting...
345 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.565 total time=   0.4s
346 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.565 total time=   0.5s
347 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.364 total time=   0.4s
348 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   0.4s
349 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 1 0]
scoring metric: accuracy, score: 0.5454545454545454 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 69 / 149 avg score was: 0.4715415019762846.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.545 total time=   0.4s
Parameter choice num 70 / 149 - starting...
350 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.565 total time=   1.2s
351 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.522 total time=   1.3s
352 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   1.2s
353 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   1.0s
354 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 70 / 149 avg score was: 0.44466403162055335.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.500 total time=   1.0s
Parameter choice num 71 / 149 - starting...
355 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.522 total time=   0.9s
356 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.609 total time=   1.0s
357 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   1.0s
358 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   1.0s
359 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 71 / 149 avg score was: 0.47154150197628464.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.500 total time=   1.0s
Parameter choice num 72 / 149 - starting...
360 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.522 total time=   0.4s
361 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.565 total time=   0.4s
362 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   0.4s
363 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.409 total time=   0.4s
364 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 1 0]
scoring metric: accuracy, score: 0.5909090909090909 
>>>
predicted correctly / predicted_in_total = 13 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 72 / 149 avg score was: 0.4810276679841897.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.591 total time=   0.4s
Parameter choice num 73 / 149 - starting...
365 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.522 total time=   1.1s
366 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.609 total time=   1.0s
367 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   1.0s
368 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   1.1s
369 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 73 / 149 avg score was: 0.47154150197628464.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.500 total time=   1.4s
Parameter choice num 74 / 149 - starting...
370 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 1 0 1 0]
scoring metric: accuracy, score: 0.43478260869565216 
>>>
predicted correctly / predicted_in_total = 10 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.435 total time=   0.9s
371 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 0 0 0 0 1 1 1 1 1 1 0 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.565 total time=   0.4s
372 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.364 total time=   0.4s
373 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 0 0 1 0 1 1 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   0.4s
374 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 1 0 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 74 / 149 avg score was: 0.4545454545454546.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   0.4s
Parameter choice num 75 / 149 - starting...
375 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.565 total time=   0.5s
376 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.609 total time=   0.6s
377 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.409 total time=   0.5s
378 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   0.4s
379 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5454545454545454 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 75 / 149 avg score was: 0.4984189723320158.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.545 total time=   0.4s
Parameter choice num 76 / 149 - starting...
380 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 1 1 0]
scoring metric: accuracy, score: 0.4782608695652174 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.478 total time=   0.4s
381 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.4782608695652174 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.478 total time=   0.4s
382 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: accuracy, score: 0.2727272727272727 
>>>
predicted correctly / predicted_in_total = 6 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.273 total time=   0.4s
383 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 1 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.364 total time=   0.4s
384 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 1 0]
scoring metric: accuracy, score: 0.5909090909090909 
>>>
predicted correctly / predicted_in_total = 13 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 76 / 149 avg score was: 0.43675889328063244.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.591 total time=   0.4s
Parameter choice num 77 / 149 - starting...
385 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: accuracy, score: 0.34782608695652173 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.348 total time=   7.4s
386 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.522 total time=   5.8s
387 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   4.8s
388 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=  15.4s
389 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 77 / 149 avg score was: 0.4011857707509881.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.500 total time=   5.1s
Parameter choice num 78 / 149 - starting...
390 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 1 0 1 1]
scoring metric: accuracy, score: 0.4782608695652174 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.478 total time=   1.0s
391 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 0 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.522 total time=   1.0s
392 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.364 total time=   1.3s
393 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   1.2s
394 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5454545454545454 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 78 / 149 avg score was: 0.4727272727272728.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.545 total time=   1.4s
Parameter choice num 79 / 149 - starting...
395 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 1 1]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.522 total time=   0.6s
396 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.609 total time=   0.4s
397 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.409 total time=   0.5s
398 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   0.5s
399 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5454545454545454 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 79 / 149 avg score was: 0.4897233201581028.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.545 total time=   0.4s
Parameter choice num 80 / 149 - starting...
400 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: accuracy, score: 0.34782608695652173 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.348 total time=   4.9s
401 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.565 total time=   3.7s
402 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   3.4s
403 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   3.4s
404 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 80 / 149 avg score was: 0.40988142292490115.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.500 total time=   3.5s
Parameter choice num 81 / 149 - starting...
405 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.43478260869565216 
>>>
predicted correctly / predicted_in_total = 10 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.435 total time=   1.0s
406 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.565 total time=   1.0s
407 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.409 total time=   1.0s
408 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.409 total time=   1.0s
409 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 81 / 149 avg score was: 0.4636363636363637.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   1.0s
Parameter choice num 82 / 149 - starting...
410 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 1 1 0]
scoring metric: accuracy, score: 0.4782608695652174 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.478 total time=   0.4s
411 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.4782608695652174 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.478 total time=   0.4s
412 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: accuracy, score: 0.2727272727272727 
>>>
predicted correctly / predicted_in_total = 6 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.273 total time=   0.4s
413 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 1 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.364 total time=   0.4s
414 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 1 0]
scoring metric: accuracy, score: 0.5909090909090909 
>>>
predicted correctly / predicted_in_total = 13 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 82 / 149 avg score was: 0.43675889328063244.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.591 total time=   0.4s
Parameter choice num 83 / 149 - starting...
415 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.522 total time=   1.0s
416 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.522 total time=   0.9s
417 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.409 total time=   1.0s
418 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   1.0s
419 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0]
scoring metric: accuracy, score: 0.5454545454545454 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 83 / 149 avg score was: 0.4632411067193676.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.545 total time=   1.0s
Parameter choice num 84 / 149 - starting...
420 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.522 total time=   3.9s
421 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.609 total time=   3.8s
422 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   3.7s
423 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   4.1s
424 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 84 / 149 avg score was: 0.47154150197628464.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.500 total time=   3.6s
Parameter choice num 85 / 149 - starting...
425 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.565 total time=   3.4s
426 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.522 total time=   3.3s
427 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.13636363636363635 
>>>
predicted correctly / predicted_in_total = 3 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.136 total time=   4.0s
428 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 0 1 1 0 1 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.318 total time=   3.6s
429 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 0 1 1 0 0 0 0 1 1 0]
scoring metric: accuracy, score: 0.6818181818181818 
>>>
predicted correctly / predicted_in_total = 15 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 85 / 149 avg score was: 0.44466403162055335.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.682 total time=   3.2s
Parameter choice num 86 / 149 - starting...
430 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: accuracy, score: 0.34782608695652173 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.348 total time=   0.4s
431 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 0 0 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.522 total time=   0.4s
432 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   0.4s
433 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 1 0 1 1 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   0.4s
434 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 1 0 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 86 / 149 avg score was: 0.44664031620553357.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   0.4s
Parameter choice num 87 / 149 - starting...
435 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.4782608695652174 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.478 total time=   1.0s
436 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 0 0 0 0 1 1 1 1 1 1 0 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.522 total time=   1.0s
437 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   1.0s
438 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   1.0s
439 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 87 / 149 avg score was: 0.42727272727272725.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.500 total time=   1.0s
Parameter choice num 88 / 149 - starting...
440 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.522 total time=   0.4s
441 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.565 total time=   0.4s
442 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   0.4s
443 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.409 total time=   0.4s
444 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 1 0]
scoring metric: accuracy, score: 0.5909090909090909 
>>>
predicted correctly / predicted_in_total = 13 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 88 / 149 avg score was: 0.4810276679841897.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.591 total time=   0.4s
Parameter choice num 89 / 149 - starting...
445 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1 1 0 1 0 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.565 total time=   0.4s
446 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.522 total time=   0.4s
447 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.364 total time=   0.4s
448 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   0.4s
449 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0]
scoring metric: accuracy, score: 0.5454545454545454 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 89 / 149 avg score was: 0.4628458498023715.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.545 total time=   0.4s
Parameter choice num 90 / 149 - starting...
450 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 1 1 1 0 0 0 1 0 0 0 1 1 1 1 0 1 0 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.522 total time=   0.4s
451 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 0 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.565 total time=   0.4s
452 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   0.4s
453 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 1 1 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.455 total time=   0.4s
454 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 90 / 149 avg score was: 0.4719367588932807.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.500 total time=   0.4s
Parameter choice num 91 / 149 - starting...
455 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.522 total time=   1.0s
456 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.522 total time=   1.0s
457 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: accuracy, score: 0.18181818181818182 
>>>
predicted correctly / predicted_in_total = 4 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.182 total time=   1.1s
458 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.318 total time=   1.0s
459 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0]
scoring metric: accuracy, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 14 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 91 / 149 avg score was: 0.43596837944664035.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.636 total time=   1.0s
Parameter choice num 92 / 149 - starting...
460 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.4782608695652174 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.478 total time=   1.0s
461 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 0 0 0 0 1 1 1 1 1 1 0 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.522 total time=   1.0s
462 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   1.1s
463 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   1.0s
464 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 92 / 149 avg score was: 0.42727272727272725.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.500 total time=   1.3s
Parameter choice num 93 / 149 - starting...
465 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 1 1 1 0 0 0 1 0 0 0 1 1 1 1 0 1 0 1 1]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.565 total time=   0.5s
466 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.522 total time=   0.6s
467 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.364 total time=   0.5s
468 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 1 0 1 1 0 1 0 0 1 0 0 0 0 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.364 total time=   0.5s
469 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0]
scoring metric: accuracy, score: 0.5454545454545454 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 93 / 149 avg score was: 0.4719367588932807.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.545 total time=   0.5s
Parameter choice num 94 / 149 - starting...
470 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 0 0 0 0 0 0 0 1 1 1 0 1 1 1 0 1 1]
scoring metric: accuracy, score: 0.6521739130434783 
>>>
predicted correctly / predicted_in_total = 15 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.652 total time=   0.4s
471 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.609 total time=   0.5s
472 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.409 total time=   0.6s
473 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   0.5s
474 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5909090909090909 
>>>
predicted correctly / predicted_in_total = 13 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 94 / 149 avg score was: 0.524901185770751.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.591 total time=   0.5s
Parameter choice num 95 / 149 - starting...
475 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.565 total time=   3.4s
476 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.522 total time=   3.3s
477 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: accuracy, score: 0.18181818181818182 
>>>
predicted correctly / predicted_in_total = 4 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.182 total time=   3.7s
478 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.318 total time=  10.4s
479 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0]
scoring metric: accuracy, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 14 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 95 / 149 avg score was: 0.44466403162055335.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.636 total time=   5.6s
Parameter choice num 96 / 149 - starting...
480 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.565 total time=   5.5s
481 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.4782608695652174 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.478 total time=   5.4s
482 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: accuracy, score: 0.18181818181818182 
>>>
predicted correctly / predicted_in_total = 4 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.182 total time=   5.1s
483 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.2727272727272727 
>>>
predicted correctly / predicted_in_total = 6 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.273 total time=   4.5s
484 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0]
scoring metric: accuracy, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 14 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 96 / 149 avg score was: 0.42687747035573126.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.636 total time=   3.9s
Parameter choice num 97 / 149 - starting...
485 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.522 total time=   1.0s
486 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.609 total time=   1.0s
487 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   1.0s
488 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   1.0s
489 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 97 / 149 avg score was: 0.47154150197628464.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=300;, score=0.500 total time=   1.0s
Parameter choice num 98 / 149 - starting...
490 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.522 total time=   0.9s
491 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.522 total time=   1.0s
492 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: accuracy, score: 0.18181818181818182 
>>>
predicted correctly / predicted_in_total = 4 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.182 total time=   1.0s
493 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 0 1 1 0 1 0 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.2727272727272727 
>>>
predicted correctly / predicted_in_total = 6 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.273 total time=   1.0s
494 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0]
scoring metric: accuracy, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 14 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 98 / 149 avg score was: 0.42687747035573126.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.636 total time=   0.9s
Parameter choice num 99 / 149 - starting...
495 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 0 1 0]
scoring metric: accuracy, score: 0.43478260869565216 
>>>
predicted correctly / predicted_in_total = 10 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.435 total time=   0.4s
496 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 0 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.565 total time=   0.4s
497 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.364 total time=   0.4s
498 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   0.4s
499 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 1 0]
scoring metric: accuracy, score: 0.5454545454545454 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 99 / 149 avg score was: 0.4454545454545455.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.545 total time=   0.4s
Parameter choice num 100 / 149 - starting...
500 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: accuracy, score: 0.391304347826087 
>>>
predicted correctly / predicted_in_total = 9 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.391 total time=   1.0s
501 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.565 total time=   0.9s
502 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   1.0s
503 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   1.0s
504 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 100 / 149 avg score was: 0.4094861660079051.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.455 total time=   1.0s
Parameter choice num 101 / 149 - starting...
505 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 1 1 1 0 0 1 0 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.609 total time=   0.4s
506 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 0 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.4782608695652174 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.478 total time=   0.4s
507 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 0 1 1]
scoring metric: accuracy, score: 0.22727272727272727 
>>>
predicted correctly / predicted_in_total = 5 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.227 total time=   0.4s
508 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.364 total time=   0.4s
509 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 0 1 1 0 0 0 0 1 1 1]
scoring metric: accuracy, score: 0.7272727272727273 
>>>
predicted correctly / predicted_in_total = 16 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 101 / 149 avg score was: 0.48102766798418967.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.727 total time=   0.4s
Parameter choice num 102 / 149 - starting...
510 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 1 1 1 0 0 1 0 0 0 1 1 1 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.6521739130434783 
>>>
predicted correctly / predicted_in_total = 15 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.652 total time=   0.4s
511 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0]
scoring metric: accuracy, score: 0.4782608695652174 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.478 total time=   0.4s
512 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: accuracy, score: 0.22727272727272727 
>>>
predicted correctly / predicted_in_total = 5 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.227 total time=   0.5s
513 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.318 total time=   0.4s
514 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 0 1 1 0]
scoring metric: accuracy, score: 0.5454545454545454 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 102 / 149 avg score was: 0.4442687747035573.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.545 total time=   0.4s
Parameter choice num 103 / 149 - starting...
515 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 1 0 0 0 1 1 1 1 0 1 0 1 1]
scoring metric: accuracy, score: 0.4782608695652174 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.478 total time=   3.5s
516 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 0 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.609 total time=   3.8s
517 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.409 total time=   3.2s
518 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   3.3s
519 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 103 / 149 avg score was: 0.4901185770750988.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   3.1s
Parameter choice num 104 / 149 - starting...
520 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 1 1 1 0 0 0 1 0 0 0 1 1 1 1 0 1 0 1 1]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.565 total time=   0.4s
521 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.522 total time=   0.4s
522 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.364 total time=   0.4s
523 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 1 0 1 1 0 1 0 0 1 0 0 0 0 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.364 total time=   0.5s
524 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0]
scoring metric: accuracy, score: 0.5454545454545454 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 104 / 149 avg score was: 0.4719367588932807.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.545 total time=   0.5s
Parameter choice num 105 / 149 - starting...
525 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: accuracy, score: 0.34782608695652173 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.348 total time=   1.0s
526 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.609 total time=   1.3s
527 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   1.3s
528 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.364 total time=   1.3s
529 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 1 0 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 105 / 149 avg score was: 0.4458498023715415.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   1.2s
Parameter choice num 106 / 149 - starting...
530 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.522 total time=   3.8s
531 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.609 total time=   5.7s
532 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   4.2s
533 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   4.4s
534 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 106 / 149 avg score was: 0.47154150197628464.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.500 total time=   4.8s
Parameter choice num 107 / 149 - starting...
535 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: accuracy, score: 0.34782608695652173 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.348 total time=   3.9s
536 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.609 total time=   3.8s
537 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   6.1s
538 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.409 total time=   7.0s
539 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 1 0 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 107 / 149 avg score was: 0.4549407114624506.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   4.6s
Parameter choice num 108 / 149 - starting...
540 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 1 1]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.565 total time=   5.5s
541 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.609 total time=   4.0s
542 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   3.6s
543 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   3.7s
544 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5454545454545454 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 108 / 149 avg score was: 0.4893280632411067.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.545 total time=   4.1s
Parameter choice num 109 / 149 - starting...
545 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 1 1]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.565 total time=   3.6s
546 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.609 total time=   3.6s
547 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   3.5s
548 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   3.7s
549 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 109 / 149 avg score was: 0.48023715415019763.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.500 total time=   3.5s
Parameter choice num 110 / 149 - starting...
550 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: accuracy, score: 0.34782608695652173 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.348 total time=   1.1s
551 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.565 total time=   1.0s
552 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   1.2s
553 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   1.0s
554 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 110 / 149 avg score was: 0.4007905138339921.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.455 total time=   1.1s
Parameter choice num 111 / 149 - starting...
555 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.565 total time=   0.5s
556 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.522 total time=   0.5s
557 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: accuracy, score: 0.18181818181818182 
>>>
predicted correctly / predicted_in_total = 4 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.182 total time=   0.7s
558 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.318 total time=   1.0s
559 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 0 1 1 0 0 0 0 1 1 0]
scoring metric: accuracy, score: 0.6818181818181818 
>>>
predicted correctly / predicted_in_total = 15 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 111 / 149 avg score was: 0.4537549407114624.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.682 total time=   0.4s
Parameter choice num 112 / 149 - starting...
560 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.34782608695652173 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.348 total time=   3.3s
561 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.609 total time=   3.7s
562 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.409 total time=   4.8s
563 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   4.2s
564 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 1 0 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 112 / 149 avg score was: 0.4549407114624506.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   3.9s
Parameter choice num 113 / 149 - starting...
565 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: accuracy, score: 0.34782608695652173 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.348 total time=   1.0s
566 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.609 total time=   1.0s
567 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   1.0s
568 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.364 total time=   1.0s
569 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 1 0 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 113 / 149 avg score was: 0.4458498023715415.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   1.0s
Parameter choice num 114 / 149 - starting...
570 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: accuracy, score: 0.34782608695652173 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.348 total time=   0.4s
571 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 0 0 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.522 total time=   0.4s
572 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   0.4s
573 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 1 0 1 1 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   0.5s
574 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 1 0 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 114 / 149 avg score was: 0.44664031620553357.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   0.5s
Parameter choice num 115 / 149 - starting...
575 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.565 total time=   1.3s
576 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 1 0 0 0 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.43478260869565216 
>>>
predicted correctly / predicted_in_total = 10 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.435 total time=   1.0s
577 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: accuracy, score: 0.22727272727272727 
>>>
predicted correctly / predicted_in_total = 5 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.227 total time=   1.1s
578 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.2727272727272727 
>>>
predicted correctly / predicted_in_total = 6 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.273 total time=   1.0s
579 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0]
scoring metric: accuracy, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 14 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 115 / 149 avg score was: 0.42727272727272725.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.636 total time=   0.9s
Parameter choice num 116 / 149 - starting...
580 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 1 1 1 0 0 1 0 0 0 1 1 1 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.6521739130434783 
>>>
predicted correctly / predicted_in_total = 15 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.652 total time=   0.4s
581 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0]
scoring metric: accuracy, score: 0.4782608695652174 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.478 total time=   0.4s
582 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: accuracy, score: 0.22727272727272727 
>>>
predicted correctly / predicted_in_total = 5 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.227 total time=   0.4s
583 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.318 total time=   0.4s
584 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 0 1 1 0]
scoring metric: accuracy, score: 0.5454545454545454 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 116 / 149 avg score was: 0.4442687747035573.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.545 total time=   0.4s
Parameter choice num 117 / 149 - starting...
585 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.565 total time=   0.5s
586 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.522 total time=   0.5s
587 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: accuracy, score: 0.22727272727272727 
>>>
predicted correctly / predicted_in_total = 5 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.227 total time=   0.4s
588 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 1 0 0 1 0 1 0 1 1 0 0 0 0 0 1 0 1 1 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.409 total time=   0.4s
589 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0]
scoring metric: accuracy, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 14 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 117 / 149 avg score was: 0.4719367588932807.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.636 total time=   0.4s
Parameter choice num 118 / 149 - starting...
590 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.565 total time=   3.4s
591 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.4782608695652174 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.478 total time=   3.2s
592 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: accuracy, score: 0.18181818181818182 
>>>
predicted correctly / predicted_in_total = 4 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.182 total time=   3.5s
593 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.2727272727272727 
>>>
predicted correctly / predicted_in_total = 6 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.273 total time=   4.2s
594 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0]
scoring metric: accuracy, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 14 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 118 / 149 avg score was: 0.42687747035573126.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=20;, score=0.636 total time=   4.7s
Parameter choice num 119 / 149 - starting...
595 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 0 1 0]
scoring metric: accuracy, score: 0.43478260869565216 
>>>
predicted correctly / predicted_in_total = 10 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.435 total time=   0.5s
596 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 0 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.565 total time=   0.4s
597 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.364 total time=   0.4s
598 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   0.5s
599 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 1 0]
scoring metric: accuracy, score: 0.5454545454545454 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 119 / 149 avg score was: 0.4454545454545455.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=50;, score=0.545 total time=   0.9s
Parameter choice num 120 / 149 - starting...
600 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.4782608695652174 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.478 total time=   5.7s
601 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 0 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.565 total time=   4.9s
602 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   4.7s
603 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   3.9s
604 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 1 0]
scoring metric: accuracy, score: 0.5909090909090909 
>>>
predicted correctly / predicted_in_total = 13 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 120 / 149 avg score was: 0.4541501976284585.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=50;, score=0.591 total time=   3.3s
Parameter choice num 121 / 149 - starting...
605 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 1 0 1 0 1 1]
scoring metric: accuracy, score: 0.4782608695652174 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.478 total time=   0.4s
606 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.565 total time=   0.4s
607 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 0 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.2727272727272727 
>>>
predicted correctly / predicted_in_total = 6 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.273 total time=   0.4s
608 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 1 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   0.4s
609 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5454545454545454 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 121 / 149 avg score was: 0.4632411067193676.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.545 total time=   0.4s
Parameter choice num 122 / 149 - starting...
610 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: accuracy, score: 0.43478260869565216 
>>>
predicted correctly / predicted_in_total = 10 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.435 total time=   1.0s
611 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.565 total time=   0.9s
612 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
>>>
predicted correctly / predicted_in_total = 7 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.318 total time=   1.0s
613 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.409 total time=   1.0s
614 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 122 / 149 avg score was: 0.4454545454545455.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=50;, score=0.500 total time=   1.1s
Parameter choice num 123 / 149 - starting...
615 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 1 1 0 0 0 1 1 0 1 1 1 0 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.609 total time=   0.4s
616 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.609 total time=   0.4s
617 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   0.4s
618 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   0.8s
619 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5909090909090909 
>>>
predicted correctly / predicted_in_total = 13 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 123 / 149 avg score was: 0.5071146245059289.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.591 total time=   0.4s
Parameter choice num 124 / 149 - starting...
620 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 1 0]
scoring metric: accuracy, score: 0.4782608695652174 
>>>
predicted correctly / predicted_in_total = 11 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.478 total time=   3.8s
621 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.609 total time=   3.4s
622 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   4.1s
623 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   4.1s
624 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 124 / 149 avg score was: 0.4628458498023716.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=300;, score=0.500 total time=   4.2s
Parameter choice num 125 / 149 - starting...
625 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0]
scoring metric: accuracy, score: 0.34782608695652173 
>>>
predicted correctly / predicted_in_total = 8 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.348 total time=   4.3s
626 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.609 total time=   3.3s
627 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   3.3s
628 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.409 total time=   3.3s
629 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 1 0 1]
scoring metric: accuracy, score: 0.45454545454545453 
>>>
predicted correctly / predicted_in_total = 10 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 125 / 149 avg score was: 0.4549407114624506.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=2000, classifier__n_jobs=-1, kBest__k=100;, score=0.455 total time=   3.3s
Parameter choice num 126 / 149 - starting...
630 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 1 0 1 1]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.565 total time=   0.4s
631 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 0]
scoring metric: accuracy, score: 0.6521739130434783 
>>>
predicted correctly / predicted_in_total = 15 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.652 total time=   0.4s
632 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.364 total time=   0.4s
633 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.409 total time=   0.4s
634 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5 
>>>
predicted correctly / predicted_in_total = 11 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 126 / 149 avg score was: 0.49802371541501983.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=100;, score=0.500 total time=   0.4s
Parameter choice num 127 / 149 - starting...
635 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.522 total time=   0.4s
636 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 1 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 0 1 0]
scoring metric: accuracy, score: 0.5217391304347826 
>>>
predicted correctly / predicted_in_total = 12 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.522 total time=   0.4s
637 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: accuracy, score: 0.18181818181818182 
>>>
predicted correctly / predicted_in_total = 4 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.182 total time=   0.4s
638 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.2727272727272727 
>>>
predicted correctly / predicted_in_total = 6 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.273 total time=   0.4s
639 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 1 0]
scoring metric: accuracy, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 14 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 127 / 149 avg score was: 0.42687747035573126.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=20;, score=0.636 total time=   0.4s
Parameter choice num 128 / 149 - starting...
640 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1]
scoring metric: accuracy, score: 0.5652173913043478 
>>>
predicted correctly / predicted_in_total = 13 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.565 total time=   0.9s
641 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 1 0 0 1 0 1 0 1 1 1 1 0 0 0 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.43478260869565216 
>>>
predicted correctly / predicted_in_total = 10 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.435 total time=   1.0s
642 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1]
scoring metric: accuracy, score: 0.22727272727272727 
>>>
predicted correctly / predicted_in_total = 5 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.227 total time=   1.3s
643 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.2727272727272727 
>>>
predicted correctly / predicted_in_total = 6 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.273 total time=   1.0s
644 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0]
scoring metric: accuracy, score: 0.6363636363636364 
>>>
predicted correctly / predicted_in_total = 14 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 128 / 149 avg score was: 0.42727272727272725.
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, classifier__n_jobs=-1, kBest__k=20;, score=0.636 total time=   1.0s
Parameter choice num 129 / 149 - starting...
645 / 749 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 1 1 0 1 1 0 0 1 1 0 0 0 1 1 0 1 1 1 0 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.609 total time=   0.4s
646 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.6086956521739131 
>>>
predicted correctly / predicted_in_total = 14 / 23
<<<
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.609 total time=   0.4s
647 / 749 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.4090909090909091 
>>>
predicted correctly / predicted_in_total = 9 / 22
<<<
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.409 total time=   0.4s
648 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.36363636363636365 
>>>
predicted correctly / predicted_in_total = 8 / 22
<<<
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100, classifier__n_jobs=-1, kBest__k=300;, score=0.364 total time=   0.4s
649 / 749 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 1]
scoring metric: accuracy, score: 0.5454545454545454 
>>>
predicted correctly / predicted_in_total = 12 / 22
<<<
Best parameter choice score by now is 0.524901185770751
In parameter choice num 129 / 149 avg score was: 0.5071146245059289.
