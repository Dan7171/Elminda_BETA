
# trial 1: 7/4/23

        # grid:

        # "pca__n_components": [1, 2, 3, 5, 8, 13, 21],
        # 'classifier__hidden_layer_sizes': generate_random_architectures(
        #     first_layer_size_options=(4, 5, 8, 10, 15, 20, 25, 28, 30, 32, 35, 37, 40)),
        # 'classifier__activation': ['relu', 'tanh'],
        # 'classifier__solver': ['adam', 'sgd', 'lbfgs'],
        # 'classifier__alpha': [0.0001],
        # 'classifier__learning_rate': ['constant', 'adaptive', 'invscaling'],
        # # 'classifier__power_t':[0.1,0.5, 0.9],
        # 'classifier__max_iter': [2000],
        # 'classifier__verbose': [False],  # details prints of loss
        # # 'classifier__warm_start':[True],
        # "classifier": [clf8]

        # choice and scores:

        # {'pca__n_components': 21, 'classifier__verbose': False, 'classifier__solver': 'adam',
        #  'classifier__max_iter': 2000, 'classifier__learning_rate': 'adaptive',
        #  'classifier__hidden_layer_sizes': (25, 18, 24, 32, 42), 'classifier__alpha': 0.0001,
        #  'classifier__activation': 'relu',
        #  'classifier': MLPClassifier(hidden_layer_sizes=(25, 18, 24, 32, 42), learning_rate='adaptive',
        #                              max_iter=2000, random_state=42)}


# trial 2: 8/4/23

        # grid

        # "pca__n_components": [i for i in range(17,30)],
        # 'classifier__hidden_layer_sizes': generate_random_architectures(first_layer_size_options=(20,23,25,27,30),
        #                                                                 avg_num_of_layers_in_network=5,
        #                                                                 adjacent_layers_ratio=1.2,
        #                                                                 num_of_networks_to_create=300
        #                                                                 ),
        # 'classifier__activation': ['relu'],
        # 'classifier__solver': ['adam'],
        # 'classifier__alpha': [0.0001],
        # 'classifier__learning_rate': ['adaptive'],
        # 'classifier__max_iter': [2500],
        # 'classifier__verbose': [False],  # details prints of loss
        # "classifier": [clf8]


        # choice and scores:

        -----------------------
         New CV report
        -----------------------
        * Classifier:
         MLPClassifier(hidden_layer_sizes=(23, 27, 22), learning_rate='adaptive',
                      max_iter=2500, random_state=42)
        * User arguments:
         {'rs': 42, 'X_version': 1, 'split_rows': 'normal', 'drop_out_correlated': False, 'age_under_50': False, 'debug': False, 'exhaustive_grid_search': False, 'classification_type': 'normal', 'scoring_method': 'accuracy', 'both': True, 'cv': 7, 'balance_y_values': True, 'n_iter': 2500, 'n_jobs': 1, 'use_gamma_columns': True, 'classification': True, 'lite_mode': True, 'test_size': 0.15, 'halving': False}
        * Pipeline details:
         Pipeline(steps=[('scaler', StandardScaler()), ('pca', PCA()),
                        ('classifier',
                         MLPClassifier(hidden_layer_sizes=(23, 27, 22),
                                       learning_rate='adaptive', max_iter=2500,
                                       random_state=42))])
        * Best Hyperparametes picked in cross validation: (cv's best score):
         {'pca__n_components': 24, 'classifier__verbose': False, 'classifier__solver': 'adam', 'classifier__max_iter': 2500, 'classifier__learning_rate': 'adaptive', 'classifier__hidden_layer_sizes': (23, 27, 22), 'classifier__alpha': 0.0001, 'classifier__activation': 'relu', 'classifier': MLPClassifier(hidden_layer_sizes=(23, 27, 22), learning_rate='adaptive',
                      max_iter=2500, random_state=42)}
        * Best features by (selectKbest):

        * Scorer_used: accuracy
        * CV Score (cv's best score for best hyperparametes): 0.787 +/- 0.029 (see score func in hyperparams)

        * Confusion matrix:
         [[56 12]
         [17 51]]
        [[TN FP
        [FN TP]]
        * Response rate:  0.5
        * CV Precision:  0.8095238095238095
        * CV Recall:  0.75
        * CV Accuracy:  0.7867647058823529
        * CV F1:  0.7786259541984734
        CV report saved to   tuning.csv
        -----------------------
         End of CV report
        -----------------------



