{'rs': 42, 'X_version': 1, 'split_rows': 'normal', 'drop_out_correlated': False, 'age_under_50': False, 'debug': False, 'exhaustive_grid_search': False, 'classification_type': 'normal', 'scoring_method': 'accuracy', 'both': True, 'cv': 5, 'balance_y_values': False, 'n_iter': 3, 'n_jobs': 1, 'use_gamma_columns': True, 'classification': True, 'lite_mode': True, 'test_size': 0.15, 'halving': False, 'stdout_to_file': True}
configs types debug
[<class 'pandas.core.frame.DataFrame'>, <class 'pandas.core.frame.DataFrame'>, <class 'pandas.core.frame.DataFrame'>, <class 'pandas.core.frame.DataFrame'>]
**************************************************Distribtion of categorial variables in data:


**************************************************Gender:
X['gender'].value_counts(): 0    78
1    54
Name: gender, dtype: int64
X_train['gender'].value_counts():
0    67
1    45
Name: gender, dtype: int64
X_test['gender'].value_counts():
0    11
1     9
Name: gender, dtype: int64
**************************************************Treatment_group (coil):
X['Treatment_group'].value_counts(): 0    75
1    57
Name: Treatment_group, dtype: int64
X_train['Treatment_group'].value_counts():
0    65
1    47
Name: Treatment_group, dtype: int64
X_test['Treatment_group'].value_counts():
1    10
0    10
Name: Treatment_group, dtype: int64
Response to treatment:
**************************************************['6-weeks_HDRS21_class'].value_counts():
1    80
0    52
Name: 6-weeks_HDRS21_class, dtype: int64
y_train['6-weeks_HDRS21_class'].value_counts():
1    68
0    44
Name: 6-weeks_HDRS21_class, dtype: int64
y_test['6-weeks_HDRS21_class'].value_counts():
1    12
0     8
Name: 6-weeks_HDRS21_class, dtype: int64

{'kBest__k': range(26, 30), 'classifier__hidden_layer_sizes': [(25, 29, 19, 29), (25, 29, 19, 30), (25, 29, 19, 31), (25, 29, 19, 32), (25, 29, 19, 33), (25, 29, 20, 29), (25, 29, 20, 30), (25, 29, 20, 31), (25, 29, 20, 32), (25, 29, 20, 33), (25, 29, 21, 29), (25, 29, 21, 30), (25, 29, 21, 31), (25, 29, 21, 32), (25, 29, 21, 33), (25, 29, 22, 29), (25, 29, 22, 30), (25, 29, 22, 31), (25, 29, 22, 32), (25, 29, 22, 33), (25, 29, 23, 29), (25, 29, 23, 30), (25, 29, 23, 31), (25, 29, 23, 32), (25, 29, 23, 33), (25, 30, 19, 29), (25, 30, 19, 30), (25, 30, 19, 31), (25, 30, 19, 32), (25, 30, 19, 33), (25, 30, 20, 29), (25, 30, 20, 30), (25, 30, 20, 31), (25, 30, 20, 32), (25, 30, 20, 33), (25, 30, 21, 29), (25, 30, 21, 30), (25, 30, 21, 31), (25, 30, 21, 32), (25, 30, 21, 33), (25, 30, 22, 29), (25, 30, 22, 30), (25, 30, 22, 31), (25, 30, 22, 32), (25, 30, 22, 33), (25, 30, 23, 29), (25, 30, 23, 30), (25, 30, 23, 31), (25, 30, 23, 32), (25, 30, 23, 33), (25, 31, 19, 29), (25, 31, 19, 30), (25, 31, 19, 31), (25, 31, 19, 32), (25, 31, 19, 33), (25, 31, 20, 29), (25, 31, 20, 30), (25, 31, 20, 31), (25, 31, 20, 32), (25, 31, 20, 33), (25, 31, 21, 29), (25, 31, 21, 30), (25, 31, 21, 31), (25, 31, 21, 32), (25, 31, 21, 33), (25, 31, 22, 29), (25, 31, 22, 30), (25, 31, 22, 31), (25, 31, 22, 32), (25, 31, 22, 33), (25, 31, 23, 29), (25, 31, 23, 30), (25, 31, 23, 31), (25, 31, 23, 32), (25, 31, 23, 33), (25, 32, 19, 29), (25, 32, 19, 30), (25, 32, 19, 31), (25, 32, 19, 32), (25, 32, 19, 33), (25, 32, 20, 29), (25, 32, 20, 30), (25, 32, 20, 31), (25, 32, 20, 32), (25, 32, 20, 33), (25, 32, 21, 29), (25, 32, 21, 30), (25, 32, 21, 31), (25, 32, 21, 32), (25, 32, 21, 33), (25, 32, 22, 29), (25, 32, 22, 30), (25, 32, 22, 31), (25, 32, 22, 32), (25, 32, 22, 33), (25, 32, 23, 29), (25, 32, 23, 30), (25, 32, 23, 31), (25, 32, 23, 32), (25, 32, 23, 33), (25, 33, 19, 29), (25, 33, 19, 30), (25, 33, 19, 31), (25, 33, 19, 32), (25, 33, 19, 33), (25, 33, 20, 29), (25, 33, 20, 30), (25, 33, 20, 31), (25, 33, 20, 32), (25, 33, 20, 33), (25, 33, 21, 29), (25, 33, 21, 30), (25, 33, 21, 31), (25, 33, 21, 32), (25, 33, 21, 33), (25, 33, 22, 29), (25, 33, 22, 30), (25, 33, 22, 31), (25, 33, 22, 32), (25, 33, 22, 33), (25, 33, 23, 29), (25, 33, 23, 30), (25, 33, 23, 31), (25, 33, 23, 32), (25, 33, 23, 33), (26, 29, 19, 29), (26, 29, 19, 30), (26, 29, 19, 31), (26, 29, 19, 32), (26, 29, 19, 33), (26, 29, 20, 29), (26, 29, 20, 30), (26, 29, 20, 31), (26, 29, 20, 32), (26, 29, 20, 33), (26, 29, 21, 29), (26, 29, 21, 30), (26, 29, 21, 31), (26, 29, 21, 32), (26, 29, 21, 33), (26, 29, 22, 29), (26, 29, 22, 30), (26, 29, 22, 31), (26, 29, 22, 32), (26, 29, 22, 33), (26, 29, 23, 29), (26, 29, 23, 30), (26, 29, 23, 31), (26, 29, 23, 32), (26, 29, 23, 33), (26, 30, 19, 29), (26, 30, 19, 30), (26, 30, 19, 31), (26, 30, 19, 32), (26, 30, 19, 33), (26, 30, 20, 29), (26, 30, 20, 30), (26, 30, 20, 31), (26, 30, 20, 32), (26, 30, 20, 33), (26, 30, 21, 29), (26, 30, 21, 30), (26, 30, 21, 31), (26, 30, 21, 32), (26, 30, 21, 33), (26, 30, 22, 29), (26, 30, 22, 30), (26, 30, 22, 31), (26, 30, 22, 32), (26, 30, 22, 33), (26, 30, 23, 29), (26, 30, 23, 30), (26, 30, 23, 31), (26, 30, 23, 32), (26, 30, 23, 33), (26, 31, 19, 29), (26, 31, 19, 30), (26, 31, 19, 31), (26, 31, 19, 32), (26, 31, 19, 33), (26, 31, 20, 29), (26, 31, 20, 30), (26, 31, 20, 31), (26, 31, 20, 32), (26, 31, 20, 33), (26, 31, 21, 29), (26, 31, 21, 30), (26, 31, 21, 31), (26, 31, 21, 32), (26, 31, 21, 33), (26, 31, 22, 29), (26, 31, 22, 30), (26, 31, 22, 31), (26, 31, 22, 32), (26, 31, 22, 33), (26, 31, 23, 29), (26, 31, 23, 30), (26, 31, 23, 31), (26, 31, 23, 32), (26, 31, 23, 33), (26, 32, 19, 29), (26, 32, 19, 30), (26, 32, 19, 31), (26, 32, 19, 32), (26, 32, 19, 33), (26, 32, 20, 29), (26, 32, 20, 30), (26, 32, 20, 31), (26, 32, 20, 32), (26, 32, 20, 33), (26, 32, 21, 29), (26, 32, 21, 30), (26, 32, 21, 31), (26, 32, 21, 32), (26, 32, 21, 33), (26, 32, 22, 29), (26, 32, 22, 30), (26, 32, 22, 31), (26, 32, 22, 32), (26, 32, 22, 33), (26, 32, 23, 29), (26, 32, 23, 30), (26, 32, 23, 31), (26, 32, 23, 32), (26, 32, 23, 33), (26, 33, 19, 29), (26, 33, 19, 30), (26, 33, 19, 31), (26, 33, 19, 32), (26, 33, 19, 33), (26, 33, 20, 29), (26, 33, 20, 30), (26, 33, 20, 31), (26, 33, 20, 32), (26, 33, 20, 33), (26, 33, 21, 29), (26, 33, 21, 30), (26, 33, 21, 31), (26, 33, 21, 32), (26, 33, 21, 33), (26, 33, 22, 29), (26, 33, 22, 30), (26, 33, 22, 31), (26, 33, 22, 32), (26, 33, 22, 33), (26, 33, 23, 29), (26, 33, 23, 30), (26, 33, 23, 31), (26, 33, 23, 32), (26, 33, 23, 33), (27, 29, 19, 29), (27, 29, 19, 30), (27, 29, 19, 31), (27, 29, 19, 32), (27, 29, 19, 33), (27, 29, 20, 29), (27, 29, 20, 30), (27, 29, 20, 31), (27, 29, 20, 32), (27, 29, 20, 33), (27, 29, 21, 29), (27, 29, 21, 30), (27, 29, 21, 31), (27, 29, 21, 32), (27, 29, 21, 33), (27, 29, 22, 29), (27, 29, 22, 30), (27, 29, 22, 31), (27, 29, 22, 32), (27, 29, 22, 33), (27, 29, 23, 29), (27, 29, 23, 30), (27, 29, 23, 31), (27, 29, 23, 32), (27, 29, 23, 33), (27, 30, 19, 29), (27, 30, 19, 30), (27, 30, 19, 31), (27, 30, 19, 32), (27, 30, 19, 33), (27, 30, 20, 29), (27, 30, 20, 30), (27, 30, 20, 31), (27, 30, 20, 32), (27, 30, 20, 33), (27, 30, 21, 29), (27, 30, 21, 30), (27, 30, 21, 31), (27, 30, 21, 32), (27, 30, 21, 33), (27, 30, 22, 29), (27, 30, 22, 30), (27, 30, 22, 31), (27, 30, 22, 32), (27, 30, 22, 33), (27, 30, 23, 29), (27, 30, 23, 30), (27, 30, 23, 31), (27, 30, 23, 32), (27, 30, 23, 33), (27, 31, 19, 29), (27, 31, 19, 30), (27, 31, 19, 31), (27, 31, 19, 32), (27, 31, 19, 33), (27, 31, 20, 29), (27, 31, 20, 30), (27, 31, 20, 31), (27, 31, 20, 32), (27, 31, 20, 33), (27, 31, 21, 29), (27, 31, 21, 30), (27, 31, 21, 31), (27, 31, 21, 32), (27, 31, 21, 33), (27, 31, 22, 29), (27, 31, 22, 30), (27, 31, 22, 31), (27, 31, 22, 32), (27, 31, 22, 33), (27, 31, 23, 29), (27, 31, 23, 30), (27, 31, 23, 31), (27, 31, 23, 32), (27, 31, 23, 33), (27, 32, 19, 29), (27, 32, 19, 30), (27, 32, 19, 31), (27, 32, 19, 32), (27, 32, 19, 33), (27, 32, 20, 29), (27, 32, 20, 30), (27, 32, 20, 31), (27, 32, 20, 32), (27, 32, 20, 33), (27, 32, 21, 29), (27, 32, 21, 30), (27, 32, 21, 31), (27, 32, 21, 32), (27, 32, 21, 33), (27, 32, 22, 29), (27, 32, 22, 30), (27, 32, 22, 31), (27, 32, 22, 32), (27, 32, 22, 33), (27, 32, 23, 29), (27, 32, 23, 30), (27, 32, 23, 31), (27, 32, 23, 32), (27, 32, 23, 33), (27, 33, 19, 29), (27, 33, 19, 30), (27, 33, 19, 31), (27, 33, 19, 32), (27, 33, 19, 33), (27, 33, 20, 29), (27, 33, 20, 30), (27, 33, 20, 31), (27, 33, 20, 32), (27, 33, 20, 33), (27, 33, 21, 29), (27, 33, 21, 30), (27, 33, 21, 31), (27, 33, 21, 32), (27, 33, 21, 33), (27, 33, 22, 29), (27, 33, 22, 30), (27, 33, 22, 31), (27, 33, 22, 32), (27, 33, 22, 33), (27, 33, 23, 29), (27, 33, 23, 30), (27, 33, 23, 31), (27, 33, 23, 32), (27, 33, 23, 33), (28, 29, 19, 29), (28, 29, 19, 30), (28, 29, 19, 31), (28, 29, 19, 32), (28, 29, 19, 33), (28, 29, 20, 29), (28, 29, 20, 30), (28, 29, 20, 31), (28, 29, 20, 32), (28, 29, 20, 33), (28, 29, 21, 29), (28, 29, 21, 30), (28, 29, 21, 31), (28, 29, 21, 32), (28, 29, 21, 33), (28, 29, 22, 29), (28, 29, 22, 30), (28, 29, 22, 31), (28, 29, 22, 32), (28, 29, 22, 33), (28, 29, 23, 29), (28, 29, 23, 30), (28, 29, 23, 31), (28, 29, 23, 32), (28, 29, 23, 33), (28, 30, 19, 29), (28, 30, 19, 30), (28, 30, 19, 31), (28, 30, 19, 32), (28, 30, 19, 33), (28, 30, 20, 29), (28, 30, 20, 30), (28, 30, 20, 31), (28, 30, 20, 32), (28, 30, 20, 33), (28, 30, 21, 29), (28, 30, 21, 30), (28, 30, 21, 31), (28, 30, 21, 32), (28, 30, 21, 33), (28, 30, 22, 29), (28, 30, 22, 30), (28, 30, 22, 31), (28, 30, 22, 32), (28, 30, 22, 33), (28, 30, 23, 29), (28, 30, 23, 30), (28, 30, 23, 31), (28, 30, 23, 32), (28, 30, 23, 33), (28, 31, 19, 29), (28, 31, 19, 30), (28, 31, 19, 31), (28, 31, 19, 32), (28, 31, 19, 33), (28, 31, 20, 29), (28, 31, 20, 30), (28, 31, 20, 31), (28, 31, 20, 32), (28, 31, 20, 33), (28, 31, 21, 29), (28, 31, 21, 30), (28, 31, 21, 31), (28, 31, 21, 32), (28, 31, 21, 33), (28, 31, 22, 29), (28, 31, 22, 30), (28, 31, 22, 31), (28, 31, 22, 32), (28, 31, 22, 33), (28, 31, 23, 29), (28, 31, 23, 30), (28, 31, 23, 31), (28, 31, 23, 32), (28, 31, 23, 33), (28, 32, 19, 29), (28, 32, 19, 30), (28, 32, 19, 31), (28, 32, 19, 32), (28, 32, 19, 33), (28, 32, 20, 29), (28, 32, 20, 30), (28, 32, 20, 31), (28, 32, 20, 32), (28, 32, 20, 33), (28, 32, 21, 29), (28, 32, 21, 30), (28, 32, 21, 31), (28, 32, 21, 32), (28, 32, 21, 33), (28, 32, 22, 29), (28, 32, 22, 30), (28, 32, 22, 31), (28, 32, 22, 32), (28, 32, 22, 33), (28, 32, 23, 29), (28, 32, 23, 30), (28, 32, 23, 31), (28, 32, 23, 32), (28, 32, 23, 33), (28, 33, 19, 29), (28, 33, 19, 30), (28, 33, 19, 31), (28, 33, 19, 32), (28, 33, 19, 33), (28, 33, 20, 29), (28, 33, 20, 30), (28, 33, 20, 31), (28, 33, 20, 32), (28, 33, 20, 33), (28, 33, 21, 29), (28, 33, 21, 30), (28, 33, 21, 31), (28, 33, 21, 32), (28, 33, 21, 33), (28, 33, 22, 29), (28, 33, 22, 30), (28, 33, 22, 31), (28, 33, 22, 32), (28, 33, 22, 33), (28, 33, 23, 29), (28, 33, 23, 30), (28, 33, 23, 31), (28, 33, 23, 32), (28, 33, 23, 33), (29, 29, 19, 29), (29, 29, 19, 30), (29, 29, 19, 31), (29, 29, 19, 32), (29, 29, 19, 33), (29, 29, 20, 29), (29, 29, 20, 30), (29, 29, 20, 31), (29, 29, 20, 32), (29, 29, 20, 33), (29, 29, 21, 29), (29, 29, 21, 30), (29, 29, 21, 31), (29, 29, 21, 32), (29, 29, 21, 33), (29, 29, 22, 29), (29, 29, 22, 30), (29, 29, 22, 31), (29, 29, 22, 32), (29, 29, 22, 33), (29, 29, 23, 29), (29, 29, 23, 30), (29, 29, 23, 31), (29, 29, 23, 32), (29, 29, 23, 33), (29, 30, 19, 29), (29, 30, 19, 30), (29, 30, 19, 31), (29, 30, 19, 32), (29, 30, 19, 33), (29, 30, 20, 29), (29, 30, 20, 30), (29, 30, 20, 31), (29, 30, 20, 32), (29, 30, 20, 33), (29, 30, 21, 29), (29, 30, 21, 30), (29, 30, 21, 31), (29, 30, 21, 32), (29, 30, 21, 33), (29, 30, 22, 29), (29, 30, 22, 30), (29, 30, 22, 31), (29, 30, 22, 32), (29, 30, 22, 33), (29, 30, 23, 29), (29, 30, 23, 30), (29, 30, 23, 31), (29, 30, 23, 32), (29, 30, 23, 33), (29, 31, 19, 29), (29, 31, 19, 30), (29, 31, 19, 31), (29, 31, 19, 32), (29, 31, 19, 33), (29, 31, 20, 29), (29, 31, 20, 30), (29, 31, 20, 31), (29, 31, 20, 32), (29, 31, 20, 33), (29, 31, 21, 29), (29, 31, 21, 30), (29, 31, 21, 31), (29, 31, 21, 32), (29, 31, 21, 33), (29, 31, 22, 29), (29, 31, 22, 30), (29, 31, 22, 31), (29, 31, 22, 32), (29, 31, 22, 33), (29, 31, 23, 29), (29, 31, 23, 30), (29, 31, 23, 31), (29, 31, 23, 32), (29, 31, 23, 33), (29, 32, 19, 29), (29, 32, 19, 30), (29, 32, 19, 31), (29, 32, 19, 32), (29, 32, 19, 33), (29, 32, 20, 29), (29, 32, 20, 30), (29, 32, 20, 31), (29, 32, 20, 32), (29, 32, 20, 33), (29, 32, 21, 29), (29, 32, 21, 30), (29, 32, 21, 31), (29, 32, 21, 32), (29, 32, 21, 33), (29, 32, 22, 29), (29, 32, 22, 30), (29, 32, 22, 31), (29, 32, 22, 32), (29, 32, 22, 33), (29, 32, 23, 29), (29, 32, 23, 30), (29, 32, 23, 31), (29, 32, 23, 32), (29, 32, 23, 33), (29, 33, 19, 29), (29, 33, 19, 30), (29, 33, 19, 31), (29, 33, 19, 32), (29, 33, 19, 33), (29, 33, 20, 29), (29, 33, 20, 30), (29, 33, 20, 31), (29, 33, 20, 32), (29, 33, 20, 33), (29, 33, 21, 29), (29, 33, 21, 30), (29, 33, 21, 31), (29, 33, 21, 32), (29, 33, 21, 33), (29, 33, 22, 29), (29, 33, 22, 30), (29, 33, 22, 31), (29, 33, 22, 32), (29, 33, 22, 33), (29, 33, 23, 29), (29, 33, 23, 30), (29, 33, 23, 31), (29, 33, 23, 32), (29, 33, 23, 33)], 'classifier__activation': ['identity', 'logistic', 'tanh', 'relu'], 'classifier__solver': ['adam', 'lbfgs', 'sgd'], 'classifier__alpha': [0.0001, 0.01], 'classifier__learning_rate': ['adaptive', 'constant', 'invscaling'], 'classifier__max_iter': [3500], 'classifier__verbose': [False], 'classifier': [MLPClassifier(random_state=42)]}
Pipeline(steps=[('smote', SMOTE(random_state=42, sampling_strategy='minority')),
                ('scaler', StandardScaler()), ('kBest', SelectKBest()),
                ('classifier', MLPClassifier(random_state=42))])
~~~~~~~~~~ RANDOMIZED SEARCH CV ~~~~~~~~~~
Fitting 5 folds for each of 3 candidates, totalling 15 fits
Parameter choice num 0 / 2 - starting...
0 / 14 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [0 0 0 1 1 1 1 1 0 0 0 1 0 0 1 0 0 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
[CV 1/5] END classifier=MLPClassifier(random_state=42), classifier__activation=tanh, classifier__alpha=0.01, classifier__hidden_layer_sizes=(27, 29, 21, 31), classifier__learning_rate=invscaling, classifier__max_iter=3500, classifier__solver=adam, classifier__verbose=False, kBest__k=28;, score=0.565 total time=   8.9s
1 / 14 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [0 0 1 1 1 1 1 1 0 1 0 0 1 0 0 1 0 1 0 0 1 1 0]
scoring metric: accuracy, score: 0.4782608695652174 
[CV 2/5] END classifier=MLPClassifier(random_state=42), classifier__activation=tanh, classifier__alpha=0.01, classifier__hidden_layer_sizes=(27, 29, 21, 31), classifier__learning_rate=invscaling, classifier__max_iter=3500, classifier__solver=adam, classifier__verbose=False, kBest__k=28;, score=0.478 total time=   1.0s
2 / 14 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
[CV 3/5] END classifier=MLPClassifier(random_state=42), classifier__activation=tanh, classifier__alpha=0.01, classifier__hidden_layer_sizes=(27, 29, 21, 31), classifier__learning_rate=invscaling, classifier__max_iter=3500, classifier__solver=adam, classifier__verbose=False, kBest__k=28;, score=0.318 total time=   1.0s
3 / 14 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 1 1 0 1 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 1]
scoring metric: accuracy, score: 0.5909090909090909 
[CV 4/5] END classifier=MLPClassifier(random_state=42), classifier__activation=tanh, classifier__alpha=0.01, classifier__hidden_layer_sizes=(27, 29, 21, 31), classifier__learning_rate=invscaling, classifier__max_iter=3500, classifier__solver=adam, classifier__verbose=False, kBest__k=28;, score=0.591 total time=   1.8s
4 / 14 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 1 0 0 0 1 0 0 0 1 1 1 1 0 1 0 1 1 0 0 1 0]
scoring metric: accuracy, score: 0.3181818181818182 
New improvement!
New best score is 0.4541501976284585
In parameter choice num 0 / 2 avg score was: 0.4541501976284585. This is the best score so far
updating search_statistics.txt...
statistics file updated successfully with new improvement in score message!
Best parameter choice score by now is 0.4541501976284585
In parameter choice num 0 / 2 avg score was: 0.4541501976284585. This is the best score so far
[CV 5/5] END classifier=MLPClassifier(random_state=42), classifier__activation=tanh, classifier__alpha=0.01, classifier__hidden_layer_sizes=(27, 29, 21, 31), classifier__learning_rate=invscaling, classifier__max_iter=3500, classifier__solver=adam, classifier__verbose=False, kBest__k=28;, score=0.318 total time=   1.2s
Parameter choice num 1 / 2 - starting...
5 / 14 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 0 0 1 0 0 1 0 0 0 0 1 0 0 1 1 0 1 0 0 0 1 0]
scoring metric: accuracy, score: 0.391304347826087 
[CV 1/5] END classifier=MLPClassifier(random_state=42), classifier__activation=relu, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(27, 32, 19, 33), classifier__learning_rate=constant, classifier__max_iter=3500, classifier__solver=sgd, classifier__verbose=False, kBest__k=29;, score=0.391 total time=   1.6s
6 / 14 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [0 0 0 1 1 0 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
[CV 2/5] END classifier=MLPClassifier(random_state=42), classifier__activation=relu, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(27, 32, 19, 33), classifier__learning_rate=constant, classifier__max_iter=3500, classifier__solver=sgd, classifier__verbose=False, kBest__k=29;, score=0.565 total time=   0.7s
7 / 14 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.22727272727272727 
[CV 3/5] END classifier=MLPClassifier(random_state=42), classifier__activation=relu, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(27, 32, 19, 33), classifier__learning_rate=constant, classifier__max_iter=3500, classifier__solver=sgd, classifier__verbose=False, kBest__k=29;, score=0.227 total time=   7.3s
8 / 14 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 1 0 1 0 1]
scoring metric: accuracy, score: 0.36363636363636365 
[CV 4/5] END classifier=MLPClassifier(random_state=42), classifier__activation=relu, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(27, 32, 19, 33), classifier__learning_rate=constant, classifier__max_iter=3500, classifier__solver=sgd, classifier__verbose=False, kBest__k=29;, score=0.364 total time=   1.1s
9 / 14 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [0 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0 1 0 0 0 0 0]
scoring metric: accuracy, score: 0.4090909090909091 
Best parameter choice score by now is 0.4541501976284585
In parameter choice num 1 / 2 avg score was: 0.39130434782608703. This is the best score so far
[CV 5/5] END classifier=MLPClassifier(random_state=42), classifier__activation=relu, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(27, 32, 19, 33), classifier__learning_rate=constant, classifier__max_iter=3500, classifier__solver=sgd, classifier__verbose=False, kBest__k=29;, score=0.409 total time=   2.4s
Parameter choice num 2 / 2 - starting...
10 / 14 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1]
fold's predicted y
 [1 1 0 1 0 1 1 1 0 0 0 1 0 0 1 0 0 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.43478260869565216 
[CV 1/5] END classifier=MLPClassifier(random_state=42), classifier__activation=tanh, classifier__alpha=0.01, classifier__hidden_layer_sizes=(29, 30, 21, 33), classifier__learning_rate=invscaling, classifier__max_iter=3500, classifier__solver=lbfgs, classifier__verbose=False, kBest__k=26;, score=0.435 total time=   2.8s
11 / 14 splits counted in cross val search 
fold's true y 
 [0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1]
fold's predicted y
 [0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0]
scoring metric: accuracy, score: 0.5652173913043478 
[CV 2/5] END classifier=MLPClassifier(random_state=42), classifier__activation=tanh, classifier__alpha=0.01, classifier__hidden_layer_sizes=(29, 30, 21, 33), classifier__learning_rate=invscaling, classifier__max_iter=3500, classifier__solver=lbfgs, classifier__verbose=False, kBest__k=26;, score=0.565 total time=   1.4s
12 / 14 splits counted in cross val search 
fold's true y 
 [0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0]
fold's predicted y
 [1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1]
scoring metric: accuracy, score: 0.3181818181818182 
[CV 3/5] END classifier=MLPClassifier(random_state=42), classifier__activation=tanh, classifier__alpha=0.01, classifier__hidden_layer_sizes=(29, 30, 21, 33), classifier__learning_rate=invscaling, classifier__max_iter=3500, classifier__solver=lbfgs, classifier__verbose=False, kBest__k=26;, score=0.318 total time=   1.1s
13 / 14 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 0 1 1 1 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 1 1]
scoring metric: accuracy, score: 0.5 
[CV 4/5] END classifier=MLPClassifier(random_state=42), classifier__activation=tanh, classifier__alpha=0.01, classifier__hidden_layer_sizes=(29, 30, 21, 33), classifier__learning_rate=invscaling, classifier__max_iter=3500, classifier__solver=lbfgs, classifier__verbose=False, kBest__k=26;, score=0.500 total time=   4.4s
14 / 14 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 1]
fold's predicted y
 [1 0 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 1 0 0 1 0]
scoring metric: accuracy, score: 0.45454545454545453 
New improvement!
New best score is 0.4545454545454545
In parameter choice num 2 / 2 avg score was: 0.4545454545454545. This is the best score so far
updating search_statistics.txt...
statistics file updated successfully with new improvement in score message!
Best parameter choice score by now is 0.4545454545454545
In parameter choice num 2 / 2 avg score was: 0.4545454545454545. This is the best score so far
[CV 5/5] END classifier=MLPClassifier(random_state=42), classifier__activation=tanh, classifier__alpha=0.01, classifier__hidden_layer_sizes=(29, 30, 21, 33), classifier__learning_rate=invscaling, classifier__max_iter=3500, classifier__solver=lbfgs, classifier__verbose=False, kBest__k=26;, score=0.455 total time=   3.2s
-----------------------
 New CV report 
-----------------------
* Classifier: 
 MLPClassifier(activation='tanh', alpha=0.01,
              hidden_layer_sizes=(29, 30, 21, 33), learning_rate='invscaling',
              max_iter=3500, random_state=42, solver='lbfgs')
* User arguments: 
 {'rs': 42, 'X_version': 1, 'split_rows': 'normal', 'drop_out_correlated': False, 'age_under_50': False, 'debug': False, 'exhaustive_grid_search': False, 'classification_type': 'normal', 'scoring_method': 'accuracy', 'both': True, 'cv': 5, 'balance_y_values': False, 'n_iter': 3, 'n_jobs': 1, 'use_gamma_columns': True, 'classification': True, 'lite_mode': True, 'test_size': 0.15, 'halving': False, 'stdout_to_file': True}
* Pipeline details: 
 Pipeline(steps=[('smote', SMOTE(random_state=42, sampling_strategy='minority')),
                ('scaler', StandardScaler()), ('kBest', SelectKBest()),
                ('classifier',
                 MLPClassifier(activation='tanh', alpha=0.01,
                               hidden_layer_sizes=(29, 30, 21, 33),
                               learning_rate='invscaling', max_iter=3500,
                               random_state=42, solver='lbfgs'))])
* Best Hyperparametes picked in cross validation: (cv's best score): 
 {'kBest__k': 26, 'classifier__verbose': False, 'classifier__solver': 'lbfgs', 'classifier__max_iter': 3500, 'classifier__learning_rate': 'invscaling', 'classifier__hidden_layer_sizes': (29, 30, 21, 33), 'classifier__alpha': 0.01, 'classifier__activation': 'tanh', 'classifier': MLPClassifier(activation='tanh', alpha=0.01,
              hidden_layer_sizes=(29, 30, 21, 33), learning_rate='invscaling',
              max_iter=3500, random_state=42, solver='lbfgs')}
* Best features by (selectKbest): 
 ['Ratio_Relative_Power_Norm_Beta1 Over Beta2_F8', 'Ratio_Relative_Power_Norm_Delta Over Beta1_C1', 'Ratio_Relative_Power_Norm_Delta Over Beta1_C2', 'Ratio_Relative_Power_Norm_Delta Over Beta1_C3', 'Ratio_Relative_Power_Norm_Delta Over Beta1_C4', 'Ratio_Relative_Power_Norm_Delta Over Beta1_CP1', 'Ratio_Relative_Power_Norm_Delta Over Beta1_CP2', 'Ratio_Relative_Power_Norm_Delta Over Beta1_CP6', 'Ratio_Relative_Power_Norm_Delta Over Beta1_CPz', 'Ratio_Relative_Power_Norm_Delta Over Beta1_Cz', 'Ratio_Relative_Power_Norm_Delta Over Beta1_F4', 'Ratio_Relative_Power_Norm_Delta Over Beta1_FC1', 'Ratio_Relative_Power_Norm_Delta Over Beta1_FC4', 'Ratio_Relative_Power_Norm_Delta Over Beta1_P10', 'Ratio_Relative_Power_Norm_Delta Over Beta1_P6', 'Ratio_Relative_Power_Norm_Delta Over Beta1_P7', 'Ratio_Relative_Power_Norm_Delta Over Beta1_P8', 'Ratio_Relative_Power_Norm_Delta Over Beta1_P9', 'Ratio_Relative_Power_Norm_Delta Over Beta1_PO8', 'Ratio_Relative_Power_Norm_Delta Over Beta1_TP7', 'Ratio_Relative_Power_Norm_Delta Over Beta1_TP8', 'Ratio_Relative_Power_Norm_Delta Over Beta2_P10', 'Ratio_Relative_Power_Norm_Delta Over Beta2_P8', 'Ratio_Relative_Power_Norm_Delta Over Beta2_PO8', 'Ratio_Relative_Power_Norm_Delta Over Beta2_Pz', 'Ratio_Relative_Power_Norm_Delta Over Beta2_TP8']
* Scorer_used: accuracy
* CV Score (cv's best score for best hyperparametes): 0.455 +/- 0.082 (see score func in hyperparams)  

* Confusion matrix: 
 [[15 29]
 [32 36]]
[[TN FP
[FN TP]]
* Response rate:  0.6071428571428571
* CV Precision:  0.5538461538461539
* CV Recall:  0.5294117647058824
* CV Accuracy:  0.45535714285714285
* CV F1:  0.5413533834586466
CV report saved to   tuning.csv
-----------------------
 End of CV report 
----------------------- 



<<<<<<<<<<<<<<<<<<<<< GSCVrunner.py finished successfuly<<<<<<<<<<<<<<<<<<<<<
