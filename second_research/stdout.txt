{'rs': 42, 'X_version': 1, 'split_rows': 'normal', 'drop_out_correlated': False, 'age_under_50': False, 'debug': False, 'exhaustive_grid_search': True, 'classification_type': 'normal', 'scoring_method': 'accuracy', 'both': True, 'cv': 5, 'balance_y_values': True, 'n_iter': None, 'n_jobs': 1, 'use_gamma_columns': True, 'classification': True, 'lite_mode': True, 'test_size': 0.15, 'halving': False, 'stdout_to_file': True}
               subject.elm_id  ... Ratio_Relative_Power_Norm_Theta Over Gamma_O2
0    634299cb222ccf67878d3812  ...                                      2.590757
1    634299cd222ccf67878d3813  ...                                      6.667580
2    634299cd222ccf67878d3814  ...                                      2.023350
3    634299cd222ccf67878d3815  ...                                      2.789142
4    634299cd222ccf67878d3816  ...                                     28.303519
..                        ...  ...                                           ...
140  634299e4222ccf67878d38a2  ...                                     13.513551
141  634299e4222ccf67878d38a3  ...                                      6.488251
142  634299e4222ccf67878d38a4  ...                                      1.044248
143  634299e4222ccf67878d38a5  ...                                      1.829696
144  634299e4222ccf67878d38a7  ...                                      2.937826

[145 rows x 1588 columns]
configs types debug
[<class 'pandas.core.frame.DataFrame'>, <class 'pandas.core.frame.DataFrame'>, <class 'pandas.core.frame.DataFrame'>, <class 'pandas.core.frame.DataFrame'>]
balancing dataset (y values) using SMOTE...
112 y values
value counts:
6-weeks_HDRS21_class
1                       68
0                       44
dtype: int64
after balancing: 136 y values
value counts:
6-weeks_HDRS21_class
0                       68
1                       68
dtype: int64
{'kBest__k': [2], 'classifier__bootstrap': [True], 'classifier__max_depth': [4, 10], 'classifier__min_samples_split': [2], 'classifier__min_samples_leaf': [2, 4], 'classifier__max_features': ['auto'], 'classifier': [RandomForestClassifier(random_state=42)]}
Pipeline(steps=[('scaler', StandardScaler()), ('kBest', SelectKBest()),
                ('classifier', RandomForestClassifier(random_state=42))])
~~~~~~~~~~ EXHAUSTIVE SEARCH CV ~~~~~~~~~~~
Fitting 5 folds for each of 4 candidates, totalling 20 fits
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__bootstrap=True, classifier__max_depth=4, classifier__max_features=auto, classifier__min_samples_leaf=2, classifier__min_samples_split=2, kBest__k=2;, score=nan total time=   0.3s
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__bootstrap=True, classifier__max_depth=4, classifier__max_features=auto, classifier__min_samples_leaf=2, classifier__min_samples_split=2, kBest__k=2;, score=nan total time=   0.2s
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__bootstrap=True, classifier__max_depth=4, classifier__max_features=auto, classifier__min_samples_leaf=2, classifier__min_samples_split=2, kBest__k=2;, score=nan total time=   0.2s
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__bootstrap=True, classifier__max_depth=4, classifier__max_features=auto, classifier__min_samples_leaf=2, classifier__min_samples_split=2, kBest__k=2;, score=nan total time=   0.2s
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__bootstrap=True, classifier__max_depth=4, classifier__max_features=auto, classifier__min_samples_leaf=2, classifier__min_samples_split=2, kBest__k=2;, score=nan total time=   0.2s
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__bootstrap=True, classifier__max_depth=4, classifier__max_features=auto, classifier__min_samples_leaf=4, classifier__min_samples_split=2, kBest__k=2;, score=nan total time=   0.2s
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__bootstrap=True, classifier__max_depth=4, classifier__max_features=auto, classifier__min_samples_leaf=4, classifier__min_samples_split=2, kBest__k=2;, score=nan total time=   0.2s
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__bootstrap=True, classifier__max_depth=4, classifier__max_features=auto, classifier__min_samples_leaf=4, classifier__min_samples_split=2, kBest__k=2;, score=nan total time=   0.2s
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__bootstrap=True, classifier__max_depth=4, classifier__max_features=auto, classifier__min_samples_leaf=4, classifier__min_samples_split=2, kBest__k=2;, score=nan total time=   0.2s
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__bootstrap=True, classifier__max_depth=4, classifier__max_features=auto, classifier__min_samples_leaf=4, classifier__min_samples_split=2, kBest__k=2;, score=nan total time=   1.1s
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__bootstrap=True, classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=2, classifier__min_samples_split=2, kBest__k=2;, score=nan total time=   0.9s
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__bootstrap=True, classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=2, classifier__min_samples_split=2, kBest__k=2;, score=nan total time=   0.5s
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__bootstrap=True, classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=2, classifier__min_samples_split=2, kBest__k=2;, score=nan total time=   1.0s
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__bootstrap=True, classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=2, classifier__min_samples_split=2, kBest__k=2;, score=nan total time=   0.8s
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__bootstrap=True, classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=2, classifier__min_samples_split=2, kBest__k=2;, score=nan total time=   0.5s
[CV 1/5] END classifier=RandomForestClassifier(random_state=42), classifier__bootstrap=True, classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=4, classifier__min_samples_split=2, kBest__k=2;, score=nan total time=   0.7s
[CV 2/5] END classifier=RandomForestClassifier(random_state=42), classifier__bootstrap=True, classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=4, classifier__min_samples_split=2, kBest__k=2;, score=nan total time=   0.6s
[CV 3/5] END classifier=RandomForestClassifier(random_state=42), classifier__bootstrap=True, classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=4, classifier__min_samples_split=2, kBest__k=2;, score=nan total time=   0.8s
[CV 4/5] END classifier=RandomForestClassifier(random_state=42), classifier__bootstrap=True, classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=4, classifier__min_samples_split=2, kBest__k=2;, score=nan total time=   0.4s
[CV 5/5] END classifier=RandomForestClassifier(random_state=42), classifier__bootstrap=True, classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=4, classifier__min_samples_split=2, kBest__k=2;, score=nan total time=   0.5s
Fitting 5 folds for each of 4 candidates, totalling 20 fits
Parameter choice num 0 / 3 - starting...
0 / 19 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0 1 1 0 0]
fold's predicted y
 [1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0]
scoring metric: accuracy, score: 0.5 
[CV 1/5] END classifier=RandomForestClassifier(max_depth=4, min_samples_leaf=2, random_state=42), classifier__bootstrap=True, classifier__max_depth=4, classifier__max_features=auto, classifier__min_samples_leaf=2, classifier__min_samples_split=2, kBest__k=2;, score=0.500 total time=   0.7s
1 / 19 splits counted in cross val search 
fold's true y 
 [1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 0 1 0 1 1 0 1 1 1 1 0 1 0 1 0 1 0 1 1 1 0 1 0 1]
scoring metric: accuracy, score: 0.5925925925925926 
[CV 2/5] END classifier=RandomForestClassifier(max_depth=4, min_samples_leaf=2, random_state=42), classifier__bootstrap=True, classifier__max_depth=4, classifier__max_features=auto, classifier__min_samples_leaf=2, classifier__min_samples_split=2, kBest__k=2;, score=0.593 total time=   0.4s
2 / 19 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 1 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0]
scoring metric: accuracy, score: 0.7037037037037037 
[CV 3/5] END classifier=RandomForestClassifier(max_depth=4, min_samples_leaf=2, random_state=42), classifier__bootstrap=True, classifier__max_depth=4, classifier__max_features=auto, classifier__min_samples_leaf=2, classifier__min_samples_split=2, kBest__k=2;, score=0.704 total time=   0.5s
3 / 19 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 0 0 1 1 0 1 0 1 0 1 1 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0]
scoring metric: accuracy, score: 0.6296296296296297 
[CV 4/5] END classifier=RandomForestClassifier(max_depth=4, min_samples_leaf=2, random_state=42), classifier__bootstrap=True, classifier__max_depth=4, classifier__max_features=auto, classifier__min_samples_leaf=2, classifier__min_samples_split=2, kBest__k=2;, score=0.630 total time=   0.4s
4 / 19 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 1]
scoring metric: accuracy, score: 0.48148148148148145 
New improvement!
New best score is 0.5814814814814815
In parameter choice num 0 / 3 avg score was: 0.5814814814814815. This is the best score so far
updating search_statistics.txt...
statistics file updated successfully with new improvement in score message!
Best parameter choice score by now is 0.5814814814814815
In parameter choice num 0 / 3 avg score was: 0.5814814814814815. This is the best score so far
[CV 5/5] END classifier=RandomForestClassifier(max_depth=4, min_samples_leaf=2, random_state=42), classifier__bootstrap=True, classifier__max_depth=4, classifier__max_features=auto, classifier__min_samples_leaf=2, classifier__min_samples_split=2, kBest__k=2;, score=0.481 total time=   0.5s
Parameter choice num 1 / 3 - starting...
5 / 19 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0 1 1 0 0]
fold's predicted y
 [1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0]
scoring metric: accuracy, score: 0.5 
[CV 1/5] END classifier=RandomForestClassifier(max_depth=4, min_samples_leaf=2, random_state=42), classifier__bootstrap=True, classifier__max_depth=4, classifier__max_features=auto, classifier__min_samples_leaf=4, classifier__min_samples_split=2, kBest__k=2;, score=0.500 total time=   0.4s
6 / 19 splits counted in cross val search 
fold's true y 
 [1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0 1 0 1 1 1 0 1 0 1]
scoring metric: accuracy, score: 0.6296296296296297 
[CV 2/5] END classifier=RandomForestClassifier(max_depth=4, min_samples_leaf=2, random_state=42), classifier__bootstrap=True, classifier__max_depth=4, classifier__max_features=auto, classifier__min_samples_leaf=4, classifier__min_samples_split=2, kBest__k=2;, score=0.630 total time=   0.6s
7 / 19 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0]
scoring metric: accuracy, score: 0.5925925925925926 
[CV 3/5] END classifier=RandomForestClassifier(max_depth=4, min_samples_leaf=2, random_state=42), classifier__bootstrap=True, classifier__max_depth=4, classifier__max_features=auto, classifier__min_samples_leaf=4, classifier__min_samples_split=2, kBest__k=2;, score=0.593 total time=   0.5s
8 / 19 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 0 0 1 1 0 1 0 1 0 1 1 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0]
scoring metric: accuracy, score: 0.5925925925925926 
[CV 4/5] END classifier=RandomForestClassifier(max_depth=4, min_samples_leaf=2, random_state=42), classifier__bootstrap=True, classifier__max_depth=4, classifier__max_features=auto, classifier__min_samples_leaf=4, classifier__min_samples_split=2, kBest__k=2;, score=0.593 total time=   0.5s
9 / 19 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 1]
scoring metric: accuracy, score: 0.48148148148148145 
Best parameter choice score by now is 0.5814814814814815
In parameter choice num 1 / 3 avg score was: 0.5592592592592592. This is the best score so far
[CV 5/5] END classifier=RandomForestClassifier(max_depth=4, min_samples_leaf=2, random_state=42), classifier__bootstrap=True, classifier__max_depth=4, classifier__max_features=auto, classifier__min_samples_leaf=4, classifier__min_samples_split=2, kBest__k=2;, score=0.481 total time=   0.5s
Parameter choice num 2 / 3 - starting...
10 / 19 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0 1 1 0 0]
fold's predicted y
 [1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0]
scoring metric: accuracy, score: 0.5714285714285714 
[CV 1/5] END classifier=RandomForestClassifier(max_depth=4, min_samples_leaf=2, random_state=42), classifier__bootstrap=True, classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=2, classifier__min_samples_split=2, kBest__k=2;, score=0.571 total time=   0.4s
11 / 19 splits counted in cross val search 
fold's true y 
 [1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 0 1 0 1 1 1 1 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 1]
scoring metric: accuracy, score: 0.48148148148148145 
[CV 2/5] END classifier=RandomForestClassifier(max_depth=4, min_samples_leaf=2, random_state=42), classifier__bootstrap=True, classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=2, classifier__min_samples_split=2, kBest__k=2;, score=0.481 total time=   0.2s
12 / 19 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 1 1 1 1 1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1]
scoring metric: accuracy, score: 0.7037037037037037 
[CV 3/5] END classifier=RandomForestClassifier(max_depth=4, min_samples_leaf=2, random_state=42), classifier__bootstrap=True, classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=2, classifier__min_samples_split=2, kBest__k=2;, score=0.704 total time=   0.2s
13 / 19 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 0 1 1 1 0 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 1]
scoring metric: accuracy, score: 0.48148148148148145 
[CV 4/5] END classifier=RandomForestClassifier(max_depth=4, min_samples_leaf=2, random_state=42), classifier__bootstrap=True, classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=2, classifier__min_samples_split=2, kBest__k=2;, score=0.481 total time=   0.2s
14 / 19 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 1]
scoring metric: accuracy, score: 0.4444444444444444 
Best parameter choice score by now is 0.5814814814814815
In parameter choice num 2 / 3 avg score was: 0.5365079365079366. This is the best score so far
[CV 5/5] END classifier=RandomForestClassifier(max_depth=4, min_samples_leaf=2, random_state=42), classifier__bootstrap=True, classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=2, classifier__min_samples_split=2, kBest__k=2;, score=0.444 total time=   0.2s
Parameter choice num 3 / 3 - starting...
15 / 19 splits counted in cross val search 
fold's true y 
 [0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0 1 1 0 0]
fold's predicted y
 [1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0]
scoring metric: accuracy, score: 0.5 
[CV 1/5] END classifier=RandomForestClassifier(max_depth=4, min_samples_leaf=2, random_state=42), classifier__bootstrap=True, classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=4, classifier__min_samples_split=2, kBest__k=2;, score=0.500 total time=   0.2s
16 / 19 splits counted in cross val search 
fold's true y 
 [1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 1 1 0 1 0 0 1 1 1 1 1 1 0 0 0 1 0 1 0 1 1 1 1 1 0 1]
scoring metric: accuracy, score: 0.5925925925925926 
[CV 2/5] END classifier=RandomForestClassifier(max_depth=4, min_samples_leaf=2, random_state=42), classifier__bootstrap=True, classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=4, classifier__min_samples_split=2, kBest__k=2;, score=0.593 total time=   0.2s
17 / 19 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 1 0 1 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1]
scoring metric: accuracy, score: 0.6296296296296297 
[CV 3/5] END classifier=RandomForestClassifier(max_depth=4, min_samples_leaf=2, random_state=42), classifier__bootstrap=True, classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=4, classifier__min_samples_split=2, kBest__k=2;, score=0.630 total time=   0.2s
18 / 19 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]
fold's predicted y
 [1 0 0 1 1 0 1 0 1 0 1 1 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0]
scoring metric: accuracy, score: 0.5925925925925926 
[CV 4/5] END classifier=RandomForestClassifier(max_depth=4, min_samples_leaf=2, random_state=42), classifier__bootstrap=True, classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=4, classifier__min_samples_split=2, kBest__k=2;, score=0.593 total time=   0.2s
19 / 19 splits counted in cross val search 
fold's true y 
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]
fold's predicted y
 [0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 1]
scoring metric: accuracy, score: 0.48148148148148145 
Best parameter choice score by now is 0.5814814814814815
In parameter choice num 3 / 3 avg score was: 0.5592592592592592. This is the best score so far
[CV 5/5] END classifier=RandomForestClassifier(max_depth=4, min_samples_leaf=2, random_state=42), classifier__bootstrap=True, classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=4, classifier__min_samples_split=2, kBest__k=2;, score=0.481 total time=   0.2s
-----------------------
 New CV report 
-----------------------
* Classifier: 
 RandomForestClassifier(max_depth=4, min_samples_leaf=2, random_state=42)
* User arguments: 
 {'rs': 42, 'X_version': 1, 'split_rows': 'normal', 'drop_out_correlated': False, 'age_under_50': False, 'debug': False, 'exhaustive_grid_search': True, 'classification_type': 'normal', 'scoring_method': 'accuracy', 'both': True, 'cv': 5, 'balance_y_values': True, 'n_iter': 4, 'n_jobs': 1, 'use_gamma_columns': True, 'classification': True, 'lite_mode': True, 'test_size': 0.15, 'halving': False, 'stdout_to_file': True}
* Pipeline details: 
 Pipeline(steps=[('scaler', StandardScaler()), ('kBest', SelectKBest()),
                ('classifier',
                 RandomForestClassifier(max_depth=4, min_samples_leaf=2,
                                        random_state=42))])
* Best Hyperparametes picked in cross validation: (cv's best score): 
 {'classifier': RandomForestClassifier(max_depth=4, min_samples_leaf=2, random_state=42), 'classifier__bootstrap': True, 'classifier__max_depth': 4, 'classifier__max_features': 'auto', 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2, 'kBest__k': 2}
* Best features by (selectKbest): 
 ['Ratio_Relative_Power_Norm_Delta Over Beta1_P10', 'Ratio_Relative_Power_Norm_Delta Over Beta1_P8']
* Scorer_used: accuracy
* CV Score (cv's best score for best hyperparametes): 0.581 +/- 0.082 (see score func in hyperparams)  

* Confusion matrix: 
 [[47 21]
 [36 32]]
[[TN FP
[FN TP]]
* Response rate:  0.5
* CV Precision:  0.6037735849056604
* CV Recall:  0.47058823529411764
* CV Accuracy:  0.5808823529411765
* CV F1:  0.5289256198347108
CV report saved to   tuning.csv
-----------------------
 End of CV report 
----------------------- 



<<<<<<<<<<<<<<<<<<<<< GSCVrunner.py finished successfuly, check stdout.txt, search_statistics.txt and tuning.csv for search results <<<<<<<<<<<<<<<<<<<<<
